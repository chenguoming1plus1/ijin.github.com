<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: events | @ijin]]></title>
  <link href="http://ijin.github.com/blog/categories/events/atom.xml" rel="self"/>
  <link href="http://ijin.github.com/"/>
  <updated>2015-04-03T22:38:55+09:00</updated>
  <id>http://ijin.github.com/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[サバフェス！2015に参加してきた]]></title>
    <link href="http://ijin.github.com/blog/2015/03/27/serverfesta-2015-spring/"/>
    <updated>2015-03-27T12:56:00+09:00</updated>
    <id>http://ijin.github.com/blog/2015/03/27/serverfesta-2015-spring</id>
    <content type="html"><![CDATA[<p><a href="http://connpass.com/event/11571/">サバフェス！2015 Spring</a>に参加してきました。
やった内容を少々。</p>

<p><a href="/blog/2013/12/13/serverfesta-2013-autumn">前回</a>と同じくチーム@ijinとして1人で参戦して、順位は「<strong>4位</strong>」。</p>

<p>スコアは<strong>44988.867 TpmC</strong>でした。</p>

<h2>お題</h2>

<p>Mysql on ioDriveでtpcc-mysqlベンチマークのtransaction throughput競争。</p>

<p>第1陣と第2陣に分かれていて、今回は後者での参戦。</p>

<h2>はじめに</h2>

<p>競技期間は5日間あったものの、第1陣で<a href="http://netmark.jp/2015/03/svfes-2.html">結構な地雷があった</a>のと、Fusion-IO（現SanDisk）のioDriveとtpcc-mysqlは2年前に<a href="/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/">触った</a>ので最初はあんまりやる気が起きなくて困ってました。後は前回と違って施せる施策がかなり限定されるというので、正直5日間は長過ぎるのではないかという印象でした。（結果的に第1陣のトラブルとかを鑑みると長さ的には良かったのかも知れないけど）</p>

<p>という事で初日はログインとベンチで基準値を取るだけして終了。</p>

<p>その後、最近のMySQLやioDrive周りの情報収集を軽ーくして数日が経過。。</p>

<p>そして最終日の夜中になって、なんとか本腰を入れてチューニング開始。まあ、やりだしたら楽しいんですけどね。</p>

<h2>マシンスペック</h2>

<ul>
<li>CentOS 6.4</li>
<li>Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz x 32</li>
<li>32GB RAM</li>
<li>40G HDD</li>
<li>320GB ioDrive</li>
</ul>


<h2>制限</h2>

<pre><code>innodb_doublewrite = 1
innodb_flush_log_at_trx_commit = 1
</code></pre>

<p>その他レギューレーションは<a href="https://2015spring.serverfesta.info/?page_id=299">こちら</a></p>

<h2>方針</h2>

<p>今までのtwitterの<a href="https://twitter.com/search?q=%23%E3%82%B5%E3%83%90%E3%83%95%E3%82%A7%E3%82%B9">タイムライン</a>からして、どうもベンチをウェブ画面から要求しても並列実行の数とキューイング、及び非常に長い実行時間からして1時間に一回実行できるかどうかも怪しかったのでローカルでこまめに回す方向に。</p>

<p>本番データはtpccの1000 warehouse（70GB+）、16GB Buffer Pool、900sの実行時間だったのでそれを250 warehouse, 4GB Buffer Poolと縮小し120sと短めに設定。こうすることによってローカルでのデータコピー時間やベンチ実行時感が短縮され、時間がない中での細かいパラメータのチューニングに専念できる。Buffer Poolはどうせ一番効くと分かりきってるので、あえて後回し。DBは6年前（MySQL 5.0時代）から手に滲んで愛用しているPercona Serverの5.6版を選択。</p>

<p>スコアの推移はこんな感じ。データセットが小さい分、スコアは大きめ。</p>

<p><img src="https://docs.google.com/spreadsheets/d/1zm6-THRYR_EcLoHgacRScxlhSzeQAkbJ0RXiAI4fiRU/pubchart?oid=1067951178&amp;format=image"></p>

<p>終盤になってやっと本番に近いデータセットや実行時感で細かいチューニング。</p>

<p><img src="https://docs.google.com/spreadsheets/d/1zm6-THRYR_EcLoHgacRScxlhSzeQAkbJ0RXiAI4fiRU/pubchart?oid=2026636320&amp;format=image"></p>

<p>最終的にローカルでのベストスコアは<strong>53420.332 TpmC</strong>でした。</p>

<h2>設定ファイル</h2>

<script src="https://gist.github.com/ijin/341bab7569e372e1addb.js"></script>


<h2>効果があったもの</h2>

<p>細かいおまじないレベルでのパラメータも他にいくつあったけど、割と効いたのをピックアップ。また、既に設定されていたパラメータは除外（innodb_io_capacity等）</p>

<p>mysql</p>

<pre><code>datadir=/fioa/mysql
tmpdir=/fioa/tmp
sync_binlog=0
innodb_buffer_pool_size = 28150M
innodb_buffer_pool_instances=16
innodb_log_file_size=4G
innodb_log_files_in_group=3
innodb_log_group_home_dir=/var/log/mysql
innodb_log_buffer_size=64M
innodb_data_file_path=ibdata1:76M;../../var/log/mysql/ibdata2:500M:autoextend
innodb_checksum_algorithm=0
innodb_max_dirty_pages_pct=90
innodb_lru_scan_depth=2000
numa_interleave=1
flush_caches
malloc-lib=/usr/lib64/libjemalloc.so.1
</code></pre>

<p>etc</p>

<pre><code>vm.swappiness=1
mount option (noatime,nodiratime,  max_batch_time=0,nobarrier,discard)
cache warmup
</code></pre>

<p>基本的にはioDriveにIOをなるべく発生させない、もしくは遅延させる関連のパラメータが効いた感じ。この辺は割と正統なチューニング方法。一つ、若干工夫したのは、doublewrite buffer fileの指定方法。シーケンシャルなIOが発生するログ周りの処理はHDDに逃がした方がioDrive/SSD的には負荷低減になるけど、Percona 5.5までは<strong>innodb_doublewrite_file</strong>というパラメータでいつも指定していたのが、5.6ではなんと未実装！なのでベンチマーク前にコピーされるibdata1の予めのサイズを計っておいて、以降の書き込みをHDD側へ逃がすように<strong>innodb_data_file_path</strong>で調整。</p>

<p>他はNUMAによるメモリの偏り調整とmallocライブラリを使う指定。この辺もPerconaやMariaDB専用オプション。</p>

<p>後は一応初動のスコアをちょっとだけ稼ぐためにmysqlのstartup script内にてテーブルをcount(*)してindexをbuffer poolに乗せたぐらい。</p>

<h2>効果が微妙だったもの</h2>

<p>mysql</p>

<pre><code>innodb_flush_method=ALL_O_DIRECT
innodb_support_xa=0
innodb_thread_concurrency=N
innodb_flush_neighbors=0
query_cache_size=0
large-pages
</code></pre>

<p>etc</p>

<pre><code>echo 'noop' &gt; /sys/block/fioa/queue/scheduler
echo 4096 &gt; /sys/block/fioa/queue/nr_requests
echo 2 &gt; /sys/block/fioa/queue/rq_affinity
renice -n19 -p `ps auxf | grep mackerel | grep -v grep | awk ‘{print $2}’`
</code></pre>

<p>large-pagesでページサイズを大きく設定すればメモリ効率は向上するはずが、少なくともベンチマークにおいては効果なし。また、スケジューラをnoopやdeadlineと変えたり、nr_requestsやrq_affinityを調整してみたけど、デフォルトのOS bypass設定と比べてあまり変化なし。</p>

<h2>試したかったもの</h2>

<ul>
<li>ioDrvieのblock sizeのリサイズ</li>
<li>C0 state（CPUのC stateを制御して変動させずにioDriveの処理向上の期待）</li>
<li>numa_node_forced_local（IO処理をメモリに一番近接しているCPUで行う）</li>
<li>IRQ pinning（ioDriveのIRQを固定）</li>
<li>network tuning</li>
</ul>


<p>この中で最後やることリストに乗っけていながらやらなかったネットワーク周りのチューニング。多分、これが敗因。（1位のチームzzz(<a href="https://twitter.com/ttkzw">@ttkzwさん</a>)はローカルベンチマークで51000ぐらいだったので）もっとリモートからベンチが実行される事に意識を向ければ良かったのかもしれないですね。とはいえ、最後はキュー待ちが8チームだったり、結果が不具合で見れなかったりと、バダバタしてたのでそっちに気を取られたのもまた事実。まあ、半日ちょいのチューニングにしてはそこそこ行った感じでしょうか。</p>

<h2>終わりに</h2>

<p>最初は運営側が「目下実装中です！」といいながら<strong>#トラしゅ</strong>をしているような感じでちょっと不安でしたが、最後は（第2陣という事もあり）それなりに楽しめました。ベンチマーク時間の短縮と並列実行数がもうちょっと増やせたらよかったですかね。運営側の皆様、大変お疲れさまでした！</p>

<h2>おまけ</h2>

<p>賞品として3DマッサージピローとSSDを頂きました！</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p>3DマッサージピローとSSDをもらった。 <a href="https://twitter.com/hashtag/%E3%82%B5%E3%83%90%E3%83%95%E3%82%A7%E3%82%B9?src=hash">#サバフェス</a> <a href="http://t.co/mKczn9mflZ">pic.twitter.com/mKczn9mflZ</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/581048257171820544">March 26, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>個人敵には飛び込みLTした人がもらったDroneの方が良さそうだったけど、ピローは家族に好評でした。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ISUCON4の本戦の思い出]]></title>
    <link href="http://ijin.github.com/blog/2014/12/31/isucon4-final/"/>
    <updated>2014-12-31T20:52:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/12/31/isucon4-final</id>
    <content type="html"><![CDATA[<p>ISUCON4の本戦の直後にそのままAWS re:Inventへ行ったきりエントリを書いてなかったので思い出だけでも年内に書いておく。</p>

<p>内容の<a href="http://isucon.net/archives/41252218.html">エントリ</a>はたくさんあるので、詳しい内容なそちらに任せます。</p>

<p>結果は予選よりちょい上の<strong>15位</strong>。まあ、中間層は結構団子状態だったので誤差の範囲とも言えますが。。</p>

<h2>Cache-Control</h2>

<p>結局はCache-Controlヘッダーに気づくかどうかという点にかかっていて、達成したのは<a href="http://isucon.net/archives/41634734.html">2チーム</a>のみ。優勝チームのモリスさんが「頭から煙が出る程考えて」やっと直前に答えにたどり着いた事を考えると、ベンチマークツールの挙動が若干不思議な実装になっていたとはいえ、思慮深さが足りなかったと反省。</p>

<h2>冒険しすぎた</h2>

<p>今回はrubyとGoのハイブリッド構成でもろもろチューニング。が、しばらくして帯域が頭打ちに。。
また、その間にメンバーの一人の<a href="https://twitter.com/fruwe">@fruwe</a>に<a href="http://undertow.io/">Undertow</a>というjavaのフレームワークでチャレンジしてもらうものの（事前の技術検証では結構期待できそうだった）、実装完走にはいたらず。この辺は冒険し過ぎたかな。。振り返ってみれば、結局2位のチームがブレークスルーをしたのを見て、全作業を一旦ストップしてでも皆で考えなおす行動を取れば良かったのかもしれないですね。ただ、当時は予選でのベンチマークツールがいささか不安定だった事と運営側もリアルタイムでバグフィックスをしてたという事情もあり、きっとバグか何かだろうとあまり気にしてなかったのも確か。</p>

<h2>最後に</h2>

<p>とまあ、不完全燃焼だったけど、なんだかんだで面白かったです。運営＆参加者の皆様お疲れ様でした。来年またあるか分からないけど、楽しみにしています。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ISUCON4の予選を通過したんだった]]></title>
    <link href="http://ijin.github.com/blog/2014/10/20/isucon4-qualifier/"/>
    <updated>2014-10-20T15:38:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/10/20/isucon4-qualifier</id>
    <content type="html"><![CDATA[<p>そういえば、3回目の参加となる<a href="http://isucon.net/">ISUCON</a>の第4回目の予選を通過してました。</p>

<p><a href="http://isucon.net/archives/40576269.html">結果</a>は185チーム中、<strong>19位</strong>というなんと微妙な結果で本戦にいける事に。</p>

<h3>事前準備</h3>

<p>今年も<a href="https://twitter.com/cads">@cads</a>と<a href="https://twitter.com/fruwe">@fruwe</a>でお馴染みのメンバーで「Mr. Frank &amp; Co: A New Hope」として登録。</p>

<p>前日までこんな感じの打ち合わせや予習を実地。</p>

<ul>
<li>選択言語はruby</li>
<li>効率化・自動化の為にansible playbookを用意

<ul>
<li>ssh keys</li>
<li>dotfiles</li>
<li>rubyの複数バージョン</li>
<li>各種ミドルウェア</li>
</ul>
</li>
<li>sidekiq等のバックグラウンドワーカーやキャッシュ周りの仮組み</li>
<li>redisの復習</li>
<li>去年やったエントリを読む</li>
<li>当日の流れの確認</li>
<li>コミュニケーションツールとして最近仕事で活躍してる<strong>Slack</strong>を導入</li>
</ul>


<p>役割としては他の二人がコード実装に集中できるように、私がインフラ周り、コードレビュー、ファシリテーターを務める。</p>

<h3>お題発表</h3>

<p>不正ログイン防止の為にアクセスの失敗回数に応じてログインロックをかけるシステム。実に今風なオンラインバンキングサービス「いすこん銀行」w 最後はjsonのレポートが出力。</p>

<p><img src="https://lh5.googleusercontent.com/-XjuyJ-r62YE/VETj3ySpGkI/AAAAAAAABAo/2Q2yi6YWJUk/w622-h373-no/isucon4q-bank.png"></p>

<h3>前半戦</h3>

<p>まずは今までの経験からいきなりチューニングをせず、じっくりとアプリ挙動を把握し、計測し、コード解析に専念。レギュレーションもしっかり読む。この辺の衝動のコントロールはうまくなって来た感触。</p>

<p>アプリ自体は例年の作りによく似ていて、まあそこそこ高速化はできるだろうけど、その分他のチームも同様だろうと予想。</p>

<p>コードを3人で読みつつ、前日までに用意していたansibleを流したり、git化したり、計測を淡々と実地。</p>

<p>言語をいくつか参考値として計測した初期スコア</p>

<table>
<thead>
<tr>
<th>language </th>
<th> score </th>
</tr>
</thead>
<tbody>
<tr>
<td>ruby     </td>
<td> 1236 </td>
</tr>
<tr>
<td>go       </td>
<td> 1733 </td>
</tr>
<tr>
<td>perl     </td>
<td> 1662 </td>
</tr>
</tbody>
</table>


<ul>
<li>Web側は各リスエストの比率やレスポンスタイム等を解析</li>
<li>DB周りは幸いMySQLだったので全ログ出力してpt-query-digestで解析<br />
（Postgresだったらどうしたんだろう）</li>
<li>OS周りはdstatやhtop等でリソースの利用具合を観測</li>
</ul>


<p>計測やコードの理解が出来た時点で新アーキテクチャの設計を3人でディスカッションし、戦略立案。</p>

<p>タイムリミットをいくつか設け、いざ開始！（この時点ではまだ1行も変更してない）</p>

<p>基本戦略としてはMySQLのRedisへの置き換えし、アプリの処理自体を減らしていく方向。チームメイトの2人には実装を担当してもらい、その間に私が既存のMySQLバージョンのチューニングを施し、地味にスコアを上げていく。</p>

<ul>
<li>INDEX追加</li>
<li>MySQL parameter tuning</li>
<li>stylesheetsやjavascriptの直接配信</li>
<li>TCP tuning</li>
<li>File Descriptor上限緩和</li>
<li>unix domain socketの利用</li>
</ul>


<p>合間合間に声をかけ、実装具合や残り時間をチェックし、テンポをとる。</p>

<p>予め決めていた期限である14:00（ソフトリミット）に到達した時点で進捗を確認し、15:00（ハードリミット）までには間に合いそうだったのでそのまま続行を決定。</p>

<p>14:31にredis版が仕上がる！</p>

<p><strong>実装方法</strong></p>

<ul>
<li>初期化スクリプトでMySQLからRedisへ変換</li>
<li>失敗ログインはINCRでカウント</li>
<li>lockとban時にはSADDでSETに追加</li>
<li>SISMEMBERでlock/banの確認</li>
<li>ユーザ個別の履歴はHMSET/HMGETでハッシュ化</li>
<li>/reportはSMEMBERSで出力</li>
</ul>


<h3>後半戦</h3>

<p>Redis版のgit branchに私のコミットをマージし計測。MySQL版よりは多少良いスコア。</p>

<p>mysql version</p>

<pre><code>tag:benchmarker type:score      success:82910   fail:0  score:17910
</code></pre>

<p>redis version</p>

<pre><code>tag:benchmarker type:score      success:87810   fail:318  score:18969
</code></pre>

<p>CPU消費がアプリに移っていたので、後はいかにrubyに処理をさせないかの勝負となる。</p>

<p>ここからやったのは</p>

<ul>
<li>worker loadの最適値模索</li>
<li>パスワードを初期化スクリプト時にオンメモリで持つように改造</li>
<li>パスワードのハッシュ計算除外（ハッシュ計算のスキップは結果的にスコアには影響せず）</li>
<li>トップページのエラーリダイレクトをクエリパラメータ化し、nginxで静的キャッシュ</li>
<li>ログイン部分のlua実装（間に合わず）</li>
</ul>


<p>最後のlua実装は取り掛かったものの、期限までには時間が足りないと判断し断念。かわりに失格とならないように再起動後の正常動作する事を入念に確認。</p>

<p>結局、ハイスコアは<strong>39243</strong>で終了</p>

<pre><code>tag:benchmarker    type:score    success:181670    fail:0    score:39243
</code></pre>

<p>後で気づいたのが最高スコアではなく、最終提出スコアが最終結果となるので誤差により若干下がってしまった。。</p>

<p><strong>戦いの軌跡</strong></p>

<p><img src="https://lh6.googleusercontent.com/VDc46K_BClolTXevFw5IH4W9sS5Z6akC6FIpIAcJhTM=w925-h328-no"></p>

<h3>振り返り</h3>

<ul>
<li>戦略と遂行は概ね正しかったかと</li>
<li>タイムキープ大事</li>
<li>実装は段階的に作ったので大きなバグがなかった</li>
<li>ansible便利（自動化で効率化）</li>
<li>Slackが非常に良かった（特にgithub連携）</li>
<li>VarnishのTシャツ着てたのに使わなかった</li>
<li>access_logを切るのを忘れてた！（offで試した41594だった）</li>
<li>多くのチームが失格となっていたので最終チェックは大事</li>
<li>今回は基本実装が余裕で間に合ったので確実に上達していると実感</li>
</ul>


<h3>復習</h3>

<p>予選終了後、最後に断念したlua化を一人で実装してみた。</p>

<p>/login実装でスコアは<strong>5万超</strong>、/mypageまでやって<strong>6万超</strong>でした。</p>

<pre><code>tag:benchmarker type:report     count:banned ips        value:1043
tag:benchmarker type:report     count:locked users      value:5290
tag:worker      type:fail       reason:Response code should be 201, got 403     method:POST     uri:/results
tag:benchmarker type:fail       message: Score sending failed   reason:Response code should be 201, got 403     method:POST     uri:/results
tag:benchmarker type:score      success:278260  fail:0  score:60108
</code></pre>

<p>その後に、競技中には思いつなかったimageやcssをUser Agent判定で切って（DOM構造は変えずに）みたら<strong>15万超え</strong></p>

<pre><code>tag:benchmarker type:report     count:banned ips        value:3115
tag:benchmarker type:report     count:locked users      value:10426
tag:worker      type:fail       reason:Response code should be 201, got 403     method:POST     uri:/results
tag:benchmarker type:fail       message: Score sending failed   reason:Response code should be 201, got 403     method:POST     uri:/results
tag:benchmarker type:score      success:210324  fail:0  score:155272
</code></pre>

<p>この辺が限界。</p>

<p>うーむ。山形組の<a href="http://nihen.hatenablog.com/entry/2014/10/01/092938">30万超え</a>には程遠いなぁ。恐ろしや。</p>

<h3>最後に</h3>

<p>運営の皆様、ベンチマークツールの<a href="http://isucon.net/archives/40434032.html">不具合</a>やインスタンスガチャの問題等ありましたが、対応方針は非常に納得のいくものでした。引き続き、本戦を楽しみにしています。ありがとうございました！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ConsulによるMySQLフェールオーバー]]></title>
    <link href="http://ijin.github.com/blog/2014/07/11/mysql-failover-with-consul/"/>
    <updated>2014-07-11T10:12:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/07/11/mysql-failover-with-consul</id>
    <content type="html"><![CDATA[<p>先日(6/22/14)、6月なのにどういう分けか早めに開催された<a href="http://2014.techfesta.jp/">July Tech Festa 2014</a>でConsulについて<a href="http://2014.techfesta.jp/p/program.html?m=1#c43">発表</a>してきた。そのユースケースの一つとしてMySQL failoverをちょっとだけ紹介したので、ここに詳しく書いておく。</p>

<h2>MHA</h2>

<p>MySQLレプリケーションの障害時にフェールオーバーしたい場合、MHAを使うの結構ポピュラー（日本では）だと思います。MHAは最新binlogの適用、Slaveの昇格とレプリケーションの張替えまではやってくれますが、実際のフェールオーバーの部分はユーザに委ねられていて、master_ip_failover_scriptのテンプレートをカスタマイズするか独自実装する必要があり、一般的な実現方法としてはカタログデータベースの更新かVirtual IPの切替等があります。</p>

<p>Virtual IPだと居残りセッションの問題や切替の保証難しかったり、そもそも環境によっては使えなかったりするので、私はあんまり好きじゃありません。また以前、後者的アプローチとしてAWSのVPC内であればrouting tableを変更する事によってこの挙動に似た実現方法を<a href="/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication/">紹介</a>した事がありますが、一番の問題点はAPI backplaneがSPoFになってて、ここが落ちたらそもそも動かない；また、APIのrate limitに達して呼び出しさえ出来ないという結構痛い目に会ったりします。</p>

<p>そこで前者的なアプローチとしてmasterの情報を管理するカタログデータベースの更新部分にConsulを使ってみました。</p>

<h2>CONSUL</h2>

<p>ConsulとはHTTP APIとDNSで操作ができる分散型クラスタで、VagrantやSerf等を開発しているHashicorpの新プロダクトです。Key featureは以下のとおり。</p>

<ul>
<li>Service Discovery</li>
<li>Failure Detection</li>
<li>Multi Datacenter</li>
<li>Key/Value Store</li>
</ul>


<h3>ConsulのConsistencyについて</h3>

<p>ConsulはCAP定理でいうCPという特性をもっており、Consistency（一貫性）に重きをおいてあります。Paxosを由来とするRaftをベースにしたconsensus protocolで実現していて、ピアセット内の各サーバノードでlog entryの書き込みがquorumで決定された後にcommitされたと見なされ、FSMに書き込まれます。よって、書き込みに関してはStrongly Consistentな処理となります。読み込みに関しては、パフォーマンス要求に応じてConsistencyレベルをクエリータイプによって調整可能（まるでCassandraのように！）で、Usually Consistent, Strongly Consistent, Staleから選択可能です。DNSベースのクエリーはデフォルトで単一のリーダーノードが返答するのでStrongly Consistentな処理となっています。（Staleにする事も可能）</p>

<h2>ConsulとMHAの連携概要</h2>

<ul>
<li>Consulを内部DNSとして使い、clientはDNSベースでmasterに接続</li>
<li>MySQL masterはAPIで予めサービス名（alias DNS）を登録しておく</li>
<li>mysql_failover_scriptで旧情報の削除と新情報の登録をやる

<ul>
<li>旧master IPを無効化する部分でConsulのCatalog endpointを使ってderegister (/v1/catalog/deregister)</li>
<li>新master ipを登録する部分でConsulのCatalog endpointを使ってregister (/v1/catalog/register)</li>
<li>成功しない限り進まない（exit code check）</li>
</ul>
</li>
<li>削除、及び登録はconsulのconsistency modelによって一貫性は保証される</li>
</ul>


<h2>DEMO</h2>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/rA4hyJ-pccU "></iframe></div></p>

<h2>Notes</h2>

<p>DNSは最新のv0.3.0になってからTTLを設定できるようになったので、Amazon RDSっぽい感じのフェールオーバーも可能ですが、v0.2系に比べて格段にパフォーマンスが向上（スライド参照）したので、デフォルトのTTL 0でも問題ない範囲になってる感じです。また、もうちょっと詳しい内容は今度の<a href="http://connpass.com/event/7322/">#hbstudy</a>で話す予定です。</p>

<h2>スライド</h2>

<p>以下、July Tech Festa 2014で発表した時のスライドです。</p>

<p><script async="true" class="speakerdeck-embed" data-id="e07317d0dc040131a0982229a5c1e016" src="//speakerdeck.com/assets/embed.js"> </script></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[#ChefConf 2014に参加してきた]]></title>
    <link href="http://ijin.github.com/blog/2014/04/21/chefconf-2014/"/>
    <updated>2014-04-21T12:10:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/04/21/chefconf-2014</id>
    <content type="html"><![CDATA[<p>San Franciscoで行われた<a href="http://chefconf.opscode.com/chefconf/">#ChefConf</a>に参加してきました。
忘れないうちに忘備録的に少しメモっておく。</p>

<h2>Day 1</h2>

<h3>Awesome Postmortems by Dave Zwieback</h3>

<p>システム障害に対して素晴らしいPost Mortem（振り返り／報告書）の書き方に関する丸一日のワークショップ</p>

<h4>前半</h4>

<p>まずはチームに分かれて断片的且つ関連性の不明な情報を渡される。
例えば、</p>

<ul>
<li>Tomは紫色の家の住人より短い</li>
<li>Jimは両隣の住人より高い</li>
<li>赤色の家の隣人は子供が5人いる</li>
</ul>


<p>各メンバーは情報を全部開示できないまま、ある不明確なタスクを時間内に完了させる必要がある。しかし、紙やモノを使って情報の整理をしてはならず、口頭による連絡のみなので当然情報は錯綜しタスクは未完のまま終了。</p>

<p>障害時の情報不足・体制不足のシミュレーション。Nosey Neighborsと言うゲームらしい。</p>

<p>その後、お怒りのCEOからDarth Vader風のオーディオ・メッセージで以下を解答せよとのお達しが。。</p>

<ul>
<li>根本原因は何か</li>
<li>何をすれば良かったか</li>
<li>誰の責任か</li>
</ul>


<p>メンバー間で議論して各グループとの比較・プレゼンする</p>

<h4>後半</h4>

<p>パラダイム・シフトとディスカッション形式</p>

<p>以下、メモ</p>

<ul>
<li>たった一つの根本原因は存在しない。システムはimpermanence（非恒久・無常）である。コレに対して誰かが「なんてZenなんだ！」w</li>
<li>そもそもHuman Error（人的エラー）は原因ではなくもっと大きな問題を示すサインであり、症状であり個人やグループのせいにしてはいけない。そうすると簡単で気持ち良いが解決にはならない。80年代の航空会社の事故分析のパラダイム・シフトを引き合いに</li>
<li>Accountability vs Responsibility（個人・グループに責任は負わせないけど説明・報告はさせるべき）</li>
<li>その為にもBlameless（誰かを責める事のないように）でNonpunitive（非罰則）にするべき。火災の消防活動に対する消防隊員の扱いの例が面白かった</li>
<li>Hindsight/Outcome Bias（事後だと情報が多くより物事がより鮮明になるけどそれは偏見である）</li>
<li>Counterfactual（事実に反する。タラレバ）な事を書いてはならない。起こった事は事象は変えられない</li>
<li>3 Rs (Regret, Reason, Remedy)　遺憾を示し、事象のリニアなタイムラインを記載し、解決案の列挙</li>
<li>5 Whys 日本では「なぜなぜ分析」というらしい。要因追求のイテレーティブ・プロセス。</li>
<li>Sharp End vs Blunt End（顕在的エラー vs 潜在的エラー）</li>
<li><a href="https://github.com/etsy/morgue">Morgue</a> - Postmortem用の便利なツール</li>
</ul>


<p>主に組織論やカルチャーの話やDevOpsとの関連性の議論等。今度<em>#トラしゅ</em>に組み込もうかな。</p>

<p>※ <em>山◯君はこっちではボブと呼ばれる</em></p>

<h2>Day 2</h2>

<h3>Keynote</h3>

<ul>
<li>ヘビメタ風のBGM</li>
<li>Barry Crist CEOによるDelightful Economyの熱いプレゼン。Uberの紹介</li>
<li><a href="https://github.com/opscode/chef-metal">Chef Metal</a>の紹介／デモ（DockerやMongoDBで）</li>
<li><a href="http://www.getchef.com/blog/2014/04/15/chef-development-kit/">ChefDK (Chef Development Kit)</a>の紹介</li>
</ul>


<h3>Hunting the DevOps Whale in Large Enterprises</h3>

<ul>
<li>大企業でのDevOpsの話</li>
<li>かなり抽象的でメタファー引用多数</li>
<li>Scrumfall (Scrum + Waterfall)という悪い冗談のような本当にあった怖い話</li>
</ul>


<h3>Spice up your recipes with Chef Sugar</h3>

<p>ChefSpec、Test Kitchen、BerkshelfのコアコミッターであるSeth Vargoによる<a href="https://github.com/sethvargo/chef-sugar"><strong>Chef Sugar</strong></a>の紹介。コードをよりrubyっぽく、より美しくする為のsyntax sugar</p>

<h3>The Berkshelf Vision</h3>

<ul>
<li><a href="http://berkshelf.com/">Berkshelf</a>の原作者であるJamie WinsorによるBerkshelf 3.0の紹介</li>
<li><a href="http://www.getchef.com/blog/2014/04/15/chef-development-kit/">ChefDK</a>でのインストールを推奨</li>
<li>推奨されるべき新しいワークフロー管理や手法について</li>
<li>その補助ツールである<a href="https://github.com/reset/berkflow">Berkflow</a>の説明</li>
<li>このセッションが一番面白かったのでyoutubeに上がったらまた見るべし！</li>
<li><a href="http://www.slideshare.net/resetexistence/chef-conf2014">スライド</a></li>
</ul>


<h3>Implementing Continuous Delivery in Chef</h3>

<p>継続デリバリーのお話。発表者がつまらなかったので、お仕事してた。</p>

<h3>Chef and Docker</h3>

<ul>
<li>Dockerの紹介やロードマップ</li>
<li>実装方法</li>
<li>Chefとの組み合わせ方</li>
<li>2014 2QのDockerConで1.0が発表されるかも</li>
<li>監視に関して突っ込んで質問したら、夏以降に出るであろう監視用コンテナに期待とな</li>
<li>ついでにTシャツもらった</li>
</ul>


<h3>BoF - Chef on AWS</h3>

<ul>
<li>AWS上でのChef利用に関してBoF (Birds of Feather)形式のディスカッション</li>
<li>Cloudformation、Autoscaling、Opsworks、Ohai等</li>
<li>特にOpsworksの使い勝手の悪さを熱く議論してきた</li>
<li>また、OhaiはIAM roleの情報をキャッシュするのでChef Serverとの組み合わせが悪い</li>
<li><a href="https://github.com/balanced-cookbooks/citadel">Citadel</a>というので回避してる人も</li>
</ul>


<h2>Day 3</h2>

<h3>Keynote</h3>

<p>Adam Jacob CTOによるChef社の歴史、思想や方向性やDevOps Cultureについて</p>

<h3>Get Up Again (Over and Over): Learning and Relearning with Chef</h3>

<p>変化への対応、リファクタリング、実験的コードの組み立て方等</p>

<h3>Foreman and Chef Integration</h3>

<p>Red HatによるForemanの発表。あんまり聞いてなかった</p>

<h3>DevOps Culture And Practices To Create Flow</h3>

<ul>
<li>ThoughtworksのJez Humbleによる発表</li>
<li>自動化や継続デリバリーによるリーンな開発手法</li>
<li>トヨタやHPの事例</li>
<li>社内カルチャーの話</li>
<li>Jesse's rule - "Don't fight stupid. Make awesome"</li>
<li>なかなか良いスピーカーであった</li>
</ul>


<h3>その他</h3>

<ul>
<li>アメリカのクライアントやリモートでの仕事仲間と初顔合わせ</li>
<li>ランチで会った人は同じくCassandra構築に苦労してて盛り上がった</li>
<li>Chef Zeroの作者と会って中の動きについてお話した</li>
<li>mizzy氏を発見。立ち話を少々</li>
</ul>

]]></content>
  </entry>
  
</feed>
