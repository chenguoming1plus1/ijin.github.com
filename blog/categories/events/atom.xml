<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: events | @ijin]]></title>
  <link href="http://ijin.github.com/blog/categories/events/atom.xml" rel="self"/>
  <link href="http://ijin.github.com/"/>
  <updated>2014-07-11T10:47:10+09:00</updated>
  <id>http://ijin.github.com/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[ConsulによるMySQLフェールオーバー]]></title>
    <link href="http://ijin.github.com/blog/2014/07/11/mysql-failover-with-consul/"/>
    <updated>2014-07-11T10:12:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/07/11/mysql-failover-with-consul</id>
    <content type="html"><![CDATA[<p>先日(6/22/14)、6月なのにどういう分けか早めに開催された<a href="http://2014.techfesta.jp/">July Tech Festa 2014</a>でConsulについて<a href="http://2014.techfesta.jp/p/program.html?m=1#c43">発表</a>してきた。そのユースケースの一つとしてMySQL failoverをちょっとだけ紹介したので、ここに詳しく書いておく。</p>

<h2>MHA</h2>

<p>MySQLレプリケーションの障害時にフェールオーバーしたい場合、MHAを使うの結構ポピュラー（日本では）だと思います。MHAは最新binlogの適用、Slaveの昇格とレプリケーションの張替えまではやってくれますが、実際のフェールオーバーの部分はユーザに委ねられていて、master_ip_failover_scriptのテンプレートをカスタマイズするか独自実装する必要があり、一般的な実現方法としてはカタログデータベースの更新かVirtual IPの切替等があります。</p>

<p>Virtual IPだと居残りセッションの問題や切替の保証難しかったり、そもそも環境によっては使えなかったりするので、私はあんまり好きじゃありません。また以前、後者的アプローチとしてAWSのVPC内であればrouting tableを変更する事によってこの挙動に似た実現方法を<a href="/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication/">紹介</a>した事がありますが、一番の問題点はAPI backplaneがSPoFになってて、ここが落ちたらそもそも動かない；また、APIのrate limitに達して呼び出しさえ出来ないという結構痛い目に会ったりします。</p>

<p>そこで前者的なアプローチとしてmasterの情報を管理するカタログデータベースの更新部分にConsulを使ってみました。</p>

<h2>CONSUL</h2>

<p>ConsulとはHTTP APIとDNSで操作ができる分散型クラスタで、VagrantやSerf等を開発しているHashicorpの新プロダクトです。Key featureは以下のとおり。</p>

<ul>
<li>Service Discovery</li>
<li>Failure Detection</li>
<li>Multi Datacenter</li>
<li>Key/Value Store</li>
</ul>


<h3>ConsulのConsistencyについて</h3>

<p>ConsulはCAP定理でいうCPという特性をもっており、Consistency（一貫性）に重きをおいてあります。Paxosを由来とするRaftをベースにしたconsensus protocolで実現していて、ピアセット内の各サーバノードでlog entryの書き込みがquorumで決定された後にcommitされたと見なされ、FSMに書き込まれます。よって、書き込みに関してはStrongly Consistentな処理となります。読み込みに関しては、パフォーマンス要求に応じてConsistencyレベルをクエリータイプによって調整可能（まるでCassandraのように！）で、Usually Consistent, Strongly Consistent, Staleから選択可能です。DNSベースのクエリーはデフォルトで単一のリーダーノードが返答するのでStrongly Consistentな処理となっています。（Staleにする事も可能）</p>

<h2>ConsulとMHAの連携概要</h2>

<ul>
<li>Consulを内部DNSとして使い、clientはDNSベースでmasterに接続</li>
<li>MySQL masterはAPIで予めサービス名（alias DNS）を登録しておく</li>
<li>mysql_failover_scriptで旧情報の削除と新情報の登録をやる

<ul>
<li>旧master IPを無効化する部分でConsulのCatalog endpointを使ってderegister (/v1/catalog/deregister)</li>
<li>新master ipを登録する部分でConsulのCatalog endpointを使ってregister (/v1/catalog/register)</li>
<li>成功しない限り進まない（exit code check）</li>
</ul>
</li>
<li>削除、及び登録はconsulのconsistency modelによって一貫性は保証される</li>
</ul>


<h2>DEMO</h2>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/rA4hyJ-pccU "></iframe></div></p>

<h2>Notes</h2>

<p>DNSは最新のv0.3.0になってからTTLを設定できるようになったので、Amazon RDSっぽい感じのフェールオーバーも可能ですが、v0.2系に比べて格段にパフォーマンスが向上（スライド参照）したので、デフォルトのTTL 0でも問題ない範囲になってる感じです。また、もうちょっと詳しい内容は今度の<a href="http://connpass.com/event/7322/">#hbstudy</a>で話す予定です。</p>

<h2>スライド</h2>

<p>以下、July Tech Festa 2014で発表した時のスライドです。</p>

<p><script async="true" class="speakerdeck-embed" data-id="e07317d0dc040131a0982229a5c1e016" src="//speakerdeck.com/assets/embed.js"> </script></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[#ChefConf 2014に参加してきた]]></title>
    <link href="http://ijin.github.com/blog/2014/04/21/chefconf-2014/"/>
    <updated>2014-04-21T12:10:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/04/21/chefconf-2014</id>
    <content type="html"><![CDATA[<p>San Franciscoで行われた<a href="http://chefconf.opscode.com/chefconf/">#ChefConf</a>に参加してきました。
忘れないうちに忘備録的に少しメモっておく。</p>

<h2>Day 1</h2>

<h3>Awesome Postmortems by Dave Zwieback</h3>

<p>システム障害に対して素晴らしいPost Mortem（振り返り／報告書）の書き方に関する丸一日のワークショップ</p>

<h4>前半</h4>

<p>まずはチームに分かれて断片的且つ関連性の不明な情報を渡される。
例えば、</p>

<ul>
<li>Tomは紫色の家の住人より短い</li>
<li>Jimは両隣の住人より高い</li>
<li>赤色の家の隣人は子供が5人いる</li>
</ul>


<p>各メンバーは情報を全部開示できないまま、ある不明確なタスクを時間内に完了させる必要がある。しかし、紙やモノを使って情報の整理をしてはならず、口頭による連絡のみなので当然情報は錯綜しタスクは未完のまま終了。</p>

<p>障害時の情報不足・体制不足のシミュレーション。Nosey Neighborsと言うゲームらしい。</p>

<p>その後、お怒りのCEOからDarth Vader風のオーディオ・メッセージで以下を解答せよとのお達しが。。</p>

<ul>
<li>根本原因は何か</li>
<li>何をすれば良かったか</li>
<li>誰の責任か</li>
</ul>


<p>メンバー間で議論して各グループとの比較・プレゼンする</p>

<h4>後半</h4>

<p>パラダイム・シフトとディスカッション形式</p>

<p>以下、メモ</p>

<ul>
<li>たった一つの根本原因は存在しない。システムはimpermanence（非恒久・無常）である。コレに対して誰かが「なんてZenなんだ！」w</li>
<li>そもそもHuman Error（人的エラー）は原因ではなくもっと大きな問題を示すサインであり、症状であり個人やグループのせいにしてはいけない。そうすると簡単で気持ち良いが解決にはならない。80年代の航空会社の事故分析のパラダイム・シフトを引き合いに</li>
<li>Accountability vs Responsibility（個人・グループに責任は負わせないけど説明・報告はさせるべき）</li>
<li>その為にもBlameless（誰かを責める事のないように）でNonpunitive（非罰則）にするべき。火災の消防活動に対する消防隊員の扱いの例が面白かった</li>
<li>Hindsight/Outcome Bias（事後だと情報が多くより物事がより鮮明になるけどそれは偏見である）</li>
<li>Counterfactual（事実に反する。タラレバ）な事を書いてはならない。起こった事は事象は変えられない</li>
<li>3 Rs (Regret, Reason, Remedy)　遺憾を示し、事象のリニアなタイムラインを記載し、解決案の列挙</li>
<li>5 Whys 日本では「なぜなぜ分析」というらしい。要因追求のイテレーティブ・プロセス。</li>
<li>Sharp End vs Blunt End（顕在的エラー vs 潜在的エラー）</li>
<li><a href="https://github.com/etsy/morgue">Morgue</a> - Postmortem用の便利なツール</li>
</ul>


<p>主に組織論やカルチャーの話やDevOpsとの関連性の議論等。今度<em>#トラしゅ</em>に組み込もうかな。</p>

<p>※ <em>山◯君はこっちではボブと呼ばれる</em></p>

<h2>Day 2</h2>

<h3>Keynote</h3>

<ul>
<li>ヘビメタ風のBGM</li>
<li>Barry Crist CEOによるDelightful Economyの熱いプレゼン。Uberの紹介</li>
<li><a href="https://github.com/opscode/chef-metal">Chef Metal</a>の紹介／デモ（DockerやMongoDBで）</li>
<li><a href="http://www.getchef.com/blog/2014/04/15/chef-development-kit/">ChefDK (Chef Development Kit)</a>の紹介</li>
</ul>


<h3>Hunting the DevOps Whale in Large Enterprises</h3>

<ul>
<li>大企業でのDevOpsの話</li>
<li>かなり抽象的でメタファー引用多数</li>
<li>Scrumfall (Scrum + Waterfall)という悪い冗談のような本当にあった怖い話</li>
</ul>


<h3>Spice up your recipes with Chef Sugar</h3>

<p>ChefSpec、Test Kitchen、BerkshelfのコアコミッターであるSeth Vargoによる<a href="https://github.com/sethvargo/chef-sugar"><strong>Chef Sugar</strong></a>の紹介。コードをよりrubyっぽく、より美しくする為のsyntax sugar</p>

<h3>The Berkshelf Vision</h3>

<ul>
<li><a href="http://berkshelf.com/">Berkshelf</a>の原作者であるJamie WinsorによるBerkshelf 3.0の紹介</li>
<li><a href="http://www.getchef.com/blog/2014/04/15/chef-development-kit/">ChefDK</a>でのインストールを推奨</li>
<li>推奨されるべき新しいワークフロー管理や手法について</li>
<li>その補助ツールである<a href="https://github.com/reset/berkflow">Berkflow</a>の説明</li>
<li>このセッションが一番面白かったのでyoutubeに上がったらまた見るべし！</li>
<li><a href="http://www.slideshare.net/resetexistence/chef-conf2014">スライド</a></li>
</ul>


<h3>Implementing Continuous Delivery in Chef</h3>

<p>継続デリバリーのお話。発表者がつまらなかったので、お仕事してた。</p>

<h3>Chef and Docker</h3>

<ul>
<li>Dockerの紹介やロードマップ</li>
<li>実装方法</li>
<li>Chefとの組み合わせ方</li>
<li>2014 2QのDockerConで1.0が発表されるかも</li>
<li>監視に関して突っ込んで質問したら、夏以降に出るであろう監視用コンテナに期待とな</li>
<li>ついでにTシャツもらった</li>
</ul>


<h3>BoF - Chef on AWS</h3>

<ul>
<li>AWS上でのChef利用に関してBoF (Birds of Feather)形式のディスカッション</li>
<li>Cloudformation、Autoscaling、Opsworks、Ohai等</li>
<li>特にOpsworksの使い勝手の悪さを熱く議論してきた</li>
<li>また、OhaiはIAM roleの情報をキャッシュするのでChef Serverとの組み合わせが悪い</li>
<li><a href="https://github.com/balanced-cookbooks/citadel">Citadel</a>というので回避してる人も</li>
</ul>


<h2>Day 3</h2>

<h3>Keynote</h3>

<p>Adam Jacob CTOによるChef社の歴史、思想や方向性やDevOps Cultureについて</p>

<h3>Get Up Again (Over and Over): Learning and Relearning with Chef</h3>

<p>変化への対応、リファクタリング、実験的コードの組み立て方等</p>

<h3>Foreman and Chef Integration</h3>

<p>Red HatによるForemanの発表。あんまり聞いてなかった</p>

<h3>DevOps Culture And Practices To Create Flow</h3>

<ul>
<li>ThoughtworksのJez Humbleによる発表</li>
<li>自動化や継続デリバリーによるリーンな開発手法</li>
<li>トヨタやHPの事例</li>
<li>社内カルチャーの話</li>
<li>Jesse's rule - "Don't fight stupid. Make awesome"</li>
<li>なかなか良いスピーカーであった</li>
</ul>


<h3>その他</h3>

<ul>
<li>アメリカのクライアントやリモートでの仕事仲間と初顔合わせ</li>
<li>ランチで会った人は同じくCassandra構築に苦労してて盛り上がった</li>
<li>Chef Zeroの作者と会って中の動きについてお話した</li>
<li>mizzy氏を発見。立ち話を少々</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Game Day Japan 2014春を開催してきた]]></title>
    <link href="http://ijin.github.com/blog/2014/03/14/aws-game-day-japan-2014-spring/"/>
    <updated>2014-03-14T23:11:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/03/14/aws-game-day-japan-2014-spring</id>
    <content type="html"><![CDATA[<p>過去に2度参加した事（東京・ラスベガス）がある<a href="/blog/2013/06/10/aws-game-day-tokyo-2013/">Game Day</a>に今回は運営側に周りました。3/15に行われる<a href="http://jawsdays2014.jaws-ug.jp/">JAWS Days 2014</a>の前夜祭という位置づけです。</p>

<p>日本では前回、東京のみだったけど<a href="http://jaws-days.doorkeeper.jp/events/8945">今回</a>は東京・大阪・名古屋・仙台と4都市同時開催。</p>

<h2>お題</h2>

<p>前回と全く一緒。。SQSを使った疎結合でオートスケーリングする画像変換処理システム（ｻｰｾﾝ）。まあ、1年前と比べてAWSの機能やできる事も大分変わったので2回目の人もいろいろ工夫のしようがあったかと。</p>

<h2>チーム</h2>

<p>1チーム3〜4人に別れて計14チームとなりました。</p>

<p><strong>東京</strong></p>

<ul>
<li>Cookie Devil</li>
<li>Bluescreens</li>
<li>沖縄</li>
<li>Blue Light of Death</li>
<li>時計じかけのオレンジ</li>
<li>I am みどり</li>
</ul>


<p><strong>名古屋</strong></p>

<ul>
<li>Shachihoko</li>
<li>ななちゃんだがや</li>
<li>ゴーゴーひつまぶし</li>
</ul>


<p><strong>大阪</strong></p>

<ul>
<li>大都会</li>
<li>AWS学坊や</li>
<li>初心者</li>
</ul>


<p><strong>仙台</strong></p>

<ul>
<li>Zao</li>
<li>八重の桜</li>
</ul>


<h2>内容</h2>

<p>当日の迫力ある詳しい内容は参加者の方がきっとブログに書いてくれるはず！その代わり、運営側で評価用に使っていた攻撃・修復内容のまとめを公開して欲しいというツィートを頂いたので下記に表示しておきます。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p>Gameday楽しめました。運営ありがとうございました。攻撃のサマリシート翻訳は誰?と思ってましたが恐縮です。あのシート何らかの形で公開頂けるとありがたいです。 QT <a href="https://twitter.com/ijin">@ijin</a>: 14チームのGoogleスプレッドシートのリアルタイム翻訳は結構ギリギリだった。</p>&mdash; Ryo Suzuki (@suzryo) <a href="https://twitter.com/suzryo/statuses/444450014627000320">March 14, 2014</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>（実は今回もイベントオーナーのMiles Wardが来日していたので、Google Spreadsheetに書き込まれていた内容を運営側で逐一翻訳していました）</p>

<iframe src="https://docs.google.com/spreadsheets/d/16-qSbw_XQGgl_4bYqy9REL-nq15yOVj2f1HBJvMy_qM/pubhtml?widget=true&amp;headers=false" height="500" width="750"></iframe>


<p>個人的にはs3の「Requester Payオプション有効化」がお気に入りでしたね。</p>

<h2>結果</h2>

<p>総合優勝はチーム<strong>「AWS学坊や」</strong>の優勝となりました。おめでとうございます！
（地方賞はすみません、総合結果評議中で聞けてませんでした）</p>

<p>今回、運営側のトラブルで攻撃対象が重複してしまう等いろいろ問題がありましたが、開催する側としても楽しかったです。次回はさらにチャレンジングな内容にしていきたいと思っています。</p>

<h2>JAWS DAYS</h2>

<p>明日の<a href="http://jawsdays2014.jaws-ug.jp/">JAWS DAYS 2014</a>はスタッフとしていろいろ動くので今回は手短に。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[サバフェス！2013に参加してきた]]></title>
    <link href="http://ijin.github.com/blog/2013/12/13/serverfesta-2013-autumn/"/>
    <updated>2013-12-13T15:59:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/12/13/serverfesta-2013-autumn</id>
    <content type="html"><![CDATA[<p>少し前に<a href="http://connpass.com/event/3690/">サバフェス！2013 Autumn</a>に参加してきました。
内容を忘れないうちにやった事を書いておきます。</p>

<p>スコアはトップレベルだったものの、運営側がサーバを起動した所、自動でサービスが立ち上がらなかったらしいので残念な事に参考値のみに。（提出前に2回ぐらい再起動確認したのにおかしいなぁ。。）
優勝スコアは90.830 (GET 199,802 : POST 18,106)で、私のは<strong>93.410</strong> (GET 162,923 : POST 29,930)でした。</p>

<h2>お題</h2>

<p>「最速インフラを構築せよ！！！</p>

<p>WordPressに一切手を加えずに、どこまで高速化できるのか！？</p>

<p>OSチューニング、サーバチューニング、負荷分散…最適解を探せ！」</p>

<p>--</p>

<p><a href="http://www.idcf.jp/cloud/service/self.html">IDCFクラウド</a>上で仮想マシン5台（M8タイプまで）を使ってスコアを競うというもの。
<a href="https://www.facebook.com/tuningathon">チューニンガソン</a>と似てますが、サーバが複数台使えるのが良いですね。</p>

<h2>構成</h2>

<p>表彰式でLTしたけど、LVS (DSR) + php 5.5 + apcu + Varnish + nginx (lua) + memcached</p>

<p>ポイントは</p>

<ul>
<li>GET時は1台では帯域の限界に達したのでLVS (DSR)による4台での並列応答</li>
<li>POST時には必ず各Varnishのキャッシュクリア（ban）する</li>
<li>POST時にnginx->memcachedへ渡すと高速すぎたのであえてsleepを5msして遅延させる</li>
<li>nginx(lua)はコード量が多いと通らないのでぎりぎりまで削減</li>
<li>memcachedからmysqlへの非同期処理（5ms間隔）</li>
<li>mysqlの更新処理はそんなにいらないので基本チューニングとInnoDBにしただけで、5.1のまま</li>
<li>サーバはM8までいらないのでM4で</li>
<li>海外から参戦したけど、GUIが重いのでAPI経由での操作</li>
</ul>


<p>でしょうか。特に意識したのはmemcachedからmysqlへの許容範囲内での同期と複数台あるVarnishのキャッシュクリアですね。他のチームはnginxでTTLを設定して逃げたようですが、実運用時にはPOST時にキャッシュクリアを確実にする必要があるのでVarnish moduleをコンパイルして他のsiblingへ並列でban処理を投げてました。まあ、今回のベンチマークツールはそこまで厳格じゃなかったけど、最終チェックは人間が動作させるので。</p>

<p>LT資料。スコア推移と簡単な構成の紹介
<div class="embed-ss-container"><iframe src="http://www.slideshare.net/slideshow/embed_code/29171459 "></iframe></div></p>

<h2>設定ファイル</h2>

<p>以下、設定ファイルです。いらない所は削ったけど動くはず。。</p>

<p>backend varnish vcl （各backendの設定は微妙に違う）:
<div><script src='https://gist.github.com/7941009.js?file='></script>
<noscript><pre><code>&lt;html&gt;&lt;body&gt;You are being &lt;a href=&quot;https://github.com/gist/7941009&quot;&gt;redirected&lt;/a&gt;.&lt;/body&gt;&lt;/html&gt;</code></pre></noscript></div>
</p>

<p>backend nginx.conf:
<div><script src='https://gist.github.com/7940999.js?file='></script>
<noscript><pre><code>&lt;html&gt;&lt;body&gt;You are being &lt;a href=&quot;https://github.com/gist/7940999&quot;&gt;redirected&lt;/a&gt;.&lt;/body&gt;&lt;/html&gt;</code></pre></noscript></div>
</p>

<p>base nginx.conf:
<div><script src='https://gist.github.com/7941214.js?file='></script>
<noscript><pre><code>&lt;html&gt;&lt;body&gt;You are being &lt;a href=&quot;https://github.com/gist/7941214&quot;&gt;redirected&lt;/a&gt;.&lt;/body&gt;&lt;/html&gt;</code></pre></noscript></div>
</p>

<p>base syncer.rb:
<div><script src='https://gist.github.com/7941042.js?file='></script>
<noscript><pre><code>&lt;html&gt;&lt;body&gt;You are being &lt;a href=&quot;https://github.com/gist/7941042&quot;&gt;redirected&lt;/a&gt;.&lt;/body&gt;&lt;/html&gt;</code></pre></noscript></div>
</p>

<p>base supervisord.conf:
<code>
[program:syncer]
command=/home/mho/.rvm/bin/ruby /home/mho/syncer/sync.rb 5
stdout_logfile_maxbytes=1MB
stderr_logfile_maxbytes=1MB
stdout_logfile=/tmp/%(program_name)s-stdout.log
stderr_logfile=/tmp/%(program_name)s-stderr.log
user=mho
directory=/home/mho/syncer
autostart=true
autorestart=true
</code></p>

<p>base my.cnf:
```
[mysqld]
datadir=/var/lib/mysql
socket=/var/lib/mysql/mysql.sock
user=mysql</p>

<h1>Disabling symbolic-links is recommended to prevent assorted security risks</h1>

<p>symbolic-links=0
character-set-server = utf8
max_connections = 1000</p>

<p>key_buffer_size = 32M
max_allowed_packet = 16M
thread_stack = 192K
thread_cache_size  = 200</p>

<h1>slow_query_log=1</h1>

<h1>long_query_time=0</h1>

<p>query_cache_type = 0
skip-innodb_doublewrite
innodb_buffer_pool_size = 192M
innodb_log_buffer_size = 4M
innodb_flush_log_at_trx_commit = 0
innodb_support_xa = 0
```</p>

<p>sysctl.conf:
```
fs.file-max = 1048576</p>

<p>net.ipv4.ip_local_port_range = 1024 65535</p>

<p>net.core.wmem_max = 16777216
net.core.rmem_max = 16777216</p>

<p>net.ipv4.tcp_wmem = 4096 65536 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216</p>

<p>net.core.somaxconn = 8192</p>

<p>net.core.netdev_max_backlog = 8000</p>

<p>net.ipv4.tcp_max_syn_backlog = 8192</p>

<p>net.ipv4.tcp_synack_retries = 3
net.ipv4.tcp_retries2 = 5</p>

<p>net.ipv4.tcp_keepalive_time = 900</p>

<p>net.ipv4.tcp_keepalive_probes = 3</p>

<p>net.ipv4.tcp_keepalive_intvl = 15</p>

<p>net.nf_conntrack_max = 1000000
```</p>

<h2>終わりに</h2>

<p>最初はecho選手権になってたのであんまりやる気がなかったけど、後半はちょっと楽しめました。結果は惜しかったけど、今まで<a href="https://www.facebook.com/tuningathon">チューニンガソン</a>や<a href="http://isucon.net">ISUCON</a>に出場したり、トラブル☆しゅーたーずを主催したり、日々の運用等の経験が生きた感じがします。運営の皆様、ありがとうございました。次があれば楽しみにしています！（レギュレーションの解釈が微妙だったのでそこはブラッシュアップして欲しいですね）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ISUCON3の本戦に参加してきた]]></title>
    <link href="http://ijin.github.com/blog/2013/11/11/isucon3-final/"/>
    <updated>2013-11-11T11:27:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/11/11/isucon3-final</id>
    <content type="html"><![CDATA[<p>先月の<a href="http://ijin.github.io/blog/2013/10/07/isucon3-preliminary/">予選に通過したの</a>で、<a href="http://isucon.net/">ISUCON3</a>の本戦に参加してきました。</p>

<p>完敗。</p>

<h3>お題発表</h3>

<p>画像版twitter。投稿する画像の公開レベルをpublic, private, followers onlyに設定できるシステムが1台のVPS（2コア、4GB RAM）で動いている状態。プレスを打った為、大量アクセスがくる18時までに別途用意された4台のサーバを使ってスケールせよという使命を与えられる。</p>

<h3>流れ</h3>

<p>画像データが1万点・約3GBあったので、まず失敗しても戻れるようにバックアップ取得を開始。それと平行して他のサーバへのsshキー登録したり、hosts書いたり、もろもろ下準備。</p>

<p>デフォルトのperlのスコアは<strong>1206.8</strong></p>

<p>言語はrubyと決めていたので、supervisorで立ち上げてみるが起動失敗。よくよく調べてみるとforemanが入ってなくてGemfileに追加してbundle。</p>

<p>この時のスコアが<strong>1180.8</strong></p>

<p>次にデータベースを見てみるものの、レコード数も比較的少なく、総容量が2MBもないのでできる事は限定されていると判断。クエリーをさらっと見た後にentriesのimageカラムに対してインデックスを張ったぐらい。</p>

<p>アクセスログにレスポンスタイムを出力するようにして1回ベンチを走らせログを解析。</p>

<p>ブラウザ上の挙動を確認しつつ、ソースコードを読んで結局画像変換のconvert処理が一番重そうだったのでそこから着手することに。</p>

<p>予選の時も外部プログラムを呼んでいるところが改善ポイントの一つだったので、まずfastimage_resizeを使って置き換えてみるものの、処理速度はそんなに上がらず、スコアもほぼ横ばい。</p>

<p>その間に、ロングポーリングの処理を変更してみるけど、</p>

<pre><code> "message": "2013-11-09T14:48:17 [36898] [CRITICAL] timeline refrection timeout"
</code></pre>

<p>タイムラインの反映がうまくいってない模様。
（ちなみにエラーメッセージのrefrectionはreflectionのスペルミスですね）</p>

<p>次に画像変換処理の部分で毎回リクエストがくる度に実行されるリンクをredisにてキャッシュ。これは効果があり、スコアは<strong>6634.2</strong>で暫定3位。</p>

<p>その間にVarnishやHaproxy + nfsを軽ーく試してみるものの、スコアは伸びず。</p>

<p>この辺でリンクだけではなく、画像自体をredisに突っ込んで全サーバで処理するアーキテクチャを決定。<a href="https://twitter.com/acidlemon">@acidlemon</a>さんと似た<a href="http://beatsync.net/main/log20131110.html">構成</a>ですね。ただ違うのはPOST後のsidekiqを使って処理を裏のワーカーに任せるという事。</p>

<p>sidekiqが動作するところまではでき、全画像の変換を試みるがredisサーバのメモリが溢れてたので、最初にアクセスされる直近30件、アクセス比率が高いサイズsと、新規画像のみに注力。スコアは徐々に上がる。</p>

<p>その後はただひたすらに、もくもく実装とデバッグ。</p>

<p>残り3-40分ぐらいのところで、生ハムチームでブレークスルーが起こり、彼らが一気にトップへ踊り出る。我々も1台構成であれば5位ぐらいにはなれただろうけど、スケールアウトしなければ全く勝負にならないので最後の最後まで果敢に挑戦するもあえなくタイムアップ。</p>

<p>結果、FAIL。</p>

<h3>感想</h3>

<p>今回はサーバが5台もあったので、スケールアウトしなければならないのは明白で、実装を真っ先に着手するべきでしたね。前半で1台だけチューニングして後でスケールしようと思ったのが戦略上の致命的ミス。時間切れで終わったので実装が間に合っていたらそれなりのスコアが出たはずかと。優勝した生ハムチームが結構ギリギリまでかかったのを考えると、やはり見極めたポイントは重要で、さすがとしか言いようがないです。また、一番時間のかかった画像配信に関しては普段AWSを使っている身としてはs3へ画像を突っ込むのが当然だと考えていたので、なかなか新鮮で違う脳を使う感じで楽しめました。</p>

<h3>その他</h3>

<ul>
<li>途中ディスカッションをすれば良かった（予選は上々でも本戦で焦ってしまった）</li>
<li>落ち着いて俯瞰して見るべし。見極め大事</li>
<li>予選とかの先入観が邪魔したのでまっさらの状態で考えるべき</li>
<li>ベンチマークツールはFAILしても再実行に2分待たされるのがどうしてももどかしかった</li>
<li>ベンチマークツールの他のサーバへの実行切替がバグってて時間をロスった</li>
<li>チーム名のRevengeが果たせなかったので、来年はチーム名どうしようかな。。</li>
<li>ドヤモリスが満面の笑みで幸せそうだった</li>
</ul>


<p>ISUCONのレベルも毎回毎回レベルが上がっていき、運営側の苦労が伺えます。本当にお疲れ様でした！また来年にも期待しています！</p>

<h3>おまけ</h3>

<p>さて。1年間待ち望んだイベントがあっという間に終わってしまって消失感・焦燥感を味わいつつも、気を取り直して次はAWS re:InventのGAMEDAYに日本から唯一（多分）の参加者として参戦します！</p>
]]></content>
  </entry>
  
</feed>
