<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: aws | @ijin]]></title>
  <link href="http://ijin.github.io/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://ijin.github.io/"/>
  <updated>2015-10-26T16:29:05+09:00</updated>
  <id>http://ijin.github.io/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS re:Invent 2015に参加してきた]]></title>
    <link href="http://ijin.github.io/blog/2015/10/26/aws-re-invent-2015/"/>
    <updated>2015-10-26T02:26:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/10/26/aws-re-invent-2015</id>
    <content type="html"><![CDATA[<p>今年で3度目の参加となるAWS re:Invent。
忘れない内に記録を残しておきます。</p>

<h2>Day 0</h2>

<h3>Game Day</h3>

<p>Unicornを貸し出すサービスを展開する仮想のスタートアップ企業にDevOpsチームとして最近入社したという設定。前任者が退職しており、資料が少ない中でサービスオープンに立ち会いつつ、様々な困難に直面するというフルデイ・イベント。
今までのGame Dayと違って面白いのはパフォーマンス・チューニングをしつつも、コストも意識しながらチーム間でスコアを競争するところ。アプリは触れないので、<a href="http://isucon.net/">ISUCON</a>よりは昔やった<a href="/blog/2012/07/03/tuningathon4/">チューニンガソン</a>に近い感じ。</p>

<p>スコアは累積の損益。アーキテクチャによっては利益が出たり損失が出たりする。例えば、多くのリクエストが処理できると利益は増すが、AWSのリソースが多いと費用が掛かって損失になりうる。
当然最初は各チームは赤字から始まり、時間とともに積算した利益によって黒転して行く様が目新しかった。</p>

<p>結果、48チーム中で<strong>6位</strong>。（上位2チームはチートで失格となったので<strong>実質は4位</strong>）</p>

<p><img src="https://lh3.googleusercontent.com/H8zoy7lrftuIo9ZQTN_LsUC3KsiGsNkOJbPzuW4vAxy4o6IOAH8=w547-h298-no"></p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://twitter.com/ijin">@ijin</a> <a href="https://twitter.com/AWSreInvent">@AWSreInvent</a> the rabbit icon was awarded to the team with the fastest response time to a request.0.0005s is not too shabby!</p>&mdash; Kyle Lichtenberg (@KyleLichtenberg) <a href="https://twitter.com/KyleLichtenberg/status/651573816301219840">October 7, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>ちなみに最速レスポンスタイムはうちのチームが叩きだした。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our team - &quot;Ubercon&quot;! <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a> <a href="https://twitter.com/hashtag/AWSGameDay?src=hash">#AWSGameDay</a> <a href="http://t.co/dpRu1vicgM">pic.twitter.com/dpRu1vicgM</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/651544851620700160">October 6, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>詳細は今度日本で開催されるかも知れないので控えておくが、非常に楽しめたので次回は運営側に回って手伝おうかと思います！</p>

<h2>Day 1</h2>

<h3>Keynote</h3>

<p>Andy Jessy副社長による発表。今年のテーマは「<strong>自由</strong>」</p>

<ul>
<li>Amazon QuickSight</li>
<li>Amazon Kinesis Firehose</li>
<li>Amazon Snowball</li>
<li>MariaDB for RDS</li>
<li>AWS Database Migration Service</li>
<li>AWS Schema Conversion Tool</li>
<li>AWS Config Rules</li>
<li>Amazon Inspector</li>
</ul>


<p><img src="https://lh3.googleusercontent.com/SSI_hMC3cjzUSvGPxT49FD26VBeY_QYt_qGoTLDPo8nBLwdmglM=w493-h544-no"></p>

<p><del>Oracle</del>からの自由、解放！</p>

<h3>WRK306 - AWS Professional Services Architecting Workshop</h3>

<p>実在した、ある企業のクラウド移行案件。RFP的なモノがあり、アーキテクチャをチーム内で議論し、最後にそれぞれ各チームが発表していく流れ。
かつてjawsugで主催を手伝ったワールドカフェ形式とほぼ同じだったので、チームメンバーを先導してCacooでさくさく構成図を起こしていく。
他のチームが模造紙にラフスケッチで発表する中、我らは綺麗に正本して、プロジェクターで登壇しながら発表。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">ワークショップはうちらのチームだけCacooで図を書いたので制覇した感がある。 <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/651869691699425281">October 7, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>最後に実際にどう移行したかというAWSチームからの回答。まず、移行フェーズを段階的に分け、最初はシステムをほぼそのままクラウド上に乗せた後に部分的に最適化してコンポーネントを置き換えて行ったという話。最後にLambdaになっていた部分があったのが興味深かった。</p>

<p>早く新サービスに対応したAWS Simple Iconsのアップデートが待たれるところ。</p>

<p><img src="https://lh3.googleusercontent.com/IVrSN7g0MnAfVa6pB4ajQWUZYPmpFMOH6Ych-FedX1HqxCfEHtc=w583-h346-no"></p>

<p>今回提案した内容。</p>

<h3>WRK305 - Zombie Apocalypse Survival: Building Serverless Microservices</h3>

<p><a href="https://ja.wikipedia.org/wiki/%E3%82%BE%E3%83%B3%E3%83%93%E3%81%AB%E3%82%88%E3%82%8B%E4%B8%96%E7%95%8C%E3%81%AE%E7%B5%82%E6%9C%AB">Zombie Apocalypse</a>が起こって、人類存亡の危機！途中まで実装されたチャットルームの機能を拡張・実装して危機を救え！というシナリオの元、LambdaとAPI Gatewayとjavascript sdkで実装されたサーバーレスアーキテクチャのワークショップ。</p>

<p>機能拡張の為に実装が必要なので、設計しながらチーム内で作業分担し、コードをせっせと書いていく。
ゾンビ出現のアラート通知、ヒートマップ描画、アンデッドカウンター、緊急食料倉庫の位置情報配信等、面白い機能要求が盛り沢山。</p>

<p><img src="https://lh3.googleusercontent.com/-UStcIzDdtS42SZTgt657iKvYHWlbcfktbvuCq3-LIioBfrBzgI=w600-h346-no"></p>

<p>ささっとSlack部屋を作り、githubでコードを共有しながらのチームワーク作業。多分、うちらのチームが一番多く実装できた感触。</p>

<p><img src="https://lh3.googleusercontent.com/WZ7nUMvRhoNzixWqjEdCFJ1wJqNH-BqjV4M4cq93mBXBnJ8UPOk=w493-h544-no"></p>

<p>このワークショップはかなりの人気で、開始30分前にすでに長蛇の列が。
運良くぎりぎり最後の参加者として入れたけど、皆どれだけゾンビが好きなんだ。。</p>

<h2>Day 2</h2>

<h3>Keynote</h3>

<p>Wernerl Vogels CTOの発表。</p>

<ul>
<li>Amazon Kinesis Analytics</li>
<li>X1 instance (100 cores, 1TB RAM)</li>
<li>t2.nano instance</li>
<li>Amazon EC2 Container Registry</li>
<li>Lambda

<ul>
<li>VPC support</li>
<li>Long running Functions (300s)</li>
<li>Scheduled Functions</li>
<li>Custom Retry Logic</li>
<li>Python</li>
</ul>
</li>
<li>AWS IOT</li>
</ul>


<p><img src="https://lh3.googleusercontent.com/A4p3UvP0JiMxjpZF7L0zxdMFkU96aOYtZ-BExM2zFERDsebakXw=w493-h543-no"></p>

<p>前日にAndyが7つの自由を語って、当日はWernerが7つの法則を語る。</p>

<h3>WRK308 - AWS + ASK: Teaching Amazon Echo New Skills</h3>

<p>Amazon Echoを使った、Alexaのプログラミングワークショップ。音声によって、Echo経由でLambdaイベントを呼び出し、Alexaサービスと連携するカスタマイズしたスキルセットを実装して行く。</p>

<p>例えば、Alexaに好きな色を覚えさせて、後ほど聞くと答えてくれる機能とか。全てボイスコントロール。<a href="http://yoshidashingo.hatenablog.com/?page=1445224481">吉田さんの英語でも通じた</a>ので、かなり優秀。</p>

<p>新品のEchoを開封して使ったので、最後に貰える物かとささやかに期待したものの、$15のAWSクーポン配布のみ。さすがFrugalなAmazonさん。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">Alexaとlambdaが連携してEchoが喋った！ <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a> <a href="http://t.co/V6QpNyj3tK">pic.twitter.com/V6QpNyj3tK</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/652234646231646208">October 8, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">Alexは今ユーザ駆動にしか対応してないけど、awsのイベント駆動はtop priorityとの事。そのうち例えばbilling alertを音声で通知できるようになるなぁ。楽しみだ。 <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/652239936968654848">October 8, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<h3>re:Play</h3>

<p>EDMの若きプリンスDJ、Zeddをシークレットゲストとして呼んでのアフター。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="en" dir="ltr">What a view for this secret <a href="https://twitter.com/Zedd">@zedd</a> show, this crowd does not end! <a href="https://twitter.com/hashtag/vegas?src=hash">#vegas</a> <a href="http://t.co/0Itv012o0k">pic.twitter.com/0Itv012o0k</a></p>&mdash; Rukes (@rukes) <a href="https://twitter.com/rukes/status/652400784353595392">October 9, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>もう完全にWernerのパーティー。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">昨夜の <a href="https://twitter.com/hashtag/replay?src=hash">#replay</a> でこの積み上がったコンテナを見て、Docker Swarm を連想した人はさぞ多かったに違いない。 <a href="http://t.co/QxF2MkbHTi">pic.twitter.com/QxF2MkbHTi</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/652681828441063425">October 10, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/cT676BMT7A8 "></iframe></div></p>

<p>Zeldaのremixが良かった。</p>

<h3>終わりに</h3>

<p>結局セッションは一つも出なかったです。まあ、ビデオやスライドは公開されるので内容自体は後で把握可能なので別にいいかな。授業を聞きに来た分けでもないし。
それよりも、現地に来ているエンジニアと交流したり、実装まで含んだハンズオンのワークショップをやった方が楽しいし、糧となる。後はトレンドを肌感覚として体感すには良い場所なので行った事ない人には是非オススメしておきたい。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GitHubのeventをLambdaで処理してSlackへ通知]]></title>
    <link href="http://ijin.github.io/blog/2015/08/06/github-to-lambda-to-slack/"/>
    <updated>2015-08-06T01:46:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/08/06/github-to-lambda-to-slack</id>
    <content type="html"><![CDATA[<p>ちょっと前にGitHubのeventを<a href="https://aws.amazon.com/lambda/">AWS Lambda</a>で処理して、GitHubやSlackのAPIを叩く仕組みを作ったので、メモ。</p>

<p>材料</p>

<ul>
<li>Github</li>
<li>SNS</li>
<li>KMS</li>
<li>Lambda</li>
<li>Slack</li>
</ul>


<p>やりたいことはこんな感じ。</p>

<p><img src="https://lh3.googleusercontent.com/CZE1yk0yqzlizL0aK5xNBVTupVovIZCPhwp3CWwxOyc=w548-h334-no"></p>

<p>あるGitHubリポジトリのissuesに特定のコメントが書き込まれると、そのユーザはプロジェクトのteamに自動で追加されて、Slackへ通知が流れるというモノです。</p>

<h2>SNS</h2>

<p>まずは媒介となるSNSの作成。
```
$ aws sns create-topic --name github --region ap-northeast-1
{</p>

<pre><code>"TopicArn": "arn:aws:sns:ap-northeast-1:123456789012:github"
</code></pre>

<p>}
```</p>

<p>次にSNSに対してpublishできるIAM userを作成</p>

<p>IAM Policy
```
{
  "Version": "2012-10-17",
  "Statement": [</p>

<pre><code>{
  "Action": [
    "sns:Publish"
  ],
  "Sid": "Stmt0000000000000",
  "Resource": [
    "arn:aws:sns:ap-northeast-1:123456789012:github"
  ],
  "Effect": "Allow"
}
</code></pre>

<p>  ]
}
```</p>

<h2>GitHub</h2>

<ul>
<li>organization: <code>my_org</code></li>
<li>repository: <code>test</code></li>
<li>team: <code>reader</code></li>
</ul>


<h3>SNS連携</h3>

<p><em>Webhooks &amp; Services</em> からAmazonSNSと連携</p>

<p><img src="https://lh3.googleusercontent.com/u4I9Z_Ing9YzhmVCQhMACwYDVIJxJM7C-aDmyMsNL3o=w328-h190-no"></p>

<p>AWS KEYには先ほど作成したIAMユーザのを利用。SNS topicのarnにはregionが書かれているにも関わらず、GitHubの方では明示的に指定が必要。</p>

<p><img src="https://lh3.googleusercontent.com/kppZQx_RdhyC11LB7a0cPtppDUiKgfZBm6laYvRG3zA=w382-h289-no"></p>

<h3>通知するeventの有効化</h3>

<p>さて、GitHubではSNSの場合、<a href="https://api.github.com/hooks">hooksのjson</a>にある通り、<code>push</code>時のeventにしか対応していないので、</p>

<p><code>json hooks https://api.github.com/hooks
"name": "amazonsns",
"events": [
  "push"
],
</code></p>

<p>GitHubの<a href="https://developer.github.com/v3/orgs/hooks/">Webhook API</a>に従って<code>issue_comment</code>を追加してやります。</p>

<p>先ほどのSNS連携のhook idを取得するには<code>GET /orgs/:org/hooks</code></p>

<p><code>bash
export HOOK_ID=$(curl -H 'Uer-Agent: ijin' -X GET -s -H "Authorization: token xxxxxxxxxx" \
https://api.github.com/repos/my_org/test/hooks | jq '.[].id')
</code></p>

<p>編集するには<code>PATCH /orgs/:org/hooks/:id</code></p>

<p><code>bash
curl -H 'Uer-Agent: ijin' -X PATCH -s -H "Authorization: token xxxxxxxxxx" \
https://api.github.com/repos/my_org/test/hooks/$HOOK_ID -d '{"add_events": ["issue_comment"]}' | jq .
</code></p>

<p>Web UIからは分からないので、ついでに<code>reader</code> teamのIDも取得しておく</p>

<p><code>bash
curl -H 'Uer-Agent: ijin' -X GET -s -H "Authorization: token xxxxxxxxxx" \
https://api.github.com/orgs/my_org/teams | jq '.[] | select(.name=="reader")'
</code></p>

<p>（※）User-Agentは<a href="https://developer.github.com/v3/#user-agent-required">必須</a></p>

<p>これで、誰かがコメントをした時にもSNSが飛びます。</p>

<h2>KMS</h2>

<p>lambdaでは以下の認証情報を使うので、予めKMSで暗号化しておく。</p>

<ul>
<li>GitHub token</li>
<li>Slack webhook</li>
</ul>


<p>rubyで暗号化する場合
<code>ruby
require 'aws-sdk'
require 'base64'
kms = Aws::KMS::Client.new(region: 'us-east-1')
Base64.encode64 kms.encrypt(key_id: "alias/ijin", plaintext: 'my plain text code').ciphertext_blob
</code></p>

<p>javascriptの場合
<code>javascript
var aws = require('aws-sdk');
var kms = new aws.KMS({ region: 'us-east-1' });
var text = 'my plain text code';
kms.encrypt({KeyId: 'alias/ijin', Plaintext: text}, function(err, data) {
  if (err) console.log(err, err.stack);
  else console.log(data.CiphertextBlob.toString('base64'));
});
</code></p>

<p>こうしておくと、SCMに入れても安心。</p>

<p>また、KMSキーの実行権限もlambdaのroleに紐づけておく。</p>

<p><img src="https://lh3.googleusercontent.com/oMHQ76XC7RQUCR_fEo9JyaMhPKSbnIdhCzjIWurEJ9c=w542-h358-no"></p>

<h2>Lambda</h2>

<p>Lambda function作成時にはSNSをevent sourceとして指定。</p>

<p><img src="https://lh3.googleusercontent.com/uDXkEVLrXT1BdUSbiMu3v5lnwTqCoXOkv_nu07XVxkk=w555-h235-no"></p>

<p>(※) KMSは現在us-eastにしかないので、そこ以外のregionでlambdaを実行する場合は、<code>timeout</code>は若干長めに指定して置くと良さげ</p>

<p>コードはこんな感じ。</p>

<ol>
<li>GitHubからSNS hookを受け取って</li>
<li>コメントした内容が<code>join</code>の場合</li>
<li>KMSによってGitHubのtokenを復号化し</li>
<li>そのユーザをteamへ追加する</li>
<li>その後、別lambda functionでslackへ通知する</li>
</ol>


<p><div><script src='https://gist.github.com/ef105e192a030571d83f.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<p><div><script src='https://gist.github.com/f83e33a6ae0acd83902a.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<p>nodeのlibraryを使うともっとスッキリ書けたけど、1 function 1 fileで纏めたかったのでやや冗長なコードになっちゃいました。。</p>

<h2>実行</h2>

<p>GitHubでコメント</p>

<p><img src="https://lh3.googleusercontent.com/KY7fwR-laXAJBQhJFv9VKzo_ydWFzeKep0G-3kgS0mM=w388-h128-no"></p>

<p>Lambda発動</p>

<p>```
2015-08-11T15:42:53.108Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    user: ijin2
2015-08-11T15:42:53.108Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    comment: join
2015-08-11T15:42:55.417Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    status code: 200
2015-08-11T15:42:55.418Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    response:
{</p>

<pre><code>"state": "pending",
"url": "https://api.github.com/teams/1234567/memberships/ijin2"
</code></pre>

<p>}
2015-08-11T15:42:55.418Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    Added to the team
END RequestId: a09e3c80-403f-1e15-bbb5-55b693433c0e
REPORT RequestId: a09e3c80-403f-1e15-bbb5-55b693433c0e  Duration: 5211.48 ms    Billed Duration: 5300 ms Memory Size: 128 MB    Max Memory Used: 14 MB <br/>
```</p>

<p>```
2015-08-11T15:42:56.058Z    a25c66fc-403f-11e5-b291-25d4ee441689    Received event:
{</p>

<pre><code>"username": "ijin2",
"icon_url": "https://avatars.githubusercontent.com/u/12809425?v=3",
"text": "Added to the team"
</code></pre>

<p>}
2015-08-11T15:42:58.310Z    a25c66fc-403f-1e15-b291-25d4ee441689    200
2015-08-11T15:42:58.311Z    a25c66fc-403f-1e15-b291-25d4ee441689    ok
2015-08-11T15:42:58.311Z    a25c66fc-403f-1e15-b291-25d4ee441689    Successfully posted to Slack!
END RequestId: a25c66fc-403f-11e5-b291-25d4ee441689
REPORT RequestId: a25c66fc-403f-1e15-b291-25d4ee441689  Duration: 2268.06 ms    Billed Duration: 2300 ms Memory Size: 128 MB    Max Memory Used: 14 MB<br/>
```</p>

<p>teamへの追加（招待）</p>

<p><img src="https://lh3.googleusercontent.com/lzamiiNraeHYD7FI6rrb8-403hxjzVRrAqGG6k3sBcc=w474-h191-no"></p>

<p>Slackへ通知</p>

<p><img src="https://lh3.googleusercontent.com/EeEiHydBDc29YhVI6MBUcdj1WUzMXnf_Sis3U-URqhw=w388-h147-no"></p>

<h2>結論</h2>

<p>簡単にできますね。実はこんな風に作っちゃった2週間後ぐらいにAWSの人も似たような<a href="https://aws.amazon.com/blogs/compute/dynamic-github-actions-with-aws-lambda/">ブログ</a>を書いていた事を発見しましたが。まあ、こっちはKMSとSlack使ってるので。。</p>

<p>後、KMSのアイコンが欲しい！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data PipelineによるDynamoDBのexport]]></title>
    <link href="http://ijin.github.io/blog/2015/07/02/dynamodb-export-with-datapipeline/"/>
    <updated>2015-07-02T20:28:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/07/02/dynamodb-export-with-datapipeline</id>
    <content type="html"><![CDATA[<p>ちょっとハマったのでメモ。</p>

<p>DynamoDBにはRDSみたいなスナップショットによるバックアップ機能がなく、データを一括でexportするにはフルスキャンしかありません。
AWSではData Pipelineによるs3へのexportテンプレートがあって、それを使うとEMRクラスタが立ち上がりHive経由で大量の処理をして、s3へ書き出してくれます。</p>

<p>1000万件程度の小さな件数だとデフォルトのテンプレートがそのまま使えるけど、1億件近くになると失敗したりタイムアウトしたりするので、パラメータの調整が必要になってきます。</p>

<h3>前提</h3>

<ul>
<li>約1億件</li>
<li>20GB</li>
<li>Provisioned Throughput (reads): 1000</li>
<li>Read Throughput Percent: 1.0</li>
<li>2時間以内のexport</li>
</ul>


<h3>エラー</h3>

<p>具体的には以下のようなエラーに遭遇しました。</p>

<p><code>
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error
 while processing row {"item":{"id_list":"{\"l\":[{\"n\":\"958\"},
{\"n\":\"704\"},{\"n\":\"847\"},{\"n\":\"232\"},{\"n\":\"72\"}]}",
"code":"{\"s\":\"adarea9\"}","user_area":"{\"s\":\"91657-adarea9\"}",
"user":"{\"s\":\"91657\"}","app_code":"{\"s\":\"xxx\"}","last_seen_at":
"{\"s\":\"2010-06-23 22:57:49 +0000\"}","target_id":"{\"n\":\"395\"}",
"count":"{\"n\":\"44\"}","promo_id":"{\"n\":\"125\"}"}} at
org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:550) at
org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:177)
... 8 more Caused by: org.apache.hadoop.hive.ql.metadata.HiveException:
java.io.IOException: All datanodes 10.160.102.191:9200 are bad. Aborting... at
org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:651) at
org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793) at org.apach
</code></p>

<p><code>
2015-06-29 13:33:31,610 Stage-1 map = 100%, reduce = 0% MapReduce Total cumulative
CPU time: 14 minutes 19 seconds 0 msec Ended Job = job_1435578726935_0002 with
errors Error during job, obtaining debugging information...
Examining task ID: task_1435578726935_0002_m_000008 (and more) from job job_1435578726935_0002
Examining task ID: task_1435578726935_0002_m_000000 (and more) from job job_1435578726935_0002
Examining task ID: task_1435578726935_0002_m_000000 (and more) from job job_1435578726935_0002
Task with the most failures(4):
----- Task ID: task_1435578726935_0002_m_000003 URL: http://ip-10-160-25-23.ap-northeast-1.compute.
internal:9026/taskdetails.jsp?jobid=job_1435578726935_0002&amp;tipid=task_1435578726935_0002_m_000003
----- Diagnostic Messages for this Task: Error: GC overhead limit exceeded FAILED:
Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
MapReduce Jobs Launched: Job 0: Map: 10 Cumulative CPU: 859.0 sec HDFS Read: 0 HDFS Write: 0 FAIL Total MapRed
</code></p>

<p><code>
2015-06-30 02:32:17,929 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 1605.94 sec
MapReduce Total cumulative CPU time: 26 minutes 45 seconds 940 msec Ended Job =
job_1435627213542_0001 with errors Error during job, obtaining debugging information...
Examining task ID: task_1435627213542_0001_m_000004 (and more) from job job_1435627213542_0001
Examining task ID: task_1435627213542_0001_m_000004 (and more) from job job_1435627213542_0001
Examining task ID: task_1435627213542_0001_m_000004 (and more) from job job_1435627213542_0001
Task with the most failures(4): ----- Task ID: task_1435627213542_0001_m_000000 URL:
http://ip-10-150-205-59.ap-northeast-1.compute.internal:9026/taskdetails.jsp?
jobid=job_1435627213542_0001&amp;tipid=task_1435627213542_0001_m_000000 -----
Diagnostic Messages for this Task: AttemptID:attempt_1435627213542_0001_m_000000_3
Timed out after 600 secs FAILED: Execution Error, return code 2 from
org.apache.hadoop.hive.ql.exec.mr.MapRedTask MapReduce Jobs Launched: Job 0: Map: 10 Cu
</code></p>

<p><code>
Error: java.lang.RuntimeException: Hive Runtime Error while closing operators at
org.apache.hadoop.hive.ql.exec.mr.ExecMapper.close(ExecMapper.java:260) at
org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:81) at
org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432) at
org.apache.hadoop.mapred.MapTask.run(MapTask.java:343) at
org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175) at
java.security.AccessController.doPrivileged(Native Method) at
javax.security.auth.Subject.doAs(Subject.java:415) at
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548) at
org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:170)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException:
java.io.IOException: All datanodes 10.186.28.181:9200 are bad.
Aborting... at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.closeWriters(FileSinkOperator.java:168) at
org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:882) at org.apache.hadoop.
</code></p>

<p>Hive Runtime ErrorやGCエラー等が出てますね。</p>

<h3>原因</h3>

<p>通常のexportテンプレートではEMRはなんと<strong>m1.medium</strong>のcore taskが一台のみ起動して処理が走ります。
各種ヒープサイズの設定（<code>YARN_RESOURCEMANAGER_HEAPSIZE</code> 等）は<a href="https://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/HadoopMemoryDefault_H2.html">instance typeによって決まって</a>おり、この件数とデータサイズではHEAPSIZEが不足し、GCエラー等が発生してOut of Memory状態になって処理が落ちるようです。
そこで、メモリをもっと搭載している大きめのインスタンスでHEAPSIZEを確保してあげる必要があります。</p>

<h3>解決策</h3>

<p>こんな感じ。</p>

<p><img src="https://lh3.googleusercontent.com/ghExdELQB1cIE9K-d97gDqz7a634413GOTxAHhvJsBg"></p>

<table>
<thead>
<tr>
<th></th>
<th>parameter</th>
<th>default value</th>
<th>new value</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>core &amp; master instance type</td>
<td>m1.medium</td>
<td>m3.xlarge</td>
</tr>
<tr>
<td></td>
<td>core instance count</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td></td>
<td>AMI version</td>
<td>3.3.2</td>
<td>3.8.0</td>
</tr>
</tbody>
</table>


<p>m3.xlargeにした事で処理が落ちる事なくスムーズに実行されるようになりました。core countを増やしたのは、exportテンプレートのデフォルト設定だとcountが1なので、mapperが不足し、DynamoDBで設定したthroughput (1000)をフルに使い切る事ができなく、デフォルトのタイムアウト時間（2時間）に達して処理自体がキャンセルされてしまうからです。EMR側のスループットも上げる為に必要な変更でした。また、Hadoopの<a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/ami-versions-supported.html">AMI version</a>も古い3.3.2から最新の3.8.0にしてあります。</p>

<p>これらによって、export処理がだいたい1時間ちょいで完了します。</p>

<p>その時の試行錯誤がこれ。</p>

<p><img src="https://lh3.googleusercontent.com/xatqR0hx1M6PhroKFNAksOplqgqYgqsaCJgonanQyzA=w437-h197-no"></p>

<h3>計算</h3>

<p>provisioned throughputに対するバックアップ時間の目安を計算するには以下の通り。</p>

<p>20GBのデータ、1億件のレコード、1000 throughputとして、</p>

<p><code>平均item size = 20*1024*1024*1024/100000000 =~  215 byte</code></p>

<p>4KB以下なので4KB blockのreadとなります。
Hive Queryのread処理は<a href="http://hipsterdevblog.com/blog/2015/05/30/analysing-dynamodb-index-usage-in-hive-queries/">eventually consistentになる</a>ので、1 IOPSに対して8KBのデータが読み込めます。
そうすると</p>

<p><code>DynamoDB scan時間 = (20*1024*1024*1024)/(1000*8*1024*60) = 43.7分</code></p>

<p>実際にはEMRクラスタのオーバーヘッドが20分弱程度あるので、これに若干加算します。</p>

<p>図にするとこんな風になります。</p>

<iframe width="670" height="412" seamless frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/14oyOry-bnrqIgYxdN36Qdwv3VC1lhdku4QffzFh8iIc/pubchart?oid=1201814511&amp;format=interactive"></iframe>


<p>バックアップのタイミングでDynamoDBのthroughputをガツンと上げれば、件数によっては短時間で済む場合もあるので、参考にでも！</p>

<p>（※ Production Trafficに影響がないように、Read Throughput Percentは適切に設定する必要があります）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EC2 Auto Recoveryの注意点]]></title>
    <link href="http://ijin.github.io/blog/2015/05/01/notes-on-ec2-auto-recovery/"/>
    <updated>2015-05-01T11:45:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/05/01/notes-on-ec2-auto-recovery</id>
    <content type="html"><![CDATA[<p>先日、EC2のAuto Recoveryでちょっとハマったのでメモ。</p>

<p>Cloudwatchの<code>StatusCheckFailed_System</code>アラームを設定すると、インスタンスを自動的に復旧してくれるEC2 Auto Recoveryという機能があり、使うためには条件がいくつかあります。</p>

<ul>
<li>特定のリージョン</li>
<li>C3, C4, M3, R3, T2 instances</li>
<li>VPC</li>
<li>共有tenancy</li>
<li>EBSストレージのみのサーバ</li>
</ul>


<p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html">Recover Your Instance</a></p>

<p>しかし、上記を満たしているのに、特定のAMIをCLI経由で起動するとEC2 Auto Recoveryを設定できなくなります。</p>

<p>（AWSコンソールでラジオボタンが押せない。CLIで設定しても効かない）
<img src="https://lh5.googleusercontent.com/-dwWUcfCssA4/VULwrOsgxNI/AAAAAAAABFo/VQy-GnIYQXg/w448-h186-no/Screenshot%2B2015-05-01%2B12.18.16.png"></p>

<p>原因はAMIにephemeral disk等のblock device mappingが設定されていて、T2やC4等のEBS onlyなinstance typeで起動しているにも関わらず、AWS側がephemeral diskが付与されていると認識してしまう所にあります。なお、AWSコンソールからの起動だとこの現象は発生しません。</p>

<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.1/gist-embed.min.js"></script>


<p>AMIでblock device mappingが埋め込まれている</p>

<pre><code>aws ec2 describe-images --image-ids ami-e74b60e6 --region ap-northeast-1
</code></pre>

<p><code data-gist-id="55659515d54593c29618" data-gist-highlight-line="21-28"></code></p>

<p>本来はEBS onlyなinstance typeだとblock device mappingの設定如何に関わらず、付与自体が不可能なので、全く関係ないはずです。</p>

<p>解決方法は現時点（2015/5/1）では3通り</p>

<ul>
<li>extraなmappingが設定されていないAMIを使う（Amazon Linux等）</li>
<li>AWSコンソールから起動する</li>
<li>明示的に<code>--block-device-mappings</code>パラメータで<code>NoDevice</code>と指定
<code>aws ec2 run-instances --image-id ami-e74b60e6 --instance-type t2.small --subnet-id subnet-xxxxxxxx --block-device-mappings "[{\"DeviceName\": \"/dev/sdb\",  \"NoDevice\": \"\"}, {\"DeviceName\": \"/dev/sdc\",  \"NoDevice\": \"\"}]"</code></li>
</ul>


<p>これは明らかにAWS側のバグなので早く治って欲しいものですね。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Auto Scalingによる自動復旧（AWS Lambda+SNS編）]]></title>
    <link href="http://ijin.github.io/blog/2015/04/17/self-healing-with-non-elb-autoscaling4/"/>
    <updated>2015-04-17T14:01:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/04/17/self-healing-with-non-elb-autoscaling4</id>
    <content type="html"><![CDATA[<p>先週の<a href="http://aws.amazon.com/summits/san-francisco/">AWS Summit San Fransisco</a>にて、ついにLambdaがSNSに<a href="http://docs.aws.amazon.com/sns/latest/dg/sns-lambda.html">対応</a>しました。
様々なサービスが発表された中、個人的にはこれが一番のヒットです！というのも、この機能によってAWS間のサービスがより連携しやすくなり、新しいリアクティブなアーキテクチャをどんどん実現できそうだからです。</p>

<p>というわけで、少し試してみました。</p>

<p>お題は去年12月に試したAutoScaling + Lambda。（当時はLambdaはまだこの機能がなかったのでSNS→SQSにてイベントをプロセスする仕組みを<a href="/blog/2014/12/05/self-healing-with-non-elb-autoscaling3/">作りました</a>。）</p>

<p>SNS連携によって前回のこれが</p>

<p><img src="https://lh4.googleusercontent.com/-IxSeVgkwfQU/VIIapiet4tI/AAAAAAAABBw/ukic0BIBIT0/w529-h393-no/aws-advent-2014.png"></p>

<p>こうなります。（Lambdaのアイコンが出たので差し替えてます）</p>

<p><img src="https://lh3.googleusercontent.com/-ejPyB1qrZyQ/VTCEjbhe2cI/AAAAAAAABFI/VCYVIo5hFao/w404-h393-no/as-sns-lambda2.png"></p>

<p>うーん、シンプル！</p>

<h3>設定</h3>

<p>前回とほぼ同様。</p>

<p>SNS作成
```
$ aws sns create-topic --name instance-alert --region ap-northeast-1
{</p>

<pre><code>"TopicArn": "arn:aws:sns:ap-northeast-1:123456789012:instance-alert"
</code></pre>

<p>}
```</p>

<p>LambdaとSNS連携できるようにポリシーを付与
```
$ aws lambda add-permission --function-name makeASUnhealty --statement-id sns-instance-alert \
--action "lambda:invokeFunction" --principal sns.amazonaws.com \
--source-arn arn:aws:sns:ap-northeast-1:123456789012:instance-alert --region us-west-2                                                                                                                                                                                                <br/>
{</p>

<pre><code>"Statement": "{\"Condition\":{\"ArnLike\":{\"AWS:SourceArn\":\"arn:aws:sns:ap-northeast-1:123456789012:instance-alert\"}},\"Resource\":\"arn:aws:lambda:us-west-2:123456789012:function:makeASUnhealty\",\"Action\":[\"lambda:invokeFunction\"],\"Principal\":{\"Service\":\"sns.amazonaws.com\"},\"Sid\":\"sns-instance-alert\",\"Effect\":\"Allow\"}"
</code></pre>

<p>}
```</p>

<p>Subscribe
```
$ aws sns subscribe --topic-arn arn:aws:sns:ap-northeast-1:123456789012:instance- --protocol lambda \
--notification-endpoint arn:aws:lambda:us-west-2:123456789012:function:makeASUnhealty --region ap-northeast-1
{</p>

<pre><code>"SubscriptionArn": "arn:aws:sns:ap-northeast-1:123456789012:as-test:4b22eec6-aeb5-4421-7a2f-99ca33a4b8ab"
</code></pre>

<p>}
```
aws cliはのヘルプにはまだSNSをLambdaへsubscribeするやり方は書いてませんが、上記のようにやればできます。 <a href="http://alestic.com/2015/04/aws-cli-sns-lambda">Thanks Eric!</a></p>

<p>EC2 Status Check
<code>
$ export INSTANCE=i-xxxxxxxx
$ aws cloudwatch put-metric-alarm --alarm-name StatusCheckFailed-Alarm-for-$INSTANCE \
--alarm-description "Instance $INSTANCE has failed" --metric-name StatusCheckFailed \
--namespace AWS/EC2 --statistic Maximum --dimensions Name=InstanceId,Value=$INSTANCE \
--period 60 --unit Count --evaluation-periods 2 --threshold 1 --comparison-operator \
  GreaterThanOrEqualToThreshold --alarm-actions arn:aws:sns:ap-northeast-1:560336700862:instance-alert \
--region ap-northeast-1
</code></p>

<p>Lambda Function
<div><script src='https://gist.github.com/52033eb3b9b02c1fe975.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<h3>自動復旧</h3>

<p>通信を遮断し、Status Check Failを発動させる
<code>
$ date; sudo ifdown eth0
Fri Apr 17 03:08:39 UTC 2015
</code></p>

<p>EC2 Status Check。2分でfail検知
```
Fri Apr 17 12:10:25 JST 2015
ok
DETAILS reachability    passed</p>

<p>Fri Apr 17 12:10:31 JST 2015
impaired
DETAILS 2015-04-17T03:10:00.000Z        reachability    failed
```</p>

<p>SNS通知。さらに2分ちょい。
```
Alarm Details:
- Name:                       StatusCheckFailed-Alarm-for-i-xxxxxxxx
- Description:                Instance i-xxxxxxxx has failed
- State Change:               OK -> ALARM
- Reason for State Change:    Threshold Crossed: 2 datapoints were greater than or equal to the threshold (1.0). The most recent datapoints: [1.0, 1.0].
- Timestamp:                  Friday 17 April, 2015 03:13:09 UTC
- AWS Account:                123456789012</p>

<p>Threshold:
- The alarm is in the ALARM state when the metric is GreaterThanOrEqualToThreshold 1.0 for 60 seconds.</p>

<p>Monitored Metric:
- MetricNamespace:            AWS/EC2
- MetricName:                 StatusCheckFailed
- Dimensions:                 [InstanceId = i-xxxxxxxx]
- Period:                     60 seconds
- Statistic:                  Maximum
- Unit:                       Count
```</p>

<p>Lambdaログ
<code>
2015-04-17T03:13:14.504Z  ac9ed52f-e4af-1e14-b826-ee9008a99db9  Received event:..
2015-04-17T03:13:14.504Z  ace9d52f-e4af-1e14-b826-ee9008a99db9  Changing instance health for: i-xxxxxxxx
2015-04-17T03:13:15.682Z  ace9d25f-e4af-1e14-b826-ee9008a99db9  { ResponseMetadata: { RequestId: 'b0194dfb-e4af-1e14-895f-abdf96b0b593' } }
2015-04-17T03:13:15.684Z  ace9d25f-e4af-1e14-b826-ee9008a99db9  result: ""
</code>
タイムスタンプによるとSNS発砲されてたからLambda発火まで5秒！</p>

<p>Auto ScalingのHealth Status
```
Fri Apr 17 12:13:10 JST 2015
as-sg   ap-northeast-1a HEALTHY i-ce02563d      as-lc   InService</p>

<p>Fri Apr 17 12:13:15 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   InService</p>

<p>Fri Apr 17 12:13:20 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   InService</p>

<p>Fri Apr 17 12:13:26 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   InService</p>

<p>Fri Apr 17 12:13:31 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   InService</p>

<p>Fri Apr 17 12:13:37 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   Terminating</p>

<p>Fri Apr 17 12:13:43 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   Terminating</p>

<p>Fri Apr 17 12:13:49 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   Terminating</p>

<p>Fri Apr 17 12:13:54 JST 2015
as-sg   ap-northeast-1a UNHEALTHY       i-ce02563d      as-lc   Terminating</p>

<p>Fri Apr 17 12:13:59 JST 2015</p>

<p>Fri Apr 17 12:14:05 JST 2015
as-sg   ap-northeast-1a HEALTHY i-525601a1      as-lc   Pending</p>

<p>Fri Apr 17 12:14:10 JST 2015
as-sg   ap-northeast-1a HEALTHY i-525601a1      as-lc   Pending</p>

<p>Fri Apr 17 12:14:16 JST 2015
as-sg   ap-northeast-1a HEALTHY i-525601a1      as-lc   Pending</p>

<p>Fri Apr 17 12:14:21 JST 2015
as-sg   ap-northeast-1a HEALTHY i-525601a1      as-lc   Pending</p>

<p>Fri Apr 17 12:14:26 JST 2015
as-sg   ap-northeast-1a HEALTHY i-525601a1      as-lc   Pending</p>

<p>Fri Apr 17 12:14:32 JST 2015
as-sg   ap-northeast-1a HEALTHY i-525601a1      as-lc   Pending</p>

<p>Fri Apr 17 12:14:37 JST 2015
as-sg   ap-northeast-1a HEALTHY i-525601a1      as-lc   InService
```</p>

<p>ちゃんとTerminateされてリプレースされてますね。</p>

<p>AutoScalingの通知
<code>
Service: AWS Auto Scaling
Time: 2015-04-17T03:13:59.367Z
RequestId: efa97137-fa15-4aa4-9c8c-5241961a2d0e
Event: autoscaling:EC2_INSTANCE_TERMINATE
AccountId: 123456789012
AutoScalingGroupName: as-sg
AutoScalingGroupARN: arn:aws:autoscaling:ap-northeast-1:123456789012:autoScalingGroup:c395c157-3a7e-4d56-287b-5ad9b26eb464:autoScalingGroupName/as-sg
ActivityId: efa97137-fa15-4aa4-9c8c-5241961a2d0e
Description: Terminating EC2 instance: i-xxxxxxxx
Cause: At 2015-04-17T03:13:36Z an instance was taken out of service in response to a user health-check.
StartTime: 2015-04-17T03:13:36.342Z
EndTime: 2015-04-17T03:13:59.367Z
StatusCode: InProgress
StatusMessage:
Progress: 50
EC2InstanceId: i-xxxxxxxx
Details: {"Availability Zone":"ap-northeast-1a","Subnet ID":"subnet-bbbbbbbb"}
</code></p>

<p>通常は<code>Cause</code>が<code>an instance was taken out of service in response to a EC2 health check indicating it has been terminated or stopped.</code>となるのが<code>an instance was taken out of service in response to a user health-check.</code>となっているのでAutoScalingのEC2 Health Checkより前にアクションが起こされた事が分かります。</p>

<p>障害発生からInstanceがリプレースされて<code>InService</code>になるAuto Healingのトータル時間は6分ちょいになりました。
<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html">EC2 Auto Recovery</a>を使えば済む場合もありますが、あちらはAWS側の障害に起因する<code>StatusCheckFailed_System</code>のみで<code>StatusCheckFailed_Instance</code>はトリガー対象じゃないのと、特定のインスタンスタイプやVPC等若干制限があります。</p>

<h3>終わりに</h3>

<p>ちなみに今回はinstanceやSNSは東京リージョン（ap-northeast-1）、Lambdaはオレゴンリージョン（us-west-2）というリージョンを跨いだ連携も可能という事が分かりました。まだ東京に来てないけど、既にproduction readyなのでもう普通に使っていけます。</p>

<p>いやー。SNS連携によって夢は広がりますねぇ。</p>
]]></content>
  </entry>
  
</feed>
