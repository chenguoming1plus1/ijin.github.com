<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: aws | @ijin]]></title>
  <link href="http://ijin.github.io/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://ijin.github.io/"/>
  <updated>2015-11-04T11:14:54+09:00</updated>
  <id>http://ijin.github.io/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Elastic Beanstalkへの簡単ssh]]></title>
    <link href="http://ijin.github.io/blog/2015/11/04/elastic-beanstalk-easy-ssh/"/>
    <updated>2015-11-04T08:43:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/11/04/elastic-beanstalk-easy-ssh</id>
    <content type="html"><![CDATA[<p>AWS Elastic Beanstalk上で管理されているinstanceにsshするには<code>eb ssh</code>コマンドを使えば割りと簡単に接続できますが、アクセスキーの設定が必要で、開発者が多い場合にそれを発行してばら撒いて管理するのはかなり面倒です（IAM user/roleの割当にしても）。特に極稀にしか接続する必要がない場合。</p>

<p>そこで、API GatewayとLambdaでinstanceのpublic ipを返却するエンドポイントを作り、SSH configを設定すれば誰でもアクセスできるようにしてみました。</p>

<p><img src="https://lh3.googleusercontent.com/vqW8J9ASHnvZSjAZnwS-_4BMxUo37m6FJ3snn1c2j1dgbX1SVybDaz9TN0mG-fVLqKRUGDtUBO4uDbL2L_QILPXYNbKFCaCmG5Au4Ar8mNacZATEX3FjT2L08T-K4-JWwIXRvsd5SM1iwPu6az7ABb28N2ezTM5wp4-B4rB7tIHFzx8ZWCq9EvZQJGFnqVZpZxXEbdGc2edk6J4dd-QgrZRAmzx2XHXSK4oWnWCkbTB1VS-LGIk0ShMbqn1wjj8AugSoHozG1hsufsuEyeNxBN8-6lQowH_O8JWRdJc28ffNtEaQeGr6Xrj66DjjxYZmO_NdS9hnlgFzUAP4t9iWt1cRAVzDHHVXfqeROmtdXc1ogYLwQY3EOMpd42l-YDNzKbp_bi4H4YJ-Mr-pmF91szERTw2avQmc2MGYcUcsOATYxnyz47mNW1f6alfbzeUf1sFwlUZ1FqS3if6CWiaKnqNjRPvHHs8ccV7magouBQ0Qm3_DOgSKsuosLYXZzNYEuPZl1WYv-m2Hnz0pMglMUA42V_7zrl6lY-cleeY=w605-h431-no"></p>

<h2>前提条件</h2>

<ul>
<li>instanceにはログインユーザーのssh keyが登録積み（.ebextensions等で）</li>
<li>ssh localhost可能である</li>
<li>Elastic Beanstalkのenvironment名は数値で終わらない</li>
<li>Auto ScalingのTermination Policyが<code>NewestInstance</code></li>
</ul>


<h2>Lambda</h2>

<p>やってる事は単純で自動的に付与される<code>elasticbeanstalk:environment-name</code>タグのついたinstanceのipを（パラメータに応じて）返却するだけ。複数ある場合は、起動した順で。</p>

<p>せっかくなので新しくサポートされたPythonで記述。</p>

<p><div><script src='https://gist.github.com/bf735efbec42e1f96d4b.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<p>当然、LambdaのIAM roleで<code>ec2:Describe*</code>のAction許可も必要。</p>

<h2>Swagger</h2>

<p>API Gatewayのresourceをコンソールでポチポチ作るのがイヤだったのでAPIの状態を<a href="http://swagger.io/">Swagger</a>で定義してみた。awscliは<a href="http://dev.classmethod.jp/cloud/aws/getting-started-with-api-gateway-lambda-integration/">生REST APIが辛い</a>。</p>

<p>編集しながらドキュメントも見れる<a href="http://editor.swagger.io/#/">online editor</a>が結構便利。</p>

<p><div><script src='https://gist.github.com/a41059039937ffc8dada.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<h2>API Gateway</h2>

<p>Swagger上でYAMLで作成した定義書はjsonとしてexportし、<a href="https://github.com/awslabs/aws-apigateway-importer">aws-apigateway-importer</a>でAPIのresourceやmethodやらを生成する。</p>

<h3>import処理</h3>

<p><code>
$ ./aws-api-import.sh -c swagger.json
2015-11-04 02:23:18,507 INFO - Attempting to create API from Swagger definition. Swagger file: swagger.json
reading from swagger.json
2015-11-04 02:23:18,649 INFO - Parsed Swagger with 2 paths
2015-11-04 02:23:18,655 INFO - Creating API with name EB API
2015-11-04 02:23:19,417 INFO - Removing default model Error
2015-11-04 02:23:19,634 INFO - Removing default model Empty
2015-11-04 02:23:19,872 INFO - Creating model for api id nx3r6d6yhh with name IP
2015-11-04 02:23:20,114 INFO - Generated json-schema for model IP: {"type":"object","properties":{"ip":{"type":"string","description":"IP address."}},"definitions":{}}
2015-11-04 02:23:20,329 INFO - Creating model for api id nx3r6d6yhh with name Error
2015-11-04 02:23:20,338 INFO - Generated json-schema for model Error: {"type":"object","properties":{"code":{"type":"integer","format":"int32"},"message":{"type":"string"},"fields":{"type":"string"}},"definitions":{}}
2015-11-04 02:23:20,770 INFO - Creating resource 'eb' on bd5pqsq37h
2015-11-04 02:23:21,420 INFO - Creating resource '{env_name}' on 8rjsbt
2015-11-04 02:23:22,079 INFO - Creating resource 'ip' on 4cg26s
2015-11-04 02:23:22,931 INFO - Creating method response for api nx3r6d6yhh and method GET and status 200
2015-11-04 02:23:23,144 INFO - Creating new model referenced from response: IPaddresses
2015-11-04 02:23:23,144 INFO - Creating model for api id nx3r6d6yhh with name IPaddresses
2015-11-04 02:23:23,153 INFO - Generated json-schema for model IPaddresses: {"type":"string","definitions":{}}
2015-11-04 02:23:23,770 WARN - Default response not supported, skipping
2015-11-04 02:23:23,772 INFO - Creating method parameter for api nx3r6d6yhh and method GET with name method.request.path.env_name
2015-11-04 02:23:23,998 INFO - Creating method for api id nx3r6d6yhh and resource id md6qcm with method get
2015-11-04 02:23:24,822 INFO - Creating resource '{server_num}' on qmd6mc
2015-11-04 02:23:25,689 INFO - Creating method response for api nx3r6d6yhh and method GET and status 200
2015-11-04 02:23:25,896 INFO - Found reference to existing model IPaddresses
2015-11-04 02:23:26,306 WARN - Default response not supported, skipping
2015-11-04 02:23:26,306 INFO - Creating method parameter for api nx3r6d6yhh and method GET with name method.request.path.env_name
2015-11-04 02:23:26,525 INFO - Creating method parameter for api nx3r6d6yhh and method GET with name method.request.path.server_number
2015-11-04 02:23:26,764 INFO - Creating method for api id nx3r6d6yhh and resource id 5udxeo with method get
</code></p>

<p>これでAPI Gateway上に階層が出来上がり。</p>

<p><img src="https://lh3.googleusercontent.com/cM7s04iaMWI73VwJcH3C9lsnFjrrFpw0qqnUCM4hkmKWZiB3Pp0idjace8rxQYPCVwYzpucRKJep1j3CN9rDQ4uG0xJa4iXM_ua_lLo6LjxCus_lXV9aPCanWS17Ab6eVfgzH3wMDS1YvUhBq_6aLl3JmGmQVlZPFAUrOjcT-Xwra2o4VRKgaTbE5LQCvoBkzkylYhe6JECBu-lqBW0T9CnyhEsbJ1KTUwnIvLLTYtvTPtG6xEqoBMiCo26QLrASGg_k5fXW66jB-SH3fK-W-2TlYHwGdvlJunbuJp__AN2RUAhU64IPTQmZS-PfBTknMF273wF0DyqoL4UsS4HCmAMytc4LBx4s3iJdxFlPkMHPQ5eM9Q6REK92yP1a9FUqXKGF15FD9M6njOGvXFQYH8BsDruCa-HvxY7l6J0oj7PjyWwgq3_Jpd13F27rQkAcK13ni-sSB17wTRi-la8Tgu5ZMvnpUYBK-ARup3vHz791VQW-LVcdecok2Sao2wG4sUiUi5pMSOUabX02OMORVCu5OSxCdw-GxGSzikM=w350-h280-no"></p>

<p>後は各<code>GET method</code>でLambdaへの関連付けをし、<code>Integration Request</code>と<code>Integration Response</code>の<code>mapping template</code>でパラメータやレスポンスを設定。（多分、この手順もswaggerで定義できるとは思うけど）</p>

<h3>integration request</h3>

<p><img src="https://lh3.googleusercontent.com/JtD50KDCwP5ggylHzSuD7WiM-fr1QvVkZFpGFKD0efPbe_wvJPR0HbaTihe8wSlBNJzFYHAAwN9ZvKS1-R1WVGqbWT-t5PCdlptIVgJkk8xjDF0HJTRXeFEjF6F5Z2sp5wfY3BMgKZnyAM0CL6Ax5WtLNxCENl1SskcqajLDAapVQP8bj0UMlxUhsATwg9wh6zbS-jKp6tjf8YlkDD3PDFV_jhE2oVnzytNTlKBb5sU_kwMRFOGfQiUIpwgsrPq11af4ETcdFiU99lxa2ey1fgwxIaoEddLNOgMyObSd7LV0ISNY_kbZj0aRi2PFFmUfnQmYfc0UTajjAejDRms08vn6oy0-6kwGRjcKMq8zDSLFMCxgaSU4_2m2zh4T1zo54DJCHRm8ilXg_r3Z2u4IdBBHf4xYdvvs2J0p4ZT6GOQy6tMT0cNAFN5XUQiC6zDVutj2Ia1OQSlhUFRvnXwtivqGdMvpOIyUqoyuJ5RHLhO3hWP90SsW_DuILy6eXAHkSMHHpDPu5uemVBD29KfKsf67GS1bmJPwu5_9gX4=w836-h208-no"></p>

<h3>integration response</h3>

<p><img src="https://lh3.googleusercontent.com/-MuJyoH_nLN5jbjrcTsDW9qfsFUhDt6nHq_gNlYwMhVNZJqYL3C5qrgPwXLrPRXL0oRICG8xGpBVJpsLKIC3KhhFL4eHyo5LPZRVMbCXQ20UfT-tMV-Pt72-Rr7AKkhXDSzLcBANpRyJgioD5VlLb6YfqcnDLpczt1gnCOvnLHeWuuIf8NTa6q8hoGZXKyBo79Xapag_xvzbqco8AzSqu_yUxR6MXArEpp_we0JGhkJJHrve41LXNDX27QfC-Fj84feKgXY9CTgB1ytHWWDT_71gU05NwMdMisuQnAZPg9kRnoze55OBXu6c8TtzN5Idvdgmc9dbeKKxFG0f4bn_pt4lN6ZzOJ0ptOteVl-EpMDPk6M9_kwKerOc1GQbH47MEEYmQTXmoMeUp9ECJwhYdxdqu_LEB6ZxrjOC3VBPP6rE8sxBZJG8od_adtClp4UYU5-LBPm9_DYsde5hThh2su9PVBph8fbk42WE8I6o3BoOSciA1G9eIwfaa99OQh-4NZhJRVIGs7M4uMHVyUnDQk0RqtjFjf7TlCkeRC4=w811-h210-no"></p>

<p>参考：</p>

<ul>
<li><a href="http://qiita.com/yuyakato/items/89fcef9746afbf48977a">Amazon API GatewayでAWS Lambda関数にクエリ文字列をパラメータとして渡す</a></li>
<li><a href="http://qiita.com/ijin/items/6edafc1f351a9de49b54">Amazon API Gatewayで文字列をクォーテーションなしで返却する</a></li>
</ul>


<h3>endpoint</h3>

<p>Deployすれば、以下のAPIでipが取得可能。</p>

<p><code>/$API_ENDPOINT/prod/eb/$EB_ENV_NAME/ip/[n]</code></p>

<p>instance ip一覧</p>

<p><code>
$ curl -s https://altvsxa2kj.execute-api.ap-northeast-1.amazonaws.com/prod/eb/my-ebenv-production/ip
54.189.149.5
54.189.168.83
</code></p>

<p>特定のinstance ip</p>

<p><code>
$ curl -s https://altvsxa2kj.execute-api.ap-northeast-1.amazonaws.com/prod/eb/my-ebenv-production/ip/1
54.189.149.5
</code></p>

<p>ipの部分だけ、PATHじゃなくquery paramterにした方がAPI Gatewayの設定がシンプルだったけど、少しでもRESTfulにしたかったもので。（まあ、そもそもjson返してないけど）</p>

<h2>SSH Config</h2>

<p>さて、ここからがキモです。</p>

<p>~/.ssh/config</p>

<p><code>
Host my-ebenv-production*
  User ec2-user
  StrictHostKeyChecking no
  ProxyCommand ssh -A localhost -W `N=$(grep -o '[0-9]\+$' &lt;&lt;&lt; %h || echo 1); E=$(perl -pe 's/\d+$//' &lt;&lt;&lt; %h); curl -s https://altvsxa2kj.execute-api.ap-northeast-1.amazonaws.com/prod/eb/$E/ip/$N`:%p
</code></p>

<p>上記の設定で<code>ssh $EB_ENV_NAME[n]</code>で指定したサーバに接続できるようになります。</p>

<p>仕組みとしては、ホスト名をparseしAPI Gatewayに適切なリクエストを行い、返却されるpublic ipにローカル端末自身を踏み台としてsshする<code>ProxyCommand</code>の設定です。</p>

<p>例えば、2番目（に起動した）のサーバに接続する場合は</p>

<p>```
$ ssh my-ebenv-production2
Last login: Wed Nov  4 01:19:14 2015 from ndx6-ppp413.tokyo.sannet.ne.jp</p>

<hr />

<p>| <em><em><strong>| | </strong> _ </em>__| |</em>(<em>) </em><strong>| </strong> )  <em><strong>  </strong> _ _ <strong>  </strong></em>| |<em> __ </em>| | | <strong>
|  <em>| | |/ </em><code>/ __| __| |/ __|  _ \ / _ \/ _</code> | '_ \/ </strong>| <strong>/ <em>` | | |/ /
| |</em></strong>| | (<em>| _</em> \ |<em>| | (__| |</em>) |  <strong>/ (<em>| | | | _</em> \ || (<em>| | |   &lt;
|</em></strong><strong>|<em>|_</em>,<em>|</em></strong>/_<em>|</em>|_<strong>|</strong><strong>/ _</strong>|_<em>,</em>|<em>| |</em>|<em><em><em>/_</em>_</em>,</em>|<em>|</em>|_\</p>

<pre><code>                                   Amazon Linux AMI
</code></pre>

<p>This EC2 instance is managed by AWS Elastic Beanstalk. Changes made via SSH
WILL BE LOST if the instance is replaced by auto-scaling. For more information
on customizing your Elastic Beanstalk environment, see our documentation here:
http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/customize-containers-ec2.html
```</p>

<p>1番目の場合は明示的に指定する必要はありません。</p>

<p><code>
$ ssh my-ebenv-production
</code></p>

<p>また、Auto Scalingでinstanceが増減せずに1台のみの場合はもっとシンプルに記述できます。</p>

<p><code>
  ProxyCommand ssh -A localhost -W `curl -s https://altvsxa2kj.execute-api.ap-northeast-1.amazonaws.com/prod/eb/$E/ip`:%p
</code></p>

<p>簡単！</p>

<p>でも、よくよく考えたら普通のAuto Scalingの場合でも利用できる事に気付きました。</p>

<h2>まとめ</h2>

<ul>
<li>Swaggerなかなか面白い</li>
<li>API GatewayとLambda便利</li>
<li>Lambda pythonも良い。けど、rubyサポートも早う。。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS re:Invent 2015に参加してきた]]></title>
    <link href="http://ijin.github.io/blog/2015/10/26/aws-re-invent-2015/"/>
    <updated>2015-10-26T02:26:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/10/26/aws-re-invent-2015</id>
    <content type="html"><![CDATA[<p>今年で3度目の参加となるAWS re:Invent。
忘れない内に記録を残しておきます。</p>

<h2>Day 0</h2>

<h3>Game Day</h3>

<p>Unicornを貸し出すサービスを展開する仮想のスタートアップ企業にDevOpsチームとして最近入社したという設定。前任者が退職しており、資料が少ない中でサービスオープンに立ち会いつつ、様々な困難に直面するというフルデイ・イベント。
今までのGame Dayと違って面白いのはパフォーマンス・チューニングをしつつも、コストも意識しながらチーム間でスコアを競争するところ。アプリは触れないので、<a href="http://isucon.net/">ISUCON</a>よりは昔やった<a href="/blog/2012/07/03/tuningathon4/">チューニンガソン</a>に近い感じ。</p>

<p>スコアは累積の損益。アーキテクチャによっては利益が出たり損失が出たりする。例えば、多くのリクエストが処理できると利益は増すが、AWSのリソースが多いと費用が掛かって損失になりうる。
当然最初は各チームは赤字から始まり、時間とともに積算した利益によって黒転して行く様が目新しかった。</p>

<p>結果、48チーム中で<strong>6位</strong>。（上位2チームはチートで失格となったので<strong>実質は4位</strong>）</p>

<p><img src="https://lh3.googleusercontent.com/H8zoy7lrftuIo9ZQTN_LsUC3KsiGsNkOJbPzuW4vAxy4o6IOAH8=w547-h298-no"></p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="en" dir="ltr"><a href="https://twitter.com/ijin">@ijin</a> <a href="https://twitter.com/AWSreInvent">@AWSreInvent</a> the rabbit icon was awarded to the team with the fastest response time to a request.0.0005s is not too shabby!</p>&mdash; Kyle Lichtenberg (@KyleLichtenberg) <a href="https://twitter.com/KyleLichtenberg/status/651573816301219840">October 7, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>ちなみに最速レスポンスタイムはうちのチームが叩きだした。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Our team - &quot;Ubercon&quot;! <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a> <a href="https://twitter.com/hashtag/AWSGameDay?src=hash">#AWSGameDay</a> <a href="http://t.co/dpRu1vicgM">pic.twitter.com/dpRu1vicgM</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/651544851620700160">October 6, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>詳細は今度日本で開催されるかも知れないので控えておくが、非常に楽しめたので次回は運営側に回って手伝おうかと思います！</p>

<h2>Day 1</h2>

<h3>Keynote</h3>

<p>Andy Jessy副社長による発表。今年のテーマは「<strong>自由</strong>」</p>

<ul>
<li>Amazon QuickSight</li>
<li>Amazon Kinesis Firehose</li>
<li>Amazon Snowball</li>
<li>MariaDB for RDS</li>
<li>AWS Database Migration Service</li>
<li>AWS Schema Conversion Tool</li>
<li>AWS Config Rules</li>
<li>Amazon Inspector</li>
</ul>


<p><img src="https://lh3.googleusercontent.com/SSI_hMC3cjzUSvGPxT49FD26VBeY_QYt_qGoTLDPo8nBLwdmglM=w493-h544-no"></p>

<p><del>Oracle</del>からの自由、解放！</p>

<h3>WRK306 - AWS Professional Services Architecting Workshop</h3>

<p>実在した、ある企業のクラウド移行案件。RFP的なモノがあり、アーキテクチャをチーム内で議論し、最後にそれぞれ各チームが発表していく流れ。
かつてjawsugで主催を手伝ったワールドカフェ形式とほぼ同じだったので、チームメンバーを先導してCacooでさくさく構成図を起こしていく。
他のチームが模造紙にラフスケッチで発表する中、我らは綺麗に正本して、プロジェクターで登壇しながら発表。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">ワークショップはうちらのチームだけCacooで図を書いたので制覇した感がある。 <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/651869691699425281">October 7, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>最後に実際にどう移行したかというAWSチームからの回答。まず、移行フェーズを段階的に分け、最初はシステムをほぼそのままクラウド上に乗せた後に部分的に最適化してコンポーネントを置き換えて行ったという話。最後にLambdaになっていた部分があったのが興味深かった。</p>

<p>早く新サービスに対応したAWS Simple Iconsのアップデートが待たれるところ。</p>

<p><img src="https://lh3.googleusercontent.com/IVrSN7g0MnAfVa6pB4ajQWUZYPmpFMOH6Ych-FedX1HqxCfEHtc=w583-h346-no"></p>

<p>今回提案した内容。</p>

<h3>WRK305 - Zombie Apocalypse Survival: Building Serverless Microservices</h3>

<p><a href="https://ja.wikipedia.org/wiki/%E3%82%BE%E3%83%B3%E3%83%93%E3%81%AB%E3%82%88%E3%82%8B%E4%B8%96%E7%95%8C%E3%81%AE%E7%B5%82%E6%9C%AB">Zombie Apocalypse</a>が起こって、人類存亡の危機！途中まで実装されたチャットルームの機能を拡張・実装して危機を救え！というシナリオの元、LambdaとAPI Gatewayとjavascript sdkで実装されたサーバーレスアーキテクチャのワークショップ。</p>

<p>機能拡張の為に実装が必要なので、設計しながらチーム内で作業分担し、コードをせっせと書いていく。
ゾンビ出現のアラート通知、ヒートマップ描画、アンデッドカウンター、緊急食料倉庫の位置情報配信等、面白い機能要求が盛り沢山。</p>

<p><img src="https://lh3.googleusercontent.com/-UStcIzDdtS42SZTgt657iKvYHWlbcfktbvuCq3-LIioBfrBzgI=w600-h346-no"></p>

<p>ささっとSlack部屋を作り、githubでコードを共有しながらのチームワーク作業。多分、うちらのチームが一番多く実装できた感触。</p>

<p><img src="https://lh3.googleusercontent.com/WZ7nUMvRhoNzixWqjEdCFJ1wJqNH-BqjV4M4cq93mBXBnJ8UPOk=w493-h544-no"></p>

<p>このワークショップはかなりの人気で、開始30分前にすでに長蛇の列が。
運良くぎりぎり最後の参加者として入れたけど、皆どれだけゾンビが好きなんだ。。</p>

<h2>Day 2</h2>

<h3>Keynote</h3>

<p>Wernerl Vogels CTOの発表。</p>

<ul>
<li>Amazon Kinesis Analytics</li>
<li>X1 instance (100 cores, 1TB RAM)</li>
<li>t2.nano instance</li>
<li>Amazon EC2 Container Registry</li>
<li>Lambda

<ul>
<li>VPC support</li>
<li>Long running Functions (300s)</li>
<li>Scheduled Functions</li>
<li>Custom Retry Logic</li>
<li>Python</li>
</ul>
</li>
<li>AWS IOT</li>
</ul>


<p><img src="https://lh3.googleusercontent.com/A4p3UvP0JiMxjpZF7L0zxdMFkU96aOYtZ-BExM2zFERDsebakXw=w493-h543-no"></p>

<p>前日にAndyが7つの自由を語って、当日はWernerが7つの法則を語る。</p>

<h3>WRK308 - AWS + ASK: Teaching Amazon Echo New Skills</h3>

<p>Amazon Echoを使った、Alexaのプログラミングワークショップ。音声によって、Echo経由でLambdaイベントを呼び出し、Alexaサービスと連携するカスタマイズしたスキルセットを実装して行く。</p>

<p>例えば、Alexaに好きな色を覚えさせて、後ほど聞くと答えてくれる機能とか。全てボイスコントロール。<a href="http://yoshidashingo.hatenablog.com/?page=1445224481">吉田さんの英語でも通じた</a>ので、かなり優秀。</p>

<p>新品のEchoを開封して使ったので、最後に貰える物かとささやかに期待したものの、$15のAWSクーポン配布のみ。さすが<del>ケチ</del>FrugalなAmazonさん。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">Alexaとlambdaが連携してEchoが喋った！ <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a> <a href="http://t.co/V6QpNyj3tK">pic.twitter.com/V6QpNyj3tK</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/652234646231646208">October 8, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">Alexは今ユーザ駆動にしか対応してないけど、awsのイベント駆動はtop priorityとの事。そのうち例えばbilling alertを音声で通知できるようになるなぁ。楽しみだ。 <a href="https://twitter.com/hashtag/reinvent?src=hash">#reinvent</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/652239936968654848">October 8, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<h3>re:Play</h3>

<p>EDMの若きプリンスDJ、Zeddをシークレットゲストとして呼んでのアフター。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="en" dir="ltr">What a view for this secret <a href="https://twitter.com/Zedd">@zedd</a> show, this crowd does not end! <a href="https://twitter.com/hashtag/vegas?src=hash">#vegas</a> <a href="http://t.co/0Itv012o0k">pic.twitter.com/0Itv012o0k</a></p>&mdash; Rukes (@rukes) <a href="https://twitter.com/rukes/status/652400784353595392">October 9, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>もう完全にWernerのパーティー。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p lang="ja" dir="ltr">昨夜の <a href="https://twitter.com/hashtag/replay?src=hash">#replay</a> でこの積み上がったコンテナを見て、Docker Swarm を連想した人はさぞ多かったに違いない。 <a href="http://t.co/QxF2MkbHTi">pic.twitter.com/QxF2MkbHTi</a></p>&mdash; Michael H. Oshita (@ijin) <a href="https://twitter.com/ijin/status/652681828441063425">October 10, 2015</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/cT676BMT7A8 "></iframe></div></p>

<p>Zeldaのremixが良かった。</p>

<h3>終わりに</h3>

<p>結局セッションは一つも出なかったです。まあ、ビデオやスライドは公開されるので内容自体は後で把握可能なので別にいいかな。授業を聞きに来た分けでもないし。
それよりも、現地に来ているエンジニアと交流したり、実装まで含んだハンズオンのワークショップをやった方が楽しいし、糧となる。後はトレンドを肌感覚として体感するには良い場所なので行った事ない人には是非オススメしておきたい。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[GitHubのeventをLambdaで処理してSlackへ通知]]></title>
    <link href="http://ijin.github.io/blog/2015/08/06/github-to-lambda-to-slack/"/>
    <updated>2015-08-06T01:46:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/08/06/github-to-lambda-to-slack</id>
    <content type="html"><![CDATA[<p>ちょっと前にGitHubのeventを<a href="https://aws.amazon.com/lambda/">AWS Lambda</a>で処理して、GitHubやSlackのAPIを叩く仕組みを作ったので、メモ。</p>

<p>材料</p>

<ul>
<li>Github</li>
<li>SNS</li>
<li>KMS</li>
<li>Lambda</li>
<li>Slack</li>
</ul>


<p>やりたいことはこんな感じ。</p>

<p><img src="https://lh3.googleusercontent.com/-aep_hTkw5Mo/VjkHcm612yI/AAAAAAAABbo/00aae3JXUkc/s548-Ic42/github%25252Blambda%25252Bslack%252520%2525281%252529.png"></p>

<p>あるGitHubリポジトリのissuesに特定のコメントが書き込まれると、そのユーザはプロジェクトのteamに自動で追加されて、Slackへ通知が流れるというモノです。</p>

<h2>SNS</h2>

<p>まずは媒介となるSNSの作成。
```
$ aws sns create-topic --name github --region ap-northeast-1
{</p>

<pre><code>"TopicArn": "arn:aws:sns:ap-northeast-1:123456789012:github"
</code></pre>

<p>}
```</p>

<p>次にSNSに対してpublishできるIAM userを作成</p>

<p>IAM Policy
```
{
  "Version": "2012-10-17",
  "Statement": [</p>

<pre><code>{
  "Action": [
    "sns:Publish"
  ],
  "Sid": "Stmt0000000000000",
  "Resource": [
    "arn:aws:sns:ap-northeast-1:123456789012:github"
  ],
  "Effect": "Allow"
}
</code></pre>

<p>  ]
}
```</p>

<h2>GitHub</h2>

<ul>
<li>organization: <code>my_org</code></li>
<li>repository: <code>test</code></li>
<li>team: <code>reader</code></li>
</ul>


<h3>SNS連携</h3>

<p><em>Webhooks &amp; Services</em> からAmazonSNSと連携</p>

<p><img src="https://lh3.googleusercontent.com/u4I9Z_Ing9YzhmVCQhMACwYDVIJxJM7C-aDmyMsNL3o=w328-h190-no"></p>

<p>AWS KEYには先ほど作成したIAMユーザのを利用。SNS topicのarnにはregionが書かれているにも関わらず、GitHubの方では明示的に指定が必要。</p>

<p><img src="https://lh3.googleusercontent.com/kppZQx_RdhyC11LB7a0cPtppDUiKgfZBm6laYvRG3zA=w382-h289-no"></p>

<h3>通知するeventの有効化</h3>

<p>さて、GitHubではSNSの場合、<a href="https://api.github.com/hooks">hooksのjson</a>にある通り、<code>push</code>時のeventにしか対応していないので、</p>

<p><code>json hooks https://api.github.com/hooks
"name": "amazonsns",
"events": [
  "push"
],
</code></p>

<p>GitHubの<a href="https://developer.github.com/v3/orgs/hooks/">Webhook API</a>に従って<code>issue_comment</code>を追加してやります。</p>

<p>先ほどのSNS連携のhook idを取得するには<code>GET /orgs/:org/hooks</code></p>

<p><code>bash
export HOOK_ID=$(curl -H 'Uer-Agent: ijin' -X GET -s -H "Authorization: token xxxxxxxxxx" \
https://api.github.com/repos/my_org/test/hooks | jq '.[].id')
</code></p>

<p>編集するには<code>PATCH /orgs/:org/hooks/:id</code></p>

<p><code>bash
curl -H 'Uer-Agent: ijin' -X PATCH -s -H "Authorization: token xxxxxxxxxx" \
https://api.github.com/repos/my_org/test/hooks/$HOOK_ID -d '{"add_events": ["issue_comment"]}' | jq .
</code></p>

<p>Web UIからは分からないので、ついでに<code>reader</code> teamのIDも取得しておく</p>

<p><code>bash
curl -H 'Uer-Agent: ijin' -X GET -s -H "Authorization: token xxxxxxxxxx" \
https://api.github.com/orgs/my_org/teams | jq '.[] | select(.name=="reader")'
</code></p>

<p>（※）User-Agentは<a href="https://developer.github.com/v3/#user-agent-required">必須</a></p>

<p>これで、誰かがコメントをした時にもSNSが飛びます。</p>

<h2>KMS</h2>

<p>lambdaでは以下の認証情報を使うので、予めKMSで暗号化しておく。</p>

<ul>
<li>GitHub token</li>
<li>Slack webhook</li>
</ul>


<p>rubyで暗号化する場合
<code>ruby
require 'aws-sdk'
require 'base64'
kms = Aws::KMS::Client.new(region: 'us-east-1')
Base64.encode64 kms.encrypt(key_id: "alias/ijin", plaintext: 'my plain text code').ciphertext_blob
</code></p>

<p>javascriptの場合
<code>javascript
var aws = require('aws-sdk');
var kms = new aws.KMS({ region: 'us-east-1' });
var text = 'my plain text code';
kms.encrypt({KeyId: 'alias/ijin', Plaintext: text}, function(err, data) {
  if (err) console.log(err, err.stack);
  else console.log(data.CiphertextBlob.toString('base64'));
});
</code></p>

<p>こうしておくと、SCMに入れても安心。</p>

<p>また、KMSキーの実行権限もlambdaのroleに紐づけておく。</p>

<p><img src="https://lh3.googleusercontent.com/oMHQ76XC7RQUCR_fEo9JyaMhPKSbnIdhCzjIWurEJ9c=w542-h358-no"></p>

<h2>Lambda</h2>

<p>Lambda function作成時にはSNSをevent sourceとして指定。</p>

<p><img src="https://lh3.googleusercontent.com/uDXkEVLrXT1BdUSbiMu3v5lnwTqCoXOkv_nu07XVxkk=w555-h235-no"></p>

<p>(※) KMSは現在us-eastにしかないので、そこ以外のregionでlambdaを実行する場合は、<code>timeout</code>は若干長めに指定して置くと良さげ</p>

<p>コードはこんな感じ。</p>

<ol>
<li>GitHubからSNS hookを受け取って</li>
<li>コメントした内容が<code>join</code>の場合</li>
<li>KMSによってGitHubのtokenを復号化し</li>
<li>そのユーザをteamへ追加する</li>
<li>その後、別lambda functionでslackへ通知する</li>
</ol>


<p><div><script src='https://gist.github.com/ef105e192a030571d83f.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<p><div><script src='https://gist.github.com/f83e33a6ae0acd83902a.js?file='></script>
<noscript><pre><code></code></pre></noscript></div>
</p>

<p>nodeのlibraryを使うともっとスッキリ書けたけど、1 function 1 fileで纏めたかったのでやや冗長なコードになっちゃいました。。</p>

<h2>実行</h2>

<p>GitHubでコメント</p>

<p><img src="https://lh3.googleusercontent.com/KY7fwR-laXAJBQhJFv9VKzo_ydWFzeKep0G-3kgS0mM=w388-h128-no"></p>

<p>Lambda発動</p>

<p>```
2015-08-11T15:42:53.108Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    user: ijin2
2015-08-11T15:42:53.108Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    comment: join
2015-08-11T15:42:55.417Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    status code: 200
2015-08-11T15:42:55.418Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    response:
{</p>

<pre><code>"state": "pending",
"url": "https://api.github.com/teams/1234567/memberships/ijin2"
</code></pre>

<p>}
2015-08-11T15:42:55.418Z    a09e3c80-403f-1e15-bbb5-55b693433c0e    Added to the team
END RequestId: a09e3c80-403f-1e15-bbb5-55b693433c0e
REPORT RequestId: a09e3c80-403f-1e15-bbb5-55b693433c0e  Duration: 5211.48 ms    Billed Duration: 5300 ms Memory Size: 128 MB    Max Memory Used: 14 MB <br/>
```</p>

<p>```
2015-08-11T15:42:56.058Z    a25c66fc-403f-11e5-b291-25d4ee441689    Received event:
{</p>

<pre><code>"username": "ijin2",
"icon_url": "https://avatars.githubusercontent.com/u/12809425?v=3",
"text": "Added to the team"
</code></pre>

<p>}
2015-08-11T15:42:58.310Z    a25c66fc-403f-1e15-b291-25d4ee441689    200
2015-08-11T15:42:58.311Z    a25c66fc-403f-1e15-b291-25d4ee441689    ok
2015-08-11T15:42:58.311Z    a25c66fc-403f-1e15-b291-25d4ee441689    Successfully posted to Slack!
END RequestId: a25c66fc-403f-11e5-b291-25d4ee441689
REPORT RequestId: a25c66fc-403f-1e15-b291-25d4ee441689  Duration: 2268.06 ms    Billed Duration: 2300 ms Memory Size: 128 MB    Max Memory Used: 14 MB<br/>
```</p>

<p>teamへの追加（招待）</p>

<p><img src="https://lh3.googleusercontent.com/lzamiiNraeHYD7FI6rrb8-403hxjzVRrAqGG6k3sBcc=w474-h191-no"></p>

<p>Slackへ通知</p>

<p><img src="https://lh3.googleusercontent.com/EeEiHydBDc29YhVI6MBUcdj1WUzMXnf_Sis3U-URqhw=w388-h147-no"></p>

<h2>結論</h2>

<p>簡単にできますね。実はこんな風に作っちゃった2週間後ぐらいにAWSの人も似たような<a href="https://aws.amazon.com/blogs/compute/dynamic-github-actions-with-aws-lambda/">ブログ</a>を書いていた事を発見しましたが。まあ、こっちはKMSとSlack使ってるので。。</p>

<p>後、KMSのアイコンが欲しい！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Data PipelineによるDynamoDBのexport]]></title>
    <link href="http://ijin.github.io/blog/2015/07/02/dynamodb-export-with-datapipeline/"/>
    <updated>2015-07-02T20:28:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/07/02/dynamodb-export-with-datapipeline</id>
    <content type="html"><![CDATA[<p>ちょっとハマったのでメモ。</p>

<p>DynamoDBにはRDSみたいなスナップショットによるバックアップ機能がなく、データを一括でexportするにはフルスキャンしかありません。
AWSではData Pipelineによるs3へのexportテンプレートがあって、それを使うとEMRクラスタが立ち上がりHive経由で大量の処理をして、s3へ書き出してくれます。</p>

<p>1000万件程度の小さな件数だとデフォルトのテンプレートがそのまま使えるけど、1億件近くになると失敗したりタイムアウトしたりするので、パラメータの調整が必要になってきます。</p>

<h3>前提</h3>

<ul>
<li>約1億件</li>
<li>20GB</li>
<li>Provisioned Throughput (reads): 1000</li>
<li>Read Throughput Percent: 1.0</li>
<li>2時間以内のexport</li>
</ul>


<h3>エラー</h3>

<p>具体的には以下のようなエラーに遭遇しました。</p>

<p><code>
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: Hive Runtime Error
 while processing row {"item":{"id_list":"{\"l\":[{\"n\":\"958\"},
{\"n\":\"704\"},{\"n\":\"847\"},{\"n\":\"232\"},{\"n\":\"72\"}]}",
"code":"{\"s\":\"adarea9\"}","user_area":"{\"s\":\"91657-adarea9\"}",
"user":"{\"s\":\"91657\"}","app_code":"{\"s\":\"xxx\"}","last_seen_at":
"{\"s\":\"2010-06-23 22:57:49 +0000\"}","target_id":"{\"n\":\"395\"}",
"count":"{\"n\":\"44\"}","promo_id":"{\"n\":\"125\"}"}} at
org.apache.hadoop.hive.ql.exec.MapOperator.process(MapOperator.java:550) at
org.apache.hadoop.hive.ql.exec.mr.ExecMapper.map(ExecMapper.java:177)
... 8 more Caused by: org.apache.hadoop.hive.ql.metadata.HiveException:
java.io.IOException: All datanodes 10.160.102.191:9200 are bad. Aborting... at
org.apache.hadoop.hive.ql.exec.FileSinkOperator.processOp(FileSinkOperator.java:651) at
org.apache.hadoop.hive.ql.exec.Operator.forward(Operator.java:793) at org.apach
</code></p>

<p><code>
2015-06-29 13:33:31,610 Stage-1 map = 100%, reduce = 0% MapReduce Total cumulative
CPU time: 14 minutes 19 seconds 0 msec Ended Job = job_1435578726935_0002 with
errors Error during job, obtaining debugging information...
Examining task ID: task_1435578726935_0002_m_000008 (and more) from job job_1435578726935_0002
Examining task ID: task_1435578726935_0002_m_000000 (and more) from job job_1435578726935_0002
Examining task ID: task_1435578726935_0002_m_000000 (and more) from job job_1435578726935_0002
Task with the most failures(4):
----- Task ID: task_1435578726935_0002_m_000003 URL: http://ip-10-160-25-23.ap-northeast-1.compute.
internal:9026/taskdetails.jsp?jobid=job_1435578726935_0002&amp;tipid=task_1435578726935_0002_m_000003
----- Diagnostic Messages for this Task: Error: GC overhead limit exceeded FAILED:
Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
MapReduce Jobs Launched: Job 0: Map: 10 Cumulative CPU: 859.0 sec HDFS Read: 0 HDFS Write: 0 FAIL Total MapRed
</code></p>

<p><code>
2015-06-30 02:32:17,929 Stage-1 map = 100%, reduce = 0%, Cumulative CPU 1605.94 sec
MapReduce Total cumulative CPU time: 26 minutes 45 seconds 940 msec Ended Job =
job_1435627213542_0001 with errors Error during job, obtaining debugging information...
Examining task ID: task_1435627213542_0001_m_000004 (and more) from job job_1435627213542_0001
Examining task ID: task_1435627213542_0001_m_000004 (and more) from job job_1435627213542_0001
Examining task ID: task_1435627213542_0001_m_000004 (and more) from job job_1435627213542_0001
Task with the most failures(4): ----- Task ID: task_1435627213542_0001_m_000000 URL:
http://ip-10-150-205-59.ap-northeast-1.compute.internal:9026/taskdetails.jsp?
jobid=job_1435627213542_0001&amp;tipid=task_1435627213542_0001_m_000000 -----
Diagnostic Messages for this Task: AttemptID:attempt_1435627213542_0001_m_000000_3
Timed out after 600 secs FAILED: Execution Error, return code 2 from
org.apache.hadoop.hive.ql.exec.mr.MapRedTask MapReduce Jobs Launched: Job 0: Map: 10 Cu
</code></p>

<p><code>
Error: java.lang.RuntimeException: Hive Runtime Error while closing operators at
org.apache.hadoop.hive.ql.exec.mr.ExecMapper.close(ExecMapper.java:260) at
org.apache.hadoop.mapred.MapRunner.run(MapRunner.java:81) at
org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:432) at
org.apache.hadoop.mapred.MapTask.run(MapTask.java:343) at
org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:175) at
java.security.AccessController.doPrivileged(Native Method) at
javax.security.auth.Subject.doAs(Subject.java:415) at
org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548) at
org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:170)
Caused by: org.apache.hadoop.hive.ql.metadata.HiveException:
java.io.IOException: All datanodes 10.186.28.181:9200 are bad.
Aborting... at org.apache.hadoop.hive.ql.exec.FileSinkOperator$FSPaths.closeWriters(FileSinkOperator.java:168) at
org.apache.hadoop.hive.ql.exec.FileSinkOperator.closeOp(FileSinkOperator.java:882) at org.apache.hadoop.
</code></p>

<p>Hive Runtime ErrorやGCエラー等が出てますね。</p>

<h3>原因</h3>

<p>通常のexportテンプレートではEMRはなんと<strong>m1.medium</strong>のcore taskが一台のみ起動して処理が走ります。
各種ヒープサイズの設定（<code>YARN_RESOURCEMANAGER_HEAPSIZE</code> 等）は<a href="https://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/HadoopMemoryDefault_H2.html">instance typeによって決まって</a>おり、この件数とデータサイズではHEAPSIZEが不足し、GCエラー等が発生してOut of Memory状態になって処理が落ちるようです。
そこで、メモリをもっと搭載している大きめのインスタンスでHEAPSIZEを確保してあげる必要があります。</p>

<h3>解決策</h3>

<p>こんな感じ。</p>

<p><img src="https://lh3.googleusercontent.com/ghExdELQB1cIE9K-d97gDqz7a634413GOTxAHhvJsBg"></p>

<table>
<thead>
<tr>
<th></th>
<th>parameter</th>
<th>default value</th>
<th>new value</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>core &amp; master instance type</td>
<td>m1.medium</td>
<td>m3.xlarge</td>
</tr>
<tr>
<td></td>
<td>core instance count</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td></td>
<td>AMI version</td>
<td>3.3.2</td>
<td>3.8.0</td>
</tr>
</tbody>
</table>


<p>m3.xlargeにした事で処理が落ちる事なくスムーズに実行されるようになりました。core countを増やしたのは、exportテンプレートのデフォルト設定だとcountが1なので、mapperが不足し、DynamoDBで設定したthroughput (1000)をフルに使い切る事ができなく、デフォルトのタイムアウト時間（2時間）に達して処理自体がキャンセルされてしまうからです。EMR側のスループットも上げる為に必要な変更でした。また、Hadoopの<a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/DeveloperGuide/ami-versions-supported.html">AMI version</a>も古い3.3.2から最新の3.8.0にしてあります。</p>

<p>これらによって、export処理がだいたい1時間ちょいで完了します。</p>

<p>その時の試行錯誤がこれ。</p>

<p><img src="https://lh3.googleusercontent.com/xatqR0hx1M6PhroKFNAksOplqgqYgqsaCJgonanQyzA=w437-h197-no"></p>

<h3>計算</h3>

<p>provisioned throughputに対するバックアップ時間の目安を計算するには以下の通り。</p>

<p>20GBのデータ、1億件のレコード、1000 throughputとして、</p>

<p><code>平均item size = 20*1024*1024*1024/100000000 =~  215 byte</code></p>

<p>4KB以下なので4KB blockのreadとなります。
Hive Queryのread処理は<a href="http://hipsterdevblog.com/blog/2015/05/30/analysing-dynamodb-index-usage-in-hive-queries/">eventually consistentになる</a>ので、1 IOPSに対して8KBのデータが読み込めます。
そうすると</p>

<p><code>DynamoDB scan時間 = (20*1024*1024*1024)/(1000*8*1024*60) = 43.7分</code></p>

<p>実際にはEMRクラスタのオーバーヘッドが20分弱程度あるので、これに若干加算します。</p>

<p>図にするとこんな風になります。</p>

<iframe width="670" height="412" seamless frameborder="0" scrolling="no" src="https://docs.google.com/spreadsheets/d/14oyOry-bnrqIgYxdN36Qdwv3VC1lhdku4QffzFh8iIc/pubchart?oid=1201814511&amp;format=interactive"></iframe>


<p>バックアップのタイミングでDynamoDBのthroughputをガツンと上げれば、件数によっては短時間で済む場合もあるので、参考にでも！</p>

<p>（※ Production Trafficに影響がないように、Read Throughput Percentは適切に設定する必要があります）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[EC2 Auto Recoveryの注意点]]></title>
    <link href="http://ijin.github.io/blog/2015/05/01/notes-on-ec2-auto-recovery/"/>
    <updated>2015-05-01T11:45:00+09:00</updated>
    <id>http://ijin.github.io/blog/2015/05/01/notes-on-ec2-auto-recovery</id>
    <content type="html"><![CDATA[<p>先日、EC2のAuto Recoveryでちょっとハマったのでメモ。</p>

<p>Cloudwatchの<code>StatusCheckFailed_System</code>アラームを設定すると、インスタンスを自動的に復旧してくれるEC2 Auto Recoveryという機能があり、使うためには条件がいくつかあります。</p>

<ul>
<li>特定のリージョン</li>
<li>C3, C4, M3, R3, T2 instances</li>
<li>VPC</li>
<li>共有tenancy</li>
<li>EBSストレージのみのサーバ</li>
</ul>


<p><a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-recover.html">Recover Your Instance</a></p>

<p>しかし、上記を満たしているのに、特定のAMIをCLI経由で起動するとEC2 Auto Recoveryを設定できなくなります。</p>

<p>（AWSコンソールでラジオボタンが押せない。CLIで設定しても効かない）
<img src="https://lh5.googleusercontent.com/-dwWUcfCssA4/VULwrOsgxNI/AAAAAAAABFo/VQy-GnIYQXg/w448-h186-no/Screenshot%2B2015-05-01%2B12.18.16.png"></p>

<p>原因はAMIにephemeral disk等のblock device mappingが設定されていて、T2やC4等のEBS onlyなinstance typeで起動しているにも関わらず、AWS側がephemeral diskが付与されていると認識してしまう所にあります。なお、AWSコンソールからの起動だとこの現象は発生しません。</p>

<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.1/gist-embed.min.js"></script>


<p>AMIでblock device mappingが埋め込まれている</p>

<pre><code>aws ec2 describe-images --image-ids ami-e74b60e6 --region ap-northeast-1
</code></pre>

<p><code data-gist-id="55659515d54593c29618" data-gist-highlight-line="21-28"></code></p>

<p>本来はEBS onlyなinstance typeだとblock device mappingの設定如何に関わらず、付与自体が不可能なので、全く関係ないはずです。</p>

<p>解決方法は現時点（2015/5/1）では3通り</p>

<ul>
<li>extraなmappingが設定されていないAMIを使う（Amazon Linux等）</li>
<li>AWSコンソールから起動する</li>
<li>明示的に<code>--block-device-mappings</code>パラメータで<code>NoDevice</code>と指定
<code>aws ec2 run-instances --image-id ami-e74b60e6 --instance-type t2.small --subnet-id subnet-xxxxxxxx --block-device-mappings "[{\"DeviceName\": \"/dev/sdb\",  \"NoDevice\": \"\"}, {\"DeviceName\": \"/dev/sdc\",  \"NoDevice\": \"\"}]"</code></li>
</ul>


<p>これは明らかにAWS側のバグなので早く治って欲しいものですね。</p>
]]></content>
  </entry>
  
</feed>
