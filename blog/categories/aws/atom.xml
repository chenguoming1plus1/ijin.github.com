<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: aws | @ijin]]></title>
  <link href="http://ijin.github.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://ijin.github.com/"/>
  <updated>2014-07-11T10:47:10+09:00</updated>
  <id>http://ijin.github.com/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS Game Day Japan 2014春を開催してきた]]></title>
    <link href="http://ijin.github.com/blog/2014/03/14/aws-game-day-japan-2014-spring/"/>
    <updated>2014-03-14T23:11:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/03/14/aws-game-day-japan-2014-spring</id>
    <content type="html"><![CDATA[<p>過去に2度参加した事（東京・ラスベガス）がある<a href="/blog/2013/06/10/aws-game-day-tokyo-2013/">Game Day</a>に今回は運営側に周りました。3/15に行われる<a href="http://jawsdays2014.jaws-ug.jp/">JAWS Days 2014</a>の前夜祭という位置づけです。</p>

<p>日本では前回、東京のみだったけど<a href="http://jaws-days.doorkeeper.jp/events/8945">今回</a>は東京・大阪・名古屋・仙台と4都市同時開催。</p>

<h2>お題</h2>

<p>前回と全く一緒。。SQSを使った疎結合でオートスケーリングする画像変換処理システム（ｻｰｾﾝ）。まあ、1年前と比べてAWSの機能やできる事も大分変わったので2回目の人もいろいろ工夫のしようがあったかと。</p>

<h2>チーム</h2>

<p>1チーム3〜4人に別れて計14チームとなりました。</p>

<p><strong>東京</strong></p>

<ul>
<li>Cookie Devil</li>
<li>Bluescreens</li>
<li>沖縄</li>
<li>Blue Light of Death</li>
<li>時計じかけのオレンジ</li>
<li>I am みどり</li>
</ul>


<p><strong>名古屋</strong></p>

<ul>
<li>Shachihoko</li>
<li>ななちゃんだがや</li>
<li>ゴーゴーひつまぶし</li>
</ul>


<p><strong>大阪</strong></p>

<ul>
<li>大都会</li>
<li>AWS学坊や</li>
<li>初心者</li>
</ul>


<p><strong>仙台</strong></p>

<ul>
<li>Zao</li>
<li>八重の桜</li>
</ul>


<h2>内容</h2>

<p>当日の迫力ある詳しい内容は参加者の方がきっとブログに書いてくれるはず！その代わり、運営側で評価用に使っていた攻撃・修復内容のまとめを公開して欲しいというツィートを頂いたので下記に表示しておきます。</p>

<p><div class='embed tweet'><blockquote class="twitter-tweet"><p>Gameday楽しめました。運営ありがとうございました。攻撃のサマリシート翻訳は誰?と思ってましたが恐縮です。あのシート何らかの形で公開頂けるとありがたいです。 QT <a href="https://twitter.com/ijin">@ijin</a>: 14チームのGoogleスプレッドシートのリアルタイム翻訳は結構ギリギリだった。</p>&mdash; Ryo Suzuki (@suzryo) <a href="https://twitter.com/suzryo/statuses/444450014627000320">March 14, 2014</a></blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></div></p>

<p>（実は今回もイベントオーナーのMiles Wardが来日していたので、Google Spreadsheetに書き込まれていた内容を運営側で逐一翻訳していました）</p>

<iframe src="https://docs.google.com/spreadsheets/d/16-qSbw_XQGgl_4bYqy9REL-nq15yOVj2f1HBJvMy_qM/pubhtml?widget=true&amp;headers=false" height="500" width="750"></iframe>


<p>個人的にはs3の「Requester Payオプション有効化」がお気に入りでしたね。</p>

<h2>結果</h2>

<p>総合優勝はチーム<strong>「AWS学坊や」</strong>の優勝となりました。おめでとうございます！
（地方賞はすみません、総合結果評議中で聞けてませんでした）</p>

<p>今回、運営側のトラブルで攻撃対象が重複してしまう等いろいろ問題がありましたが、開催する側としても楽しかったです。次回はさらにチャレンジングな内容にしていきたいと思っています。</p>

<h2>JAWS DAYS</h2>

<p>明日の<a href="http://jawsdays2014.jaws-ug.jp/">JAWS DAYS 2014</a>はスタッフとしていろいろ動くので今回は手短に。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[i2 instanceでMySQLベンチマーク]]></title>
    <link href="http://ijin.github.com/blog/2014/01/01/mysql-benchmarks-on-aws-i2-instance-ssds/"/>
    <updated>2014-01-01T00:00:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/01/01/mysql-benchmarks-on-aws-i2-instance-ssds</id>
    <content type="html"><![CDATA[<p>新年明けました。おめでとうございます。</p>

<p>すっかり12月の<a href="http://www.zusaar.com/event/1117005">aws</a>/<a href="http://www.zusaar.com/event/1847003">mysql</a> advent calendarに乗り遅れたので、AWSのi2 instanceでのMySQLのベンチマークを勝手におまけとして公表します。
以前取ったhi1.4xlargeとの比較になります。</p>

<h2>構築</h2>

<p>SSDディスクはAWSが<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/i2-instances.html#i2-instances-diskperf">推奨する</a>over-provisioningを有効にする為に10%を非partitionし、それぞれ720Gでパーティション作成。</p>

<pre><code>sudo mdadm --create /dev/md0 --level 0 --raid-devices 8 /dev/xvdb1 /dev/xvdc1  /dev/xvdd1 /dev/xvde1 /dev/xvdf1 /dev/xvdg1 /dev/xvdh1 /dev/xvdi1
sudo mkfs.xfs -f -b size=4096 -i size=512 -l size=64m /dev/md0
sudo mount -t xfs -o noatime,logbufs=8 /dev/md0 /data
</code></pre>

<p>OSはkernel versionが3.8以上が<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/i2-instances.html#i2-instances-diskperf">望ましい</a>のでいつものLTSではなく、Ubuntu Server 13.10のHVMタイプ (ami-b93264d0)</p>

<h2>sysbench</h2>

<p>やり方やパラメータは<a href="/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/">前回</a>の計測方法と同じ。i2.8xlaregは32coreですが、今回はhi1.4xlargeの時と比較する為に敢えて16スレッドで計測しました。</p>

<ul>
<li>sysbenchのoltpモード</li>
<li>データサイズは12G（5000万件）</li>
<li>readonly</li>
<li>uniform（フルスキャン）</li>
</ul>


<p>コマンド</p>

<pre><code>time sysbench --test=oltp --oltp-table-size=50000000 --db-driver=mysql --mysql-user=root --num-threads=16 --max-requests=0 --max-time=180 --init-rng=on --oltp-read-only=on --oltp-dist-type=uniform 2&gt;&amp;1 run
</code></pre>

<p>トランザクション推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=5&amp;zx=jwv2ytp6xwx3"></p>

<p>レスポンスタイム推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=6&amp;zx=sfl6ocblw5ob"></p>

<p>速いですね。</p>

<h2>tpcc-mysql</h2>

<p>こちらも<a href="/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/">前回</a>)の計測方法と同じ。</p>

<ul>
<li>500 warehouses (50GBぐらい)</li>
<li>24GB Buffer pool</li>
<li>16スレッド</li>
<li>1時間実行</li>
</ul>


<p>コマンド</p>

<pre><code> tpcc_load localhost tpcc root "" 500
 tpcc_start -d tpcc -u root -p "" -w 500 -c 16 -r 300 -l 3600
</code></pre>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=7&amp;zx=fc6nz8iel3ez"></p>

<p>hi1.4xlargeはSSD1台で計測した事を考えると、同価格帯のi2.4xlarge（SSD4台）の半分（SSD2台）のパフォーマンスが出るのは妥当ですね。</p>

<h2>fio</h2>

<p>ついでにfioでそれぞれRAID0した場合のベンチマークも取ってみたけど、<a href="http://d.hatena.ne.jp/rx7/20131224/p1">並河さん</a>と結果が違ってwriteがスケールしてます。OSとmkfs.xfsのオプションしか違わないはずだけど。。</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=9&amp;zx=v7nbywda04bp"></p>

<h2>その他</h2>

<p>いやー。spot instanceがないので計測だけで結構かかってしまった。</p>

<p>しかし、なんでhi1世代の次はhi2ではなく、i2なんだろう。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Autoscalingによる自動復旧(Immutable Infrastucture)]]></title>
    <link href="http://ijin.github.com/blog/2013/12/14/self-healing-with-non-elb-autoscaling2/"/>
    <updated>2013-12-14T23:40:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/12/14/self-healing-with-non-elb-autoscaling2</id>
    <content type="html"><![CDATA[<p>以前、「<a href="/blog/2013/02/08/self-healing-with-non-elb-autoscaling/">非ELBなAutoscalingによる自動復旧</a>」でインスタンスの自動復旧の挙動をテストしました。
障害が発生したサーバをterminateし、新サーバをstartしてリプレースする仕組みはまさに最近話題のImmutable Infrastructureですね。
CDP的には「<a href="http://aws.clouddesignpattern.org/index.php/CDP:Server_Swapping%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Server Swappingパターン</a>」が一番近いですが、今後はImmutable分類もあっても良いような気がします。</p>

<p>前回はAuto Scalingがインスタンス障害を検知してリプレースするまでのタイムラグが約20分だと分かりました。
本日、インスタンスの状態をチェックするEC2 Status Checkが1分間隔になった（以前は5分間隔）と<a href="https://forums.aws.amazon.com/ann.jspa?annID=2266">発表</a>されたので、
これによってタイムラグが短縮されたかを検証してみます。</p>

<h3>設定</h3>

<p>手順は前回と一緒なので省略</p>

<h3>自動復旧</h3>

<p>通信を遮断し、Status Check Failを発動させる
<code>
ubuntu@ip-10-123-32-180:~$ date; sudo ifdown eth0
Sat Dec 14 14:19:19 UTC 2013
Write failed: Broken pipe
</code></p>

<p>EC2のStatus Checkを流す</p>

<pre><code>while true; do date; aws ec2 describe-instance-status --instance-ids i-b03788b5 --query 'InstanceStatuses[*].InstanceStatus' --output text ; echo ; sleep 10; done
</code></pre>

<p>```
Sat Dec 14 23:22:05 JST 2013
ok
DETAILS reachability    passed</p>

<p>Sat Dec 14 23:22:16 JST 2013
ok
DETAILS reachability    passed</p>

<p>Sat Dec 14 23:22:27 JST 2013
impaired
DETAILS 2013-12-14T14:22:00.000Z        reachability    failed</p>

<p>Sat Dec 14 23:22:37 JST 2013
impaired
DETAILS 2013-12-14T14:22:00.000Z        reachability    failed
```</p>

<p>約3分でStatus異常が検知されました。</p>

<p><img src="https://lh5.googleusercontent.com/-pabfvBU5fW0/Uqx4SEmBYLI/AAAAAAAAA2E/abCLUwoESds/w734-h154-no/Instance_status_check_2013-12-14+at+11.34.27+PM.png"></p>

<p>Auto ScalingのHealthStatusを流す</p>

<pre><code>while true; do date; aws autoscaling describe-auto-scaling-instances --query 'AutoScalingInstances[*].HealthStatus' --output text; echo; sleep 10; done
</code></pre>

<p>```
Sat Dec 14 23:38:06 JST 2013
[</p>

<pre><code>{
    "State": "InService", 
    "Health": "HEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:17 JST 2013
[</p>

<pre><code>{
    "State": "InService", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:28 JST 2013
[</p>

<pre><code>{
    "State": "InService", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:38 JST 2013
[</p>

<pre><code>{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:49 JST 2013
[</p>

<pre><code>{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:59 JST 2013
[</p>

<pre><code>{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:39:10 JST 2013
[</p>

<pre><code>{
    "State": "Pending", 
    "Health": "HEALTHY", 
    "ID": "i-4cc7a849"
}, 
{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>```
やっとAuto Scalingの方でも異常検知。</p>

<p><img src="https://lh4.googleusercontent.com/-8Dj_s0mm9I8/Uqx4R1-Wl9I/AAAAAAAAA2I/laUZmwhUw8o/w873-h151-no/Autoscaling_health_2013-12-14+at+11.57.42+PM.png"></p>

<p>SNS通知</p>

<p><code>
Service: AWS Auto Scaling
Time: 2013-12-14T14:39:41.271Z
RequestId: f622c6d2-8c77-4fef-8b38-ece463574712
Event: autoscaling:EC2_INSTANCE_TERMINATE
AccountId: 111155559999
AutoScalingGroupName: test-sg
AutoScalingGroupARN: arn:aws:autoscaling:ap-northeast-1:11115559999:autoScalingGroup:0e771015-f979-4afe-b065-595abafdbf9b:autoScalingGroupName/test-sg
ActivityId: f622c6d2-8c77-4fef-8b38-ece463574712
Description: Terminating EC2 instance: i-b03788b5
Cause: At 2013-12-14T14:38:38Z an instance was taken out of service in response to a system health-check.
StartTime: 2013-12-14T14:38:38.257Z
EndTime: 2013-12-14T14:39:41.271Z
StatusCode: InProgress
StatusMessage:
Progress: 50
EC2InstanceId: i-b03788b5
</code></p>

<p>やはり20分のタイムラグ変わらずですね。。</p>

<h3>結論</h3>

<p>というわけで、EC2 Status Checkが1分間隔になっても、EC2のみ（ELBを使わい場合）のAuto Scalingによる不調インスタンスの自動復旧時間は変わらずでした。</p>

<p>ちなみにAWS ConsoleでAuto Scalingの設定ができるようになったけど、まだscaling groupにtagが付けられないのがちょっと微妙ですね。。GUIで状態を見る分には楽だけど。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Game Day Tokyo 2013で受賞してきた]]></title>
    <link href="http://ijin.github.com/blog/2013/06/10/aws-game-day-tokyo-2013/"/>
    <updated>2013-06-10T23:33:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/06/10/aws-game-day-tokyo-2013</id>
    <content type="html"><![CDATA[<p>大統領選挙でオバマ陣営のシステムを堅牢化する為に用いた手法である仮想対戦シミュレーション「<a href="http://gameday2013.doorkeeper.jp/events/3960">AWS Game Day Tokyo</a>」が日本で初めて（世界2番目に）開催されたので参加してきました。</p>

<p>結果、ベスト・ディフェンス賞こと「<strong>Most Awesome Fix!</strong>」賞を受賞しました。</p>

<h2>経緯</h2>

<p>以前、<a href="http://jaws-ug.jp/jawsdays2013/">JAWS DAYS 2013</a>でMiles Wardが講演した「<a href="http://www.publickey1.jp/blog/13/obama_for_america.html">Behind the Scenes of the Presidential Campaign</a>」でチームを攻撃・防御に分けて対戦させ、そこから学んだ事をフィードバックしてシステムをより堅牢にするという「Game Day」を知り、日本でもやりたいねという話になってました。そこで先日の<a href="http://www.awssummittokyo.com/">AWS Summit Tokyo</a>のスピンオフイベントとして、Milesの再来日に合せてADSJ（アマゾンデータサービスジャパン株式会社）さんによって開催される事になりました。チーム戦の大会は<a href="http://ijin.github.io/blog/2012/07/03/tuningathon4/">チューニンガソン</a>や<a href="http://ijin.github.io/blog/2012/11/05/isucon2/">ISUCON</a>以来なので、わくわくしながら速攻で応募をしました。</p>

<h2>概要</h2>

<p>大体、こんな流れです。</p>

<ul>
<li>システムの構築・堅牢化</li>
<li>相手システムの攻撃（この間、自システムも攻撃される）</li>
<li>自システムの修復</li>
<li>評価</li>
</ul>


<p>それぞれ、2〜3人のチームに別れ、計18チームにより対戦。私のチーム名は時事ネタとして今流行りの「<a href="http://jp.techcrunch.com/2013/06/07/20130606report-nsa-collects-data-directly-from-servers-of-google-apple-microsoft-facebook-and-more/">PRISM</a>」としました。
システム概要はnginksさんの<a href="http://d.hatena.ne.jp/nginks/20130608/1370700185">ブログ</a>が非常に分かりやすいです。
要するに画像変換処理バッチクラスターですね。</p>

<h2>構築</h2>

<p>手順書をざっと見ながら画像処理クラスターを構築。相方はシステムの人間ではなかったので、動作確認を手伝ってもらいつつ実質一人でもくもくと作業。s3作成、sqs作成、アプリのインストール・設定・動作確認、AMI化、Cloudwatch設定、AutoScaling設定等を淡々と。構築しながらシステムを把握して行くけど、結構これだけで時間がとられます。なので、じっくりと防衛策は練れなかったのでひとまず、プロセスの自動復旧をしてくれるmonitをインストール・設定し（upstartでやりかけたけどうまく動かなかった）、主要ファイルのchecksumを取って改善検知してメール通知する仕組みを導入。</p>

<h2>攻撃</h2>

<p>AWSキー（Poweruser権限）を奪取したという仮定の元、相手システムに攻撃をしかけるターン。
単純に全部消したり、セキュリティグループの権限を変えたりではあまりにもつまらないので、いろいろ考えます。（無論、システムの全消しは誰でもできる最低の攻撃手法）</p>

<p>まず、状況把握する為にいろいろ動作確認。キューに画像を突っ込んで、ちゃんと処理されるとか。あれ、でも動かない。。
どうやらTokyoで作りかけたけど、結局Virginiaリージョンで仕上げたと運営側から伝えられる。いきなりのタイムロス！</p>

<p>気を取り直して、稼働中のインスタンスに入る方法を思いつく。通常はキー設定されているのでsshでは入れないので仮のインスタンスを起動し旧インスタンスのroot volumeのEBSを強制detachし、仮インスタンスにattachして中身をいじってからre-attachする事に。見た目は同じinstance-idなのに中身だけ違う、一見すると分かりづらいです。そこで旧インスタンスを一旦停止させる為にstopさせると、、terminateされちゃいました。。よくよく調べて見ると、Auto Scalingの設定になっていて、min-sizeの制約によって旧インスタンスが消され、代替インスタンスが自動的に起動するようになってました。</p>

<p>どうやら構築が間に合わなかったチーム用に運営側が用意した自動構築をしてくれる虎の子のCloudformationを使った模様。
そこで、相手チームのスキルレベルがそれ程高くないと判断し、Auto Scalingの元AMIを置き換える事に。
新たなlaunch configを作成し、既存のscaling groupと同盟のものを作成。</p>

<p>次にs3への攻撃。bucket名はglobalなnamespaceなので、こいつを削除して同名のを別AWSアカウントで作れば乗っ取りが可能。。
のはずが、削除してから一定時間経過しないと作成不可だったので1字違いのbucketを作成しておく。</p>

<p>最後にs3のbucket一覧を取得して、常に空のディレクトリと同期し続ける攻撃を思いつき、実装を始める。システムはs3に出力するのでそこを継続的に空にする攻撃です。しかし、実装を初めて動作確認の途中で時間切れになりシステムに埋め込めなくて断念。もうちょっと時間が欲しかったです</p>

<h2>修復</h2>

<p>次は自システムが受けた攻撃を修復するターン。</p>

<p>いろいろ余計なインスタンスが起動していたが、まずやったのがAMI番号の確認。（これが無事であればOSに侵入されていようがAMIをベースに全体の再構築が速やかにできるので）
幸い、控えていたのと一致していたので他のインスタンスを全て停止。一応monitのアラートメールが飛んでいなかったので、インスタンスに対しての操作は限定されているのだろうとは踏んでましたが。</p>

<p>AMIが無事なら次はAuto Scalingの確認。ざっと見た感じだと、lauch configは操作されておらず、scaling groupのmin-sizeが0に変更されている模様。他の変更点は確認が面倒だったので、一旦全部削除してさくっと再作成。後で聞いた話だと、Auto Scalingのrecurring schedule設定で1分起きに0台にする設定をしていたらしいが、消された時点で攻撃は無効化。</p>

<p>次にSQS。消して再作成すればてっとり早いけど、相手チームがキューに投入した画像を最終的に表示させないといけないルールだと誤解していて、その復旧に務める。新しく作ったSQSと比較するとパラメータ（Default Visibility Timeout, Retention Period, Message Size等）が異常な値に変更されていると分かり、通常の値へ戻す。</p>

<p>この時点でアプリとSQSの通信を確認するも疎通できない事を把握。pingが通らない事からSecurity Group, Routing Table, Network ACLが変更されていないかを確認。どうやらSecurity GroupのIn/Outルールが削除されている単純な攻撃だと判明し、なんなく再設定。</p>

<p>キュー内のメッセージが1コ処理されるのを確認し、SQS周りは対応済みかと思ったけど残り2コのメッセージがいくら待てども処理されず、若干悩む。
ログを見たり、メッセージの中身を覗くとと「<strong>--max-redirect=99999999</strong> 」が目に留まる。どうやら変換する画像をダウンロードする部分で無限ループさせている模様。メッセージを削除し、そのパラメータを除外したものを流してちゃんとキューが処理される事を確認。</p>

<p>最後にs3周りで怪しい設定がないかを調査して、一通りの動作確認をして復旧完了。</p>

<h2>振り返り</h2>

<p>お互いに対戦したチームと顔合わせをし、攻撃や復旧の手の内を明かします。全チームの行動記録を集約して運営側で審査を行われ各賞が授与される中、我がPRISMはSQS内の無限ループを検知・修復したのが評価されて最も優れた修復を行った「<strong>Most Awesome Fix!賞</strong>」を頂きました。後で他のチームに聞いた所、monitのような検知・通知の仕組みを導入した所はなさそうだったので、それも評価ポイントだったかも知れません。</p>

<p>賞の内容としては、ワンタイムトークンを生成するハードウェアMFAデバイスとAWSのクーポンコードでした。ありがとうございます。</p>

<p>最後にMilesが壊れても戻せるようにあるべき状態の定義と常に比較して自動的に自己治癒するのが最高のシステムと言ってました。AWSの状態を保存するにはCloudformerでCloudformationテンプレート化すれば便利で楽だけど、chefみたいにIdempotency（冪等性）を継続的に保証する仕組みをそのレイヤーで組むのはなかなか大変ですね。（個々のサーバ単位は可能だとしても）</p>

<h2>感想</h2>

<p>「<em>チューニンガソン</em>」や私が他にお手伝いをしている「<em>トラブル☆しゅーたーず</em>」とも一味違って、非常に楽しめました。</p>

<p>以下、思った事をいくつか。</p>

<ul>
<li>構築に時間が取られたのでなるべく出来合いのシステムがあった方が防衛策に専念できそう</li>
<li>攻撃可能な時間が思ったより短かったのでもうちょっと長めで</li>
<li>Default-VPCとEC2-Classicでは挙動が違うのでアカウントタイプは統一した方が良い</li>
<li>ターン性ではなく、攻撃と修復・防御のリアルタイム性を試すとか</li>
<li>あるべき正しい状態を把握する為のツールがあると他のタスクに集中できるかも</li>
</ul>


<p>次に開催される時も参加したいですね。もしくは運営側のお手伝いでも！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Non-RDSなオレオレMulti-AZ MySQL Replication]]></title>
    <link href="http://ijin.github.com/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication/"/>
    <updated>2013-05-21T18:03:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication</id>
    <content type="html"><![CDATA[<p>先日（5/17/13）<a href="http://www.zusaar.com/event/668006">cloudpack night #6 - Re:Generate -</a>に参加してきました。</p>

<p>当日の様子はcloudpack<a href="https://twitter.com/yoshidashingo">吉田</a>さんの以下のレポートで。<br />
<a href="http://d.hatena.ne.jp/yoshidashingo/20130518/1368853720">cloudpack Night #6 - re:Generate - を開催しました</a></p>

<p>私はDJを少々とLTで参加させて頂いたのでその内容になります。</p>

<h2>オレオレMulti-AZのススメ</h2>

<p>AWS上でMySQLを使う場合、RDSはてっとり早くて良いんですが、たまにもうちょっと柔軟性が欲しい時があります。
例えば別のストーレジエンジンやディストリビューションを使ったり（Percona Server, MariaDB, TokuDB, Mronnga等）、RDSでは使えないインスタンスファミリー（hi1, m3, c1系）を使ったり、OSレベルでのチューニングができたり、スレーブのバッファプールを予め温めておいたり。等々。</p>

<p>しかし、RDSにはAvailability Zone (AZ)をまたいでフェールオーバーするMulti-AZ機能があり、AWSで設計するにはAZ障害を考慮した方が推奨されます。</p>

<p>そこで、MHAとVPCを組み合わせて柔軟性をもったMulti-AZ環境を実現します。
（ちなみに私の場合はhi1.4xlargeでPercona Serverを冗長化をする必要があったから）</p>

<h3>MHA</h3>

<p><a href="https://code.google.com/p/mysql-master-ha/">MHA</a>とはFacebookの<a href="http://yoshinorimatsunobu.blogspot.jp/">松信</a>さんがDeNA時代に作ったMySQLの自動フェールオーバーしてくれうナイスなツールです。Master障害時にbinlog同期とSlaveの昇格を全自動でやってくれます。昇格時にはカタログデータベースに更新をかけて新DB構成のIPの情報を更新するか、Virtual IPを切り替えるかをする必要（この担当部分はmaster_ip_failover_scriptで対応）があるけど、今回は後者的なアプローチになります。</p>

<h3>VPC</h3>

<p>ENIを使えばVirtual IP的な使い方はできるけどAZは超えられないので、source/dest. checkを無効化した上でrouting tableによって擬似Virtual IPを実現する<a href="http://aws.clouddesignpattern.org/index.php/CDP:Routing-Based_HA%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Routing-Based HAパターン</a>（CDP 2.0候補）を使います。ADSJ<a href="https://twitter.com/c9katayama">片山</a>さんの<a href="http://d.hatena.ne.jp/c9katayama/20111225/1324837509">エントリ</a>が発端ですね。</p>

<h2>Demo</h2>

<p>以下、LT時に見せたデモ動画</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/tovb29K6ddc "></iframe></div></p>

<p>擬似Virtual IPに対してそれぞれread/writeを行いつつMasterのプロセスをkillすると、通信できなくエラーが出続けるが20秒以内に自動フェールオーバーが完了しread/write共に再開します。pingも平均0.5msから2.0msに変わった事からAZが移った事が確認できます。</p>

<p>RDSのMulti-AZの場合、フェールオーバーには3-6分かかるので、かなり短時間で復旧が可能です。
また、RDSはCNAME切替によるDNSベースに対して、MHA+VPC構成の場合はIP指定することができます。そうするとアプリからのresolveが不要になり、去年起こった内部DNSが引けない障害が起きても問題ありません。</p>

<h2>注意点</h2>

<ul>
<li>RDSな自動バックアップがない

<ul>
<li>Xtrabackupとbinlogの定期s3保存で対応</li>
</ul>
</li>
<li>Point in Timeリカバリー

<ul>
<li>Chef等で自動化しましょう</li>
</ul>
</li>
<li>Read Replicaの作成

<ul>
<li>Chefで頑張りましょう</li>
</ul>
</li>
<li>学習曲線

<ul>
<li>勉強しましょう</li>
</ul>
</li>
<li>API backplaneがSPoF

<ul>
<li>AWSに祈りましょう</li>
</ul>
</li>
</ul>


<p>特に一番の懸念点は最後のAPI backplane。AWSの今までの大規模障害状況を見ていると、皆が同時に復旧をしようとしAPIへのリクエストが大量に集中してそこがボトルネックになり、リソースの操作不能に陥るという悲惨な事象が何回かありました。まあ、その場合はRDSでも同じような気はしますが、ここは当時の障害を経験にキャパシティが増加されている事を信じておくしかありませんね。。</p>

<h2>おわりに</h2>

<p>とまあ、こんなLTをしたわけですが、この後に続いたCookpadの<a href="https://twitter.com/sgwr_dts">菅原</a>さんの<a href="http://www.slideshare.net/winebarrel/ec2keepalivedlvsdsr">LT</a>の方が盛り上がって自分のは余興に終わってしまいました。</p>

<p>あ、ついでにその日はcpniteの資料作成やDJの選曲であんまり寝てなかったにもかかわらず、無事AWSソリューションアーキテクト（Associate）の認定試験に受かりました！</p>

<p><img src="https://lh5.googleusercontent.com/-d_HVsb6DgBc/UZs39XB1KGI/AAAAAAAAAuw/ntgPp33hcOI/w294-h120-no/Solutions-Architect-Associate.png"></p>

<h2>LTスライド</h2>

<p><div class="embed-ss-container"><iframe src="http://www.slideshare.net/slideshow/embed_code/21341276 "></iframe></div></p>
]]></content>
  </entry>
  
</feed>
