<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: aws | @ijin]]></title>
  <link href="http://ijin.github.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://ijin.github.com/"/>
  <updated>2014-01-01T01:29:29+09:00</updated>
  <id>http://ijin.github.com/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[i2 instanceでMySQLベンチマーク]]></title>
    <link href="http://ijin.github.com/blog/2014/01/01/mysql-benchmarks-on-aws-i2-instance-ssds/"/>
    <updated>2014-01-01T00:00:00+09:00</updated>
    <id>http://ijin.github.com/blog/2014/01/01/mysql-benchmarks-on-aws-i2-instance-ssds</id>
    <content type="html"><![CDATA[<p>新年明けました。おめでとうございます。</p>

<p>すっかり年末の<a href="http://www.zusaar.com/event/1117005">aws</a>/<a href="http://www.zusaar.com/event/1847003">mysql</a> advent calendarに乗り遅れたので、AWSのi2 instanceでのMySQLのベンチマークを公表します。
以前取ったhi1.4xlargeとの比較になります。</p>

<h2>構築</h2>

<p>SSDディスクはAWSが<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/i2-instances.html#i2-instances-diskperf">推奨する</a>over-provisioningを有効にする為に10%を非partitionし、それぞれ720Gでパーティション作成。</p>

<pre><code>sudo mdadm --create /dev/md0 --level 0 --raid-devices 8 /dev/xvdb1 /dev/xvdc1  /dev/xvdd1 /dev/xvde1 /dev/xvdf1 /dev/xvdg1 /dev/xvdh1 /dev/xvdi1
sudo mkfs.xfs -f -b size=4096 -i size=512 -l size=64m /dev/md0
sudo mount -t xfs -o noatime,logbufs=8 /dev/md0 /data
</code></pre>

<p>OSはkernel versionが3.8以上が<a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/i2-instances.html#i2-instances-diskperf">望ましい</a>のでいつものLTSではなく、Ubuntu Server 13.10のHVMタイプ (ami-b93264d0)</p>

<h2>sysbench</h2>

<p>やり方やパラメータは<a href="//blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/">前回</a>の計測方法と同じ。i2.8xlaregは32coreですが、今回はhi1.4xlargeの時と比較する為に敢えて16スレッドで計測しました。</p>

<ul>
<li>sysbenchのoltpモード</li>
<li>データサイズは12G（5000万件）</li>
<li>readonly</li>
<li>uniform（フルスキャン）</li>
</ul>


<p>コマンド</p>

<pre><code>time sysbench --test=oltp --oltp-table-size=50000000 --db-driver=mysql --mysql-user=root --num-threads=16 --max-requests=0 --max-time=180 --init-rng=on --oltp-read-only=on --oltp-dist-type=uniform 2&gt;&amp;1 run
</code></pre>

<p>トランザクション推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=5&amp;zx=jwv2ytp6xwx3"></p>

<p>レスポンスタイム推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=6&amp;zx=sfl6ocblw5ob"></p>

<p>速いですね。</p>

<h2>tpcc-mysql</h2>

<p>こちらも<a href="//blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/">前回</a>)の計測方法と同じ。</p>

<ul>
<li>500 warehouses (50GBぐらい)</li>
<li>24GB Buffer pool</li>
<li>16スレッド</li>
<li>1時間実行</li>
</ul>


<p>コマンド</p>

<pre><code> tpcc_load localhost tpcc root "" 500
 tpcc_start -d tpcc -u root -p "" -w 500 -c 16 -r 300 -l 3600
</code></pre>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=7&amp;zx=fc6nz8iel3ez"></p>

<p>hi1.4xlargeはSSD1台で計測した事を考えると、同価格帯のi2.4xlarge（SSD4台）の半分（SSD2台）のパフォーマンスが出るのは妥当ですね。</p>

<h2>fio</h2>

<p>ついでにfioでそれぞれRAID0した場合のベンチマークも取ってみたけど、<a href="http://d.hatena.ne.jp/rx7/20131224/p1">並河さん</a>と結果が違ってwriteがスケールしてます。OSとmkfs.xfsのオプションしか違わないはずだけど。。</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=9&amp;zx=v7nbywda04bp"></p>

<p>いやー。spot instanceがないので計測だけで結構かかってしまった。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Autoscalingによる自動復旧(Immutable Infrastucture)]]></title>
    <link href="http://ijin.github.com/blog/2013/12/14/self-healing-with-non-elb-autoscaling2/"/>
    <updated>2013-12-14T23:40:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/12/14/self-healing-with-non-elb-autoscaling2</id>
    <content type="html"><![CDATA[<p>以前、「<a href="/blog/2013/02/08/self-healing-with-non-elb-autoscaling/">非ELBなAutoscalingによる自動復旧</a>」でインスタンスの自動復旧の挙動をテストしました。
障害が発生したサーバをterminateし、新サーバをstartしてリプレースする仕組みはまさに最近話題のImmutable Infrastructureですね。
CDP的には「<a href="http://aws.clouddesignpattern.org/index.php/CDP:Server_Swapping%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Server Swappingパターン</a>」が一番近いですが、今後はImmutable分類もあっても良いような気がします。</p>

<p>前回はAuto Scalingがインスタンス障害を検知してリプレースするまでのタイムラグが約20分だと分かりました。
本日、インスタンスの状態をチェックするEC2 Status Checkが1分間隔になった（以前は5分間隔）と<a href="https://forums.aws.amazon.com/ann.jspa?annID=2266">発表</a>されたので、
これによってタイムラグが短縮されたかを検証してみます。</p>

<h3>設定</h3>

<p>手順は前回と一緒なので省略</p>

<h3>自動復旧</h3>

<p>通信を遮断し、Status Check Failを発動させる
<code>
ubuntu@ip-10-123-32-180:~$ date; sudo ifdown eth0
Sat Dec 14 14:19:19 UTC 2013
Write failed: Broken pipe
</code></p>

<p>EC2のStatus Checkを流す</p>

<pre><code>while true; do date; aws ec2 describe-instance-status --instance-ids i-b03788b5 --query 'InstanceStatuses[*].InstanceStatus' --output text ; echo ; sleep 10; done
</code></pre>

<p>```
Sat Dec 14 23:22:05 JST 2013
ok
DETAILS reachability    passed</p>

<p>Sat Dec 14 23:22:16 JST 2013
ok
DETAILS reachability    passed</p>

<p>Sat Dec 14 23:22:27 JST 2013
impaired
DETAILS 2013-12-14T14:22:00.000Z        reachability    failed</p>

<p>Sat Dec 14 23:22:37 JST 2013
impaired
DETAILS 2013-12-14T14:22:00.000Z        reachability    failed
```</p>

<p>約3分でStatus異常が検知されました。</p>

<p><img src="https://lh5.googleusercontent.com/-pabfvBU5fW0/Uqx4SEmBYLI/AAAAAAAAA2E/abCLUwoESds/w734-h154-no/Instance_status_check_2013-12-14+at+11.34.27+PM.png"></p>

<p>Auto ScalingのHealthStatusを流す</p>

<pre><code>while true; do date; aws autoscaling describe-auto-scaling-instances --query 'AutoScalingInstances[*].HealthStatus' --output text; echo; sleep 10; done
</code></pre>

<p>```
Sat Dec 14 23:38:06 JST 2013
[</p>

<pre><code>{
    "State": "InService", 
    "Health": "HEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:17 JST 2013
[</p>

<pre><code>{
    "State": "InService", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:28 JST 2013
[</p>

<pre><code>{
    "State": "InService", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:38 JST 2013
[</p>

<pre><code>{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:49 JST 2013
[</p>

<pre><code>{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:38:59 JST 2013
[</p>

<pre><code>{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>Sat Dec 14 23:39:10 JST 2013
[</p>

<pre><code>{
    "State": "Pending", 
    "Health": "HEALTHY", 
    "ID": "i-4cc7a849"
}, 
{
    "State": "Terminating", 
    "Health": "UNHEALTHY", 
    "ID": "i-b03788b5"
}
</code></pre>

<p>]</p>

<p>```
やっとAuto Scalingの方でも異常検知。</p>

<p><img src="https://lh4.googleusercontent.com/-8Dj_s0mm9I8/Uqx4R1-Wl9I/AAAAAAAAA2I/laUZmwhUw8o/w873-h151-no/Autoscaling_health_2013-12-14+at+11.57.42+PM.png"></p>

<p>SNS通知</p>

<p><code>
Service: AWS Auto Scaling
Time: 2013-12-14T14:39:41.271Z
RequestId: f622c6d2-8c77-4fef-8b38-ece463574712
Event: autoscaling:EC2_INSTANCE_TERMINATE
AccountId: 111155559999
AutoScalingGroupName: test-sg
AutoScalingGroupARN: arn:aws:autoscaling:ap-northeast-1:11115559999:autoScalingGroup:0e771015-f979-4afe-b065-595abafdbf9b:autoScalingGroupName/test-sg
ActivityId: f622c6d2-8c77-4fef-8b38-ece463574712
Description: Terminating EC2 instance: i-b03788b5
Cause: At 2013-12-14T14:38:38Z an instance was taken out of service in response to a system health-check.
StartTime: 2013-12-14T14:38:38.257Z
EndTime: 2013-12-14T14:39:41.271Z
StatusCode: InProgress
StatusMessage:
Progress: 50
EC2InstanceId: i-b03788b5
</code></p>

<p>やはり20分のタイムラグ変わらずですね。。</p>

<h3>結論</h3>

<p>というわけで、EC2 Status Checkが1分間隔になっても、EC2のみ（ELBを使わい場合）のAuto Scalingによる不調インスタンスの自動復旧時間は変わらずでした。</p>

<p>ちなみにAWS ConsoleでAuto Scalingの設定ができるようになったけど、まだscaling groupにtagが付けられないのがちょっと微妙ですね。。GUIで状態を見る分には楽だけど。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS Game Day Tokyo 2013で受賞してきた]]></title>
    <link href="http://ijin.github.com/blog/2013/06/10/aws-game-day-tokyo-2013/"/>
    <updated>2013-06-10T23:33:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/06/10/aws-game-day-tokyo-2013</id>
    <content type="html"><![CDATA[<p>大統領選挙でオバマ陣営のシステムを堅牢化する為に用いた手法である仮想対戦シミュレーション「<a href="http://gameday2013.doorkeeper.jp/events/3960">AWS Game Day Tokyo</a>」が日本で初めて（世界2番目に）開催されたので参加してきました。</p>

<p>結果、ベスト・ディフェンス賞こと「<strong>Most Awesome Fix!</strong>」賞を受賞しました。</p>

<h2>経緯</h2>

<p>以前、<a href="http://jaws-ug.jp/jawsdays2013/">JAWS DAYS 2013</a>でMiles Wardが講演した「<a href="http://www.publickey1.jp/blog/13/obama_for_america.html">Behind the Scenes of the Presidential Campaign</a>」でチームを攻撃・防御に分けて対戦させ、そこから学んだ事をフィードバックしてシステムをより堅牢にするという「Game Day」を知り、日本でもやりたいねという話になってました。そこで先日の<a href="http://www.awssummittokyo.com/">AWS Summit Tokyo</a>のスピンオフイベントとして、Milesの再来日に合せてADSJ（アマゾンデータサービスジャパン株式会社）さんによって開催される事になりました。チーム戦の大会は<a href="http://ijin.github.io/blog/2012/07/03/tuningathon4/">チューニンガソン</a>や<a href="http://ijin.github.io/blog/2012/11/05/isucon2/">ISUCON</a>以来なので、わくわくしながら速攻で応募をしました。</p>

<h2>概要</h2>

<p>大体、こんな流れです。</p>

<ul>
<li>システムの構築・堅牢化</li>
<li>相手システムの攻撃（この間、自システムも攻撃される）</li>
<li>自システムの修復</li>
<li>評価</li>
</ul>


<p>それぞれ、2〜3人のチームに別れ、計18チームにより対戦。私のチーム名は時事ネタとして今流行りの「<a href="http://jp.techcrunch.com/2013/06/07/20130606report-nsa-collects-data-directly-from-servers-of-google-apple-microsoft-facebook-and-more/">PRISM</a>」としました。
システム概要はnginksさんの<a href="http://d.hatena.ne.jp/nginks/20130608/1370700185">ブログ</a>が非常に分かりやすいです。
要するに画像変換処理バッチクラスターですね。</p>

<h2>構築</h2>

<p>手順書をざっと見ながら画像処理クラスターを構築。相方はシステムの人間ではなかったので、動作確認を手伝ってもらいつつ実質一人でもくもくと作業。s3作成、sqs作成、アプリのインストール・設定・動作確認、AMI化、Cloudwatch設定、AutoScaling設定等を淡々と。構築しながらシステムを把握して行くけど、結構これだけで時間がとられます。なので、じっくりと防衛策は練れなかったのでひとまず、プロセスの自動復旧をしてくれるmonitをインストール・設定し（upstartでやりかけたけどうまく動かなかった）、主要ファイルのchecksumを取って改善検知してメール通知する仕組みを導入。</p>

<h2>攻撃</h2>

<p>AWSキー（Poweruser権限）を奪取したという仮定の元、相手システムに攻撃をしかけるターン。
単純に全部消したり、セキュリティグループの権限を変えたりではあまりにもつまらないので、いろいろ考えます。（無論、システムの全消しは誰でもできる最低の攻撃手法）</p>

<p>まず、状況把握する為にいろいろ動作確認。キューに画像を突っ込んで、ちゃんと処理されるとか。あれ、でも動かない。。
どうやらTokyoで作りかけたけど、結局Virginiaリージョンで仕上げたと運営側から伝えられる。いきなりのタイムロス！</p>

<p>気を取り直して、稼働中のインスタンスに入る方法を思いつく。通常はキー設定されているのでsshでは入れないので仮のインスタンスを起動し旧インスタンスのroot volumeのEBSを強制detachし、仮インスタンスにattachして中身をいじってからre-attachする事に。見た目は同じinstance-idなのに中身だけ違う、一見すると分かりづらいです。そこで旧インスタンスを一旦停止させる為にstopさせると、、terminateされちゃいました。。よくよく調べて見ると、Auto Scalingの設定になっていて、min-sizeの制約によって旧インスタンスが消され、代替インスタンスが自動的に起動するようになってました。</p>

<p>どうやら構築が間に合わなかったチーム用に運営側が用意した自動構築をしてくれる虎の子のCloudformationを使った模様。
そこで、相手チームのスキルレベルがそれ程高くないと判断し、Auto Scalingの元AMIを置き換える事に。
新たなlaunch configを作成し、既存のscaling groupと同盟のものを作成。</p>

<p>次にs3への攻撃。bucket名はglobalなnamespaceなので、こいつを削除して同名のを別AWSアカウントで作れば乗っ取りが可能。。
のはずが、削除してから一定時間経過しないと作成不可だったので1字違いのbucketを作成しておく。</p>

<p>最後にs3のbucket一覧を取得して、常に空のディレクトリと同期し続ける攻撃を思いつき、実装を始める。システムはs3に出力するのでそこを継続的に空にする攻撃です。しかし、実装を初めて動作確認の途中で時間切れになりシステムに埋め込めなくて断念。もうちょっと時間が欲しかったです</p>

<h2>修復</h2>

<p>次は自システムが受けた攻撃を修復するターン。</p>

<p>いろいろ余計なインスタンスが起動していたが、まずやったのがAMI番号の確認。（これが無事であればOSに侵入されていようがAMIをベースに全体の再構築が速やかにできるので）
幸い、控えていたのと一致していたので他のインスタンスを全て停止。一応monitのアラートメールが飛んでいなかったので、インスタンスに対しての操作は限定されているのだろうとは踏んでましたが。</p>

<p>AMIが無事なら次はAuto Scalingの確認。ざっと見た感じだと、lauch configは操作されておらず、scaling groupのmin-sizeが0に変更されている模様。他の変更点は確認が面倒だったので、一旦全部削除してさくっと再作成。後で聞いた話だと、Auto Scalingのrecurring schedule設定で1分起きに0台にする設定をしていたらしいが、消された時点で攻撃は無効化。</p>

<p>次にSQS。消して再作成すればてっとり早いけど、相手チームがキューに投入した画像を最終的に表示させないといけないルールだと誤解していて、その復旧に務める。新しく作ったSQSと比較するとパラメータ（Default Visibility Timeout, Retention Period, Message Size等）が異常な値に変更されていると分かり、通常の値へ戻す。</p>

<p>この時点でアプリとSQSの通信を確認するも疎通できない事を把握。pingが通らない事からSecurity Group, Routing Table, Network ACLが変更されていないかを確認。どうやらSecurity GroupのIn/Outルールが削除されている単純な攻撃だと判明し、なんなく再設定。</p>

<p>キュー内のメッセージが1コ処理されるのを確認し、SQS周りは対応済みかと思ったけど残り2コのメッセージがいくら待てども処理されず、若干悩む。
ログを見たり、メッセージの中身を覗くとと「<strong>--max-redirect=99999999</strong> 」が目に留まる。どうやら変換する画像をダウンロードする部分で無限ループさせている模様。メッセージを削除し、そのパラメータを除外したものを流してちゃんとキューが処理される事を確認。</p>

<p>最後にs3周りで怪しい設定がないかを調査して、一通りの動作確認をして復旧完了。</p>

<h2>振り返り</h2>

<p>お互いに対戦したチームと顔合わせをし、攻撃や復旧の手の内を明かします。全チームの行動記録を集約して運営側で審査を行われ各賞が授与される中、我がPRISMはSQS内の無限ループを検知・修復したのが評価されて最も優れた修復を行った「<strong>Most Awesome Fix!賞</strong>」を頂きました。後で他のチームに聞いた所、monitのような検知・通知の仕組みを導入した所はなさそうだったので、それも評価ポイントだったかも知れません。</p>

<p>賞の内容としては、ワンタイムトークンを生成するハードウェアMFAデバイスとAWSのクーポンコードでした。ありがとうございます。</p>

<p>最後にMilesが壊れても戻せるようにあるべき状態の定義と常に比較して自動的に自己治癒するのが最高のシステムと言ってました。AWSの状態を保存するにはCloudformerでCloudformationテンプレート化すれば便利で楽だけど、chefみたいにIdempotency（冪等性）を継続的に保証する仕組みをそのレイヤーで組むのはなかなか大変ですね。（個々のサーバ単位は可能だとしても）</p>

<h2>感想</h2>

<p>「<em>チューニンガソン</em>」や私が他にお手伝いをしている「<em>トラブル☆しゅーたーず</em>」とも一味違って、非常に楽しめました。</p>

<p>以下、思った事をいくつか。</p>

<ul>
<li>構築に時間が取られたのでなるべく出来合いのシステムがあった方が防衛策に専念できそう</li>
<li>攻撃可能な時間が思ったより短かったのでもうちょっと長めで</li>
<li>Default-VPCとEC2-Classicでは挙動が違うのでアカウントタイプは統一した方が良い</li>
<li>ターン性ではなく、攻撃と修復・防御のリアルタイム性を試すとか</li>
<li>あるべき正しい状態を把握する為のツールがあると他のタスクに集中できるかも</li>
</ul>


<p>次に開催される時も参加したいですね。もしくは運営側のお手伝いでも！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Non-RDSなオレオレMulti-AZ MySQL Replication]]></title>
    <link href="http://ijin.github.com/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication/"/>
    <updated>2013-05-21T18:03:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/05/21/custom-non-rds-multi-az-mysql-replication</id>
    <content type="html"><![CDATA[<p>先日（5/17/13）<a href="http://www.zusaar.com/event/668006">cloudpack night #6 - Re:Generate -</a>に参加してきました。</p>

<p>当日の様子はcloudpack<a href="https://twitter.com/yoshidashingo">吉田</a>さんの以下のレポートで。<br />
<a href="http://d.hatena.ne.jp/yoshidashingo/20130518/1368853720">cloudpack Night #6 - re:Generate - を開催しました</a></p>

<p>私はDJを少々とLTで参加させて頂いたのでその内容になります。</p>

<h2>オレオレMulti-AZのススメ</h2>

<p>AWS上でMySQLを使う場合、RDSはてっとり早くて良いんですが、たまにもうちょっと柔軟性が欲しい時があります。
例えば別のストーレジエンジンやディストリビューションを使ったり（Percona Server, MariaDB, TokuDB, Mronnga等）、RDSでは使えないインスタンスファミリー（hi1, m3, c1系）を使ったり、OSレベルでのチューニングができたり、スレーブのバッファプールを予め温めておいたり。等々。</p>

<p>しかし、RDSにはAvailability Zone (AZ)をまたいでフェールオーバーするMulti-AZ機能があり、AWSで設計するにはAZ障害を考慮した方が推奨されます。</p>

<p>そこで、MHAとVPCを組み合わせて柔軟性をもったMulti-AZ環境を実現します。
（ちなみに私の場合はhi1.4xlargeでPercona Serverを冗長化をする必要があったから）</p>

<h3>MHA</h3>

<p><a href="https://code.google.com/p/mysql-master-ha/">MHA</a>とはFacebookの<a href="http://yoshinorimatsunobu.blogspot.jp/">松信</a>さんがDeNA時代に作ったMySQLの自動フェールオーバーしてくれうナイスなツールです。Master障害時にbinlog同期とSlaveの昇格を全自動でやってくれます。昇格時にはカタログデータベースに更新をかけて新DB構成のIPの情報を更新するか、Virtual IPを切り替えるかをする必要（この担当部分はmaster_ip_failover_scriptで対応）があるけど、今回は後者的なアプローチになります。</p>

<h3>VPC</h3>

<p>ENIを使えばVirtual IP的な使い方はできるけどAZは超えられないので、source/dest. checkを無効化した上でrouting tableによって擬似Virtual IPを実現する<a href="http://aws.clouddesignpattern.org/index.php/CDP:Routing-Based_HA%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Routing-Based HAパターン</a>（CDP 2.0候補）を使います。ADSJ<a href="https://twitter.com/c9katayama">片山</a>さんの<a href="http://d.hatena.ne.jp/c9katayama/20111225/1324837509">エントリ</a>が発端ですね。</p>

<h2>Demo</h2>

<p>以下、LT時に見せたデモ動画</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/tovb29K6ddc "></iframe></div></p>

<p>擬似Virtual IPに対してそれぞれread/writeを行いつつMasterのプロセスをkillすると、通信できなくエラーが出続けるが20秒以内に自動フェールオーバーが完了しread/write共に再開します。pingも平均0.5msから2.0msに変わった事からAZが移った事が確認できます。</p>

<p>RDSのMulti-AZの場合、フェールオーバーには3-6分かかるので、かなり短時間で復旧が可能です。
また、RDSはCNAME切替によるDNSベースに対して、MHA+VPC構成の場合はIP指定することができます。そうするとアプリからのresolveが不要になり、去年起こった内部DNSが引けない障害が起きても問題ありません。</p>

<h2>注意点</h2>

<ul>
<li>RDSな自動バックアップがない

<ul>
<li>Xtrabackupとbinlogの定期s3保存で対応</li>
</ul>
</li>
<li>Point in Timeリカバリー

<ul>
<li>Chef等で自動化しましょう</li>
</ul>
</li>
<li>Read Replicaの作成

<ul>
<li>Chefで頑張りましょう</li>
</ul>
</li>
<li>学習曲線

<ul>
<li>勉強しましょう</li>
</ul>
</li>
<li>API backplaneがSPoF

<ul>
<li>AWSに祈りましょう</li>
</ul>
</li>
</ul>


<p>特に一番の懸念点は最後のAPI backplane。AWSの今までの大規模障害状況を見ていると、皆が同時に復旧をしようとしAPIへのリクエストが大量に集中してそこがボトルネックになり、リソースの操作不能に陥るという悲惨な事象が何回かありました。まあ、その場合はRDSでも同じような気はしますが、ここは当時の障害を経験にキャパシティが増加されている事を信じておくしかありませんね。。</p>

<h2>おわりに</h2>

<p>とまあ、こんなLTをしたわけですが、この後に続いたCookpadの<a href="https://twitter.com/sgwr_dts">菅原</a>さんの<a href="http://www.slideshare.net/winebarrel/ec2keepalivedlvsdsr">LT</a>の方が盛り上がって自分のは余興に終わってしまいました。</p>

<p>あ、ついでにその日はcpniteの資料作成やDJの選曲であんまり寝てなかったにもかかわらず、無事AWSソリューションアーキテクト（Associate）の認定試験に受かりました！</p>

<p><img src="https://lh5.googleusercontent.com/-d_HVsb6DgBc/UZs39XB1KGI/AAAAAAAAAuw/ntgPp33hcOI/w294-h120-no/Solutions-Architect-Associate.png"></p>

<h2>LTスライド</h2>

<p><div class="embed-ss-container"><iframe src="http://www.slideshare.net/slideshow/embed_code/21341276 "></iframe></div></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[リージョン間高速データ転送]]></title>
    <link href="http://ijin.github.com/blog/2013/04/03/accelerating-cross-region-data-transfer/"/>
    <updated>2013-04-03T09:05:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/04/03/accelerating-cross-region-data-transfer</id>
    <content type="html"><![CDATA[<p>先日の<a href="http://jaws-ug.jp/jawsdays2013/">JAWS DAYS</a>のセッション<a href="http://www.publickey1.jp/blog/13/obama_for_america.html">「Behind the scenes of Presidential Campaign」</a>でリージョン間のデータ転送を高速化するツールとして<a href="http://tsunami-udp.sourceforge.net">tsunami udp</a>と<a href="http://www.cloudopt.com">cloudopt</a>を使った話が出てたので試してみました。</p>

<p>通常、遠距離のサーバはRTTが大きくなるのでスループットが下がり、巨大なデータ転送には苦労しますが、なんと27TBを9時間で転送したとのこと！実際はマシンを並列にして同時転送したらしいので1台での実験です。</p>

<h3>前提</h3>

<ul>
<li>東京(server1) -> アメリカ西海岸(server2)</li>
<li>RTT: 120msぐらい</li>
<li>EC2 instance type: m1.large</li>
<li>OS: Ubuntu 12.04</li>
</ul>


<h3>ベーステスト</h3>

<p>10Gファイルの作成</p>

<pre><code>server1$ mkdir _tmp; cd _tmp
server1$ dd if=/dev/zero of=10G count=1 bs=1 seek=10G
</code></pre>

<p>転送</p>

<pre><code>server1$ scp -rp 10G server2:
10G     100%   10GB  11.1MB/s   15:22
</code></pre>

<p>だいたい、90Mbpsぐらい。</p>

<h3>Tsunami UDP</h3>

<p>インストールは両サーバで</p>

<pre><code>sudo apt-get install make gcc autoconf
wget http://downloads.sourceforge.net/project/tsunami-udp/tsunami-udp/tsunami-v1.1-cvsbuild42/tsunami-v1.1-cvsbuild42.tar.gz
tar xvfz tsunami-v1.1-cvsbuild42.tar.gz
cd tsunami-udp-v11-b42
make
sudo make install
</code></pre>

<p>tsunami udpはfetch型の作りなので、送信側のサーバ（server1）で対象ファイルのあるディレクトリに移動してサービス起動</p>

<pre><code>server1$ cd _tmp
server1$ tsunamid *
</code></pre>

<p>で、クライアント(server2)からファイルをfetch</p>

<pre><code>server2$ tsunami connect ec2-xx-x-xx-x-x get 10G quit
</code></pre>

<p>本当はftp-likeは対話型クライアントだけど、ワンライナーでも可能。  <br/>
転送が完了するとクライアント側で情報が出力されます。</p>

<pre><code>Transfer complete. Flushing to disk and signaling server to stop...
!!!!
PC performance figure : 224947 packets dropped (if high this indicates receiving PC overload)
Transfer duration     : 419.32 seconds
Total packet data     : 183339.18 Mbit
Goodput data          : 181958.17 Mbit
File data             : 81920.00 Mbit
Throughput            : 437.23 Mbps
Goodput w/ restarts   : 433.93 Mbps
Final file rate       : 195.36 Mbps
Transfer mode         : lossless
</code></pre>

<p>おお、確かに速い！スループットもセッションでも言ってた476Mbpsに近いし。</p>

<p>サーバ側では</p>

<pre><code>Server 1 transferred 10737418241 bytes in 419.33 seconds (195.4 Mbps)
</code></pre>

<p>ファイル自身の実際の転送レートはFinal file rateである<strong>195.4Mbps</strong>。
多分、パラメータチューニングやより速いディスクを使うとスループットはさらに向上すると予想。</p>

<h3>cloudopt</h3>

<p>次は圧縮、TCP最適化、data deduplication等、様々な技術を用いてWANを高速化する<a href="http://www.cloudopt.com">cloudopt</a>の実験。こちらは有料で、ソフトウェアをインストールしてライセンスを購入（15日間のお試しあり）して使う方法とAmazon Marketplaceでセットアップ済みの課金型AMIを起動する方法がとれます。今回はてっとり早く後者で。</p>

<p>AMIはMarketplaceでCloudoptを検索し、各リージョンで1台づつ起動。</p>

<p><img src="https://lh5.googleusercontent.com/-7PWSb_8ClIo/UVuL_bzBeAI/AAAAAAAAAtc/8Lw_bDnaPVE/s665/cloudopt_marketplace_+2013-03-30+at+2.08.07+PM.png"></p>

<p>Ubuntuベースなのが良いですね。</p>

<p>まずscpから呼べるcloudcopyを使っての転送</p>

<pre><code>server1$ scp -rp -S cloudcopy 10G server2:
10G                 100%   10GB  41.5MB/s   04:07     
CloudCopy transferred 17.22 MB, saving 99.8% of bandwidth by sending 9.983 fewer GB 
</code></pre>

<p>お、速い。しかしよく見てみると17.22MBしか転送されてません。どうやらファイル自体が全てゼロ埋めなので圧縮とdeduplicationが最大限効いているみたい。</p>

<p>では、今度は実際のDBのバックアップで転送実験（容量14GB）</p>

<pre><code>server1$ scp -rp -S cloudcopy dbbackup.tar server2:
dbbackup.tar                100%   14GB  11.2MB/s   20:42   
CloudCopy transferred 6.041 GB, saving 55.5% of bandwidth by sending 7.528 fewer GB
</code></pre>

<p>スループットはほぼ一緒だけど、転送容量が削減できてます。</p>

<p>一度転送したファイルはbyte cacheされるので、次に転送する時は差分だけ送るので高速化されます。</p>

<pre><code>server2$ rm dbbackup.tar 

server1$ tar rvf dbbackup.tar file
server1$ scp -rp -S cloudcopy dbbackup.tar server2:
dbbackup.tar                100%   14GB  20.0MB/s   11:35  
CloudCopy transferred 59.57 MB, saving 99.6% of bandwidth by sending 13.511 fewer GB
</code></pre>

<h3>リージョン間レプリケーション</h3>

<p>次はMySQLのレプリケーション実験。</p>

<p>各インスタンスでのピア設定</p>

<pre><code>server1$ sudo cloudconfig peer_add server2 server2_local_ip(10.x.x.x)
server2$ sudo cloudconfig peer_add server1 server1_local_ip(10.x.x.x)
</code></pre>

<p>これでcloudoptを使ったサーバ間のトンネルが確立されます。MySQLのレプリケーションはprivate ipでの設定が必要。
一通りレプリケーションが出来き、スレーブIOを停止した状態でマスターにしばらく書き込んだのちに再開すると、binlogが転送されるのでcloudstatsコマンドで統計が見れます。</p>

<pre><code>Component - cloudoptimizer
------------------------------------------------------------
           Number of connections:                    1
              Original data size:            111.96 MB
           Transferred data size:             52.44 MB

            Bandwidth Saving:             59.51 MB (53.2%)
</code></pre>

<p><strong>53.2%</strong>の転送容量削減！</p>

<h3>結論</h3>

<p>以上を組み合わせれば、新たなCDP候補である「<strong>リージョン間レプリケーションパターン (Cross-Region Replication Pattern)</strong>」が実現できます。</p>

<ul>
<li>巨大データをリージョン間で転送するにはtsunami udpが有効そう</li>
<li>リージョン間での差分バックアップやレプリケーション向けにはcloudoptで高速化</li>
<li>普通のHTTP通信とかも使えるかも</li>
<li>s3へのアップロード高速化も対応しているのでいずれ試してみたい</li>
</ul>

]]></content>
  </entry>
  
</feed>
