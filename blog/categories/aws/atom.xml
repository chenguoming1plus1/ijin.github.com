<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: aws | @ijin]]></title>
  <link href="http://ijin.github.com/blog/categories/aws/atom.xml" rel="self"/>
  <link href="http://ijin.github.com/"/>
  <updated>2013-02-22T17:46:07+09:00</updated>
  <id>http://ijin.github.com/</id>
  <author>
    <name><![CDATA[Michael H. Oshita]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS SSD vs Fusion-IOでのMySQLベンチマーク]]></title>
    <link href="http://ijin.github.com/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io/"/>
    <updated>2013-02-22T17:32:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/02/22/mysql-benchmarks-on-aws-ssd-vs-fusion-io</id>
    <content type="html"><![CDATA[<p>巷ではMySQL 5.6 GAが出て騒がしいですが、ちょっと前に5.5系でAWSのSSDインスタンス（hi1.4xlarge）に載せ替える案件があったので、その時に取ったベンチマークを公表します。以前Fusion-IO (ioDrive Duo)でも同じようにやったので、比較になれば。</p>

<h2>経緯</h2>

<ul>
<li>あるウェブサービスのDBサイズが巨大でm2.4xlargeでも辛くなってきている</li>
<li>アクセスパターンによりパーティショニングが効かない</li>
<li>シャーディングをするにはアプリ改修が大変</li>
<li>数週間後に急激なアクセスが予想され、時間的余裕がない！</li>
<li>データサイズの急激な増加によりbuffer poolから溢れ、ディスクアクセスのさらなる発生が懸念</li>
</ul>


<p>というわけで、時間がないのでSSDへの移行を検討し、ベンチマークを取りました。</p>

<h2>ベンチマーク</h2>

<p>buffer poolが徐々に足りなくなった場合のディスクアクセスの発生をシミュレート</p>

<ul>
<li>sysbenchのoltpモード</li>
<li>データサイズは12G（5000万件）</li>
<li>readonly</li>
<li>uniform（フルスキャン）</li>
</ul>


<p>主要my.cnfパラメータ</p>

<pre><code> sync_binlog = 0
 innodb_buffer_pool_size = XXG
 innodb_flush_method = O_DIRECT
 innodb_flush_log_at_trx_commit = 1
 innodb_file_per_table
 innodb_io_capacity = 2000
</code></pre>

<p>コマンド</p>

<pre><code> time sysbench --test=oltp --oltp-table-size=50000000 --db-driver=mysql --mysql-user=root prepare                                                                                                         
 time sysbench --test=oltp --oltp-table-size=50000000 --db-driver=mysql --mysql-user=root --num-threads=16 --max-requests=0 --max-time=180 --init-rng=on --oltp-read-only=on --oltp-dist-type=uniform 2&gt;&amp;1 run                                                                                                         
</code></pre>

<h2>結果</h2>

<p>トランザクション推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=2&amp;zx=ii4lryrf8pz8"></p>

<p>レスポンスタイム推移</p>

<p><img src="https://docs.google.com/spreadsheet/oimg?key=0Aliw9SoXFJNMdFhhcHJkcDA5MGlackNHTXlPcWt0VWc&amp;oid=3&amp;zx=c2drap7b5561"></p>

<p>Fusion-IOと比べて半分ぐらい。ioDrvie Duoの公称IOPSが250,000+ IOPSでhi1.4xlargeが120,000 IOPSなので、まあ合致しますね。</p>

<p>まだ整理されてないベンチマーク結果があるので、後ほど追記しようと思います。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[非ELBなAutoscalingによる自動復旧]]></title>
    <link href="http://ijin.github.com/blog/2013/02/08/self-healing-with-non-elb-autoscaling/"/>
    <updated>2013-02-08T09:29:00+09:00</updated>
    <id>http://ijin.github.com/blog/2013/02/08/self-healing-with-non-elb-autoscaling</id>
    <content type="html"><![CDATA[<p>バッチ処理等、サーバの冗長化が難しく仕方なく1台で動かさざるを得ない場合があります。でも可用性は確保したい。また、Pacemakerやkeepalived等できなくはないが、お金もあんまりかけられない場合もあります。
そんな時にAWS上でよく使うのがAutoscalingによる1台構成です。最低台数・最大台数共に「1」に設定しておけばEC2インスタンスが壊れても自動的に新しいのにリプレースされて復旧されます。</p>

<p>しかし、Autoscalingのhealth-check-typeを「EC2」にした場合、インスタンスの起動状態（running, stopped）しか見てくれないので、今までこの構成を実現するのにELBによる死活監視が必要でした。インスタンスがHTTPサーバじゃない場合、ちょっとムダです。</p>

<p>ところが、ちょっと前にAutoscalingがインスタンスの健康状態をチェックするEC2 status checkに<a href="http://aws.amazon.com/about-aws/whats-new/2012/12/14/auto-scaling-now-uses-amazon-ec2-status-checks/">対応</a>し、ELBが不要になったはずなので試してみました。</p>

<p>今回は各種AWSサービスに対応した統合されたPython版の<a href="http://aws.amazon.com/cli/">AWS CLI</a>ツールを使います。</p>

<h3>セットアップ</h3>

<p>まずは、ツールのインストール</p>

<pre><code>sudo apt-get install python-pip
sudo pip install awscli
complete -C aws_completer was
</code></pre>

<h3>Autoscaling設定</h3>

<p>Launch Configの設定</p>

<pre><code>aws autoscaling create-launch-configuration --image-id ami-4a12aa4b \
--launch-configuration-name test-lc --instance-type t1.micro --key-name ijin-tokyo \
--security-groups test --iam-instance-profile test_iam

{
    "ResponseMetadata": {
        "RequestId": "c0e66974-7103-11e2-9780-a53199bac60e"
    }
}
</code></pre>

<p>Scaling Groupの設定</p>

<pre><code>aws autoscaling create-auto-scaling-group --auto-scaling-group-name test-sg \
--launch-configuration-name test-lc --min-size 1 --max-size 1 \
--health-check-grace-period 180 --tags '{"key":"Name", "value":"as-test"}' \
'{"key":"Use Case", "value":"test"}' --availability-zones ap-northeast-1a --health-check-type "EC2"

{
    "ResponseMetadata": {
        "RequestId": "e3808ef3-7103-11e2-9780-a53199bac60e"
    }
}
</code></pre>

<p>通知</p>

<pre><code>aws autoscaling put-notification-configuration --auto-scaling-group-name test-sg \
--topic-arn arn:aws:sns:ap-northeast-1:521026608000:test \
--notification-types autoscaling:EC2_INSTANCE_LAUNCH autoscaling:EC2_INSTANCE_TERMINATE \
autoscaling:EC2_INSTANCE_LAUNCH_ERROR autoscaling:EC2_INSTANCE_TERMINATE_ERROR

{
    "ResponseMetadata": {
        "RequestId": "f68359be-7103-11e2-9a1a-5f77b12b596e"
    }
}
</code></pre>

<p>レスポンスがjsonなのが良いですね。
また、<a href="http://aws.amazon.com/developertools/2535">Auto Scaling Command Line Tool</a>と違って、tagでスペースが使えるようになったのが素晴らしい！</p>

<p>以上の設定でAutoscalingによってインスタンスが1台立ち上がります。</p>

<h3>自動復旧</h3>

<p>最後にインスタンス不調（status check failure）をシミュレートする為にインスタンス内からネットワークを落とします。</p>

<pre><code>ubuntu@ip-10-128-25-25:~$ sudo ifdown eth0
</code></pre>

<p>これでstatus checkがfailし、Autoscalingが自動的に新しいインスタンスと取り替えてくれるはず！</p>

<p><img src="https://lh6.googleusercontent.com/-9FpM6ywjg84/URN6q29FD-I/AAAAAAAAAsw/paP8HBnisPE/s161/aws_status_check_2013-02-07+18.06.20.png"></p>

<p><img src="https://lh5.googleusercontent.com/-5avxLvp5RH8/URN6n-ihwiI/AAAAAAAAAso/zOHxli4vM8o/s702/aws_instance_check_2013-02-07+18.09.19.png"></p>

<p>と、期待して待っていたらなかなかアラートメールが来ません。。</p>

<p>設定間違ったかなーっていろいろ見直していたら20分経った頃にやっと到着。</p>

<p><code>
Service: AWS Auto Scaling
Time: 2013-02-07T09:17:42.304Z
RequestId: f395660b-4847-4415-ad33-f8cc5091bdb3
Event: autoscaling:EC2_INSTANCE_TERMINATE
AccountId: 521026608000
AutoScalingGroupName: test-sg
AutoScalingGroupARN: arn:aws:autoscaling:ap-northeast-1:521026608000:autoScalingGroup:a036877b-dab7-4e5d-a6e1-1d3424b20d14:autoScalingGroupName/test-sg
ActivityId: f395660b-4837-4415-ad33-f8cc5071bdb3
Description: Terminating EC2 instance: i-15fadd17
Cause: At 2013-02-07T09:16:57Z an instance was taken out of service in response to a system health-check.
StartTime: 2013-02-07T09:16:57.389Z
EndTime: 2013-02-07T09:17:42.304Z
StatusCode: InProgress
StatusMessage:
Progress: 50
EC2InstanceId: i-15fadd17
Details: {}
</code></p>

<p>うーん。動く事は動いたけど、ちょっと時間がかかるなぁ。</p>

<p>この後何回か試してみたけど、Autoscaling発動までどれも20分ぐらいかかりました。</p>

<h3>結論</h3>

<p>20分程サーバダウンが許容できるようなゆるめの条件に限定した場合には非ELBでも使えるかな。まあ、それでも適用する場面は多々あるとは思いますが。（早める方法あるのかなー。）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Auto Scalingの設定とデプロイ方法]]></title>
    <link href="http://ijin.github.com/blog/2012/12/03/cdp/"/>
    <updated>2012-12-03T01:34:00+09:00</updated>
    <id>http://ijin.github.com/blog/2012/12/03/cdp</id>
    <content type="html"><![CDATA[<p><a href="http://www.zusaar.com/event/451061">CDP Advent Calendar 2012</a>に登録しました。ここ1年ちょいで使い慣れてきたパターンがあり、作った当時はクラウドデザインパターンはなかったのですが、<a href="http://aws.clouddesignpattern.org/index.php/CDP:Clone_Server%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Clone Server</a>と<a href="http://aws.clouddesignpattern.org/index.php/CDP:Scale_Out%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3">Scale Out</a>パターンの組合せに当てはまると思うので紹介します。ちなみにアプリはRails。</p>

<p>常にデプロイして更新し続けるシステムを手動、あるいは自動スケールアウトする時に便利な手法だったりします。</p>

<p>図にするとこんな感じですかね。</p>

<p><img src="https://lh4.googleusercontent.com/-eDSfSiz0XhU/ULyOlKj_JKI/AAAAAAAAArw/QzSfVJeeUfw/w727-h490-p-k/CDP_Clone%252BScale_Out.png"></p>

<h2>Auto Scaling設定</h2>

<h3>Launch Config</h3>

<p>まず、ベースとなるAMIの起動インスタンスサイズやセキュリティーグループを定義したLaunch Configを設定。</p>

<pre><code>as-create-launch-config cdp-lc --image-id ami-22a51d23 --instance-type m1.small \
--group cdp_web, cdp_admin
</code></pre>

<h3>Scaling Group</h3>

<p>次に、Scaling Groupで適用するAvailability Zone、インスタンス数の最小・最大閾値設定、紐尽くELB、死活監視方法・開始待ち時間、タグ等を定義。（ec2addtagではスペース入りのキーを設定できるのにas-create-auto-scaling-groupではできないので注意。早く直して。。）</p>

<pre><code>as-create-auto-scaling-group cdp-sg --launch-configuration cdp-lc \
--availability-zones ap-northeast-1a  --min-size 1 --max-size 9 --load-balancers cdp \
--health-check-type ELB --grace-period 300 --tag "k=Name, v=web.cdp" --tag "k=Use_Case, v=Test"
</code></pre>

<h3>Scaling Out Policy</h3>

<p>Scaling Outのポリシー設定。以下の例ではインスタンス1台を追加し、次のスケールアクションまでは5分間待機。ポリシーのARN (Amazon Resource Name)が出力されるので控えます。</p>

<pre><code>as-put-scaling-policy CDPOut --auto-scaling-group cdp-sg --adjustment 1 --type ChangeInCapacity \
--cooldown 300

&gt; arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:d0d4dcf1-fb44-428a-a19c-38946633acf5:autoScalingGroupName/cdp-sg:policyName/CDPOut
</code></pre>

<h3>Cloudwatchトリガー（Scaling Out）</h3>

<p>Cloudwatchで閾値を超えたらスケールアウトするように設定。以下の例では対象Scaling Group配下のインスタンス達のCPUが1分間で平均75%以上で推移した場合、先ほど設定したScaling OutポリシーがARN経由で実行されます。また、閾値を超過あるいは下回った場合にSNS経由でアラートメールを飛ばします。</p>

<pre><code>mon-put-metric-alarm  CDPHighCPUAlarm --comparison-operator GreaterThanThreshold \
--evaluation-periods 1 --metric-name CPUUtilization --namespace "AWS/EC2" --period 60 \
--statistic Average --threshold 75 --dimensions "AutoScalingGroupName=cdp-sg" \
--ok-actions arn:aws:sns:ap-northeast-1:494850320039:cdp-alert --alarm-actions \
arn:aws:sns:ap-northeast-1:494850320039:cdp-alert, arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:d0d4dcf1-fb44-428a-a19c-38946633acf5:autoScalingGroupName/cdp-sg:policyName/CDPOut
</code></pre>

<h3>Scaling Down Policy</h3>

<p>同じくScaling Downのポリシー設定。インスタンスが起動すると最低1時間は課金されるので頻繁に伸縮するともったいないのでスケールダウンアクションはゆっくりやるのがポイントです。</p>

<pre><code>as-put-scaling-policy CDPDown --auto-scaling-group cdp-sg --adjustment=-1 \
--type ChangeInCapacity --cooldown 1500

&gt; arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:de53fbd5-130c-46a8-bf47-25e29f7d358e:autoScalingGroupName/cdp-sg:policyName/CDPDown
</code></pre>

<h3>Cloudwatchトリガー（Scaling Down）</h3>

<p>スケールダウンのトリガーは平均CPUが35%を25分間下回った場合に実行されます。この閾値周辺のアラートメールはいらないので設定してません。</p>

<pre><code>mon-put-metric-alarm CDPLowCPUAlarm --comparison-operator LessThanThreshold \
--evaluation-periods 1 --metric-name CPUUtilization --namespace "AWS/EC2" --period 1500 \
--statistic Average --threshold 35 --dimensions "AutoScalingGroupName=cdp-sg" --alarm-actions \
arn:aws:autoscaling:ap-northeast-1:494850320039:scalingPolicy:de53fbd5-130c-46a8-bf47-25e29f7d358e:autoScalingGroupName/cdp-sg:policyName/CDPDown
</code></pre>

<h3>通知</h3>

<p>最後にスケールアクション時に通知が飛ぶように設定。例えば、あるインスタンスが不調により反応がなく、ポリシーによってリプレースされる場合に飛んだりします。</p>

<pre><code>as-put-notification-configuration cdp-sg -t arn:aws:sns:ap-northeast-1:494850320039:cdp-alert \
-n autoscaling:EC2_INSTANCE_LAUNCH, autoscaling:EC2_INSTANCE_TERMINATE, \
autoscaling:EC2_INSTANCE_LAUNCH_ERROR, autoscaling:EC2_INSTANCE_TERMINATE_ERROR
</code></pre>

<h2>APP側の設定</h2>

<h3>ソースコード同期</h3>

<p>同期には起動時にupstart経由でrsyncを叩いて管理サーバから最新ソースを取ってきてサービスを再起動します。転送時の圧縮モードはarcfourが一番スループットが出たのでそれに。</p>

<p><div><script src='https://gist.github.com/4191986.js?file='></script>
<noscript><pre><code># sync source code
description &quot;Update source code&quot;

start on filesystem
stop on shutdown

task
console output

script
time sudo -u deploy rsync -av --delete -e 'ssh -c arcfour -i /home/deploy/.ssh/id_dsa -o StrictHostKeyChecking=no' deploy@admin.cdp:/usr/local/apps/project/ /usr/local/rails_apps/project &gt;&gt; /mnt/update.log 2&gt;&amp;1
/etc/init.d/unicorn upgrade &gt;&gt; /mnt/update.log 2&gt;&amp;1
/etc/init.d/nginx restart &gt;&gt; /mnt/update.log 2&gt;&amp;1
end script
</code></pre></noscript></div>
</p>

<h2>Capistrano</h2>

<p>デプロイはマスターサーバ（管理兼）上でCapistranoを実行し、ELB配下の生きているインスタンスに対して更新をかけます。deploy.rbに追加する記述は以下の通り。昔はec2 api toolsを直接呼んでパースしたりしてコードが長かったのですが、今は<a href="http://aws.amazon.com/sdkforruby/">AWS SDK for Ruby</a>があり、<a href="http://aws.amazon.com/iam/">IAM role</a>でinstance profileを設定すればわずか数行でできてしまいます！</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class='ruby'><span class='line'><span class="nb">require</span> <span class="s1">&#39;aws-sdk&#39;</span>
</span><span class='line'><span class="no">AWS</span><span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="ss">:ec2_endpoint</span> <span class="o">=&gt;</span> <span class="s1">&#39;ec2.ap-northeast-1.amazonaws.com&#39;</span><span class="p">,</span> <span class="ss">:elb_endpoint</span> <span class="o">=&gt;</span> <span class="s1">&#39;elasticloadbalancing.ap-northeast-1.amazonaws.com&#39;</span><span class="p">)</span>
</span><span class='line'><span class="n">instances</span> <span class="o">=</span> <span class="no">AWS</span><span class="o">::</span><span class="no">ELB</span><span class="o">.</span><span class="n">new</span><span class="o">.</span><span class="n">load_balancers</span><span class="o">[</span><span class="s1">&#39;cdp&#39;</span><span class="o">].</span><span class="n">instances</span><span class="o">.</span><span class="n">select</span><span class="p">{</span><span class="o">|</span><span class="n">i</span><span class="o">|</span> <span class="n">i</span><span class="o">.</span><span class="n">exists?</span> <span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span> <span class="n">i</span><span class="o">.</span><span class="n">elb_health</span><span class="o">[</span><span class="ss">:state</span><span class="o">]</span> <span class="o">==</span> <span class="s2">&quot;InService&quot;</span><span class="p">}</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="o">&amp;</span><span class="n">amp</span><span class="p">;</span><span class="ss">:public_dns_name</span><span class="p">)</span>
</span><span class='line'><span class="n">servers</span> <span class="o">=</span> <span class="n">instances</span> <span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span><span class="o">&amp;</span><span class="n">lt</span><span class="p">;</span> <span class="s2">&quot;localhost&quot;</span>
</span><span class='line'><span class="n">role</span> <span class="ss">:app</span> <span class="k">do</span> <span class="n">servers</span> <span class="k">end</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h2>注意点</h2>

<ul>
<li>同期するファイル数が多すぎる（数十万個）と、チェックサム比較で時間がかかってしまい同期が終了する前にAuto Scalingの死活監視によってインスタンスがterminateされ、またlaunchされterminateされるという恐怖のスケールループ地獄に陥る。。。（これ、制限できないのかな）</li>
<li>あらかじめトラフィック増の時間帯が分かっていたら<a href="http://docs.amazonwebservices.com/AutoScaling/latest/DeveloperGuide/scaling_plan.html#schedule_time">Scheduled Action</a>で多めに設定しておいて自動スケールダウンさせた方が吉。</li>
<li>マスタサーバがSPOFとなりうるので冗長化する、もしくはrsyncよりs3経由にした方が良い。</li>
<li>急激なトラフィック増ではELB自体のスケールが追いつかない場合も。</li>
</ul>

]]></content>
  </entry>
  
</feed>
